{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CUHK-DH-Lab/CUHK-DH-Lab.github.io/blob/main/Google_Vision_OCR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1a39e518"
      },
      "source": [
        "Extracting Text from Images with Google Cloud Vision API (Python)\n",
        "This notebook demonstrates how to use Google Cloud's Vision API to perform Optical Character Recognition (OCR) on an image file. We will use the document_text_detection feature, which is optimized for dense text documents like scans or photos of pages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "id": "EqpFckBjxuUO",
        "outputId": "c3b21515-1cfd-4e12-a3a9-f55c17fe8060"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting google-cloud-vision\n",
            "  Downloading google_cloud_vision-3.12.0-py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision) (2.29.0)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-cloud-vision) (2.47.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-vision) (1.76.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-vision) (1.27.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-vision) (5.29.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2026.1.4)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision) (1.72.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision) (1.71.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-vision) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-vision) (4.9.1)\n",
            "Requirement already satisfied: typing-extensions~=4.12 in /usr/local/lib/python3.12/dist-packages (from grpcio<2.0.0,>=1.33.2->google-cloud-vision) (4.15.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-vision) (0.6.2)\n",
            "Downloading google_cloud_vision-3.12.0-py3-none-any.whl (538 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m538.2/538.2 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: google-cloud-vision\n",
            "Successfully installed google-cloud-vision-3.12.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "6b82cacadeb448fcbd8e3f04bcf84e45"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install google-cloud-vision requests Pillow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqiHxi3X81qB",
        "outputId": "49af408d-cc94-4d6c-fa3e-60b714eea705"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authentication successful using local JSON file.\n",
            "--- Attempting OCR on local image file: IMG_2056.JPG ---\n",
            "\n",
            "Detected Text (Full):\n",
            "--------------------\n",
            "MAXES\n",
            "ठ\n",
            "Lusiadis Leonina\n",
            "Libri Duodecim.\n",
            "Carmen SrCeroicum\n",
            "reni (simo\n",
            "Lusitania\n",
            "Principi Petro\n",
            "Dicatum.\n",
            "Patre Ignatio Archamone\n",
            "Neapolitano è Societate Jesu\n",
            "in Goana Provincia operario\n",
            "Je Rebus Gestis Lusitanorum\n",
            "in Regionibus\n",
            "Vlera Marinis\n",
            "Compediosa Carratio.\n",
            "--------------------\n",
            "Authentication successful using local JSON file.\n",
            "--- Attempting OCR on local image file: IMG_2056.JPG ---\n",
            "\n",
            "Detected Text (Full):\n",
            "--------------------\n",
            "MAXES\n",
            "ठ\n",
            "Lusiadis Leonina\n",
            "Libri Duodecim.\n",
            "Carmen SrCeroicum\n",
            "reni (simo\n",
            "Lusitania\n",
            "Principi Petro\n",
            "Dicatum.\n",
            "Patre Ignatio Archamone\n",
            "Neapolitano è Societate Jesu\n",
            "in Goana Provincia operario\n",
            "Je Rebus Gestis Lusitanorum\n",
            "in Regionibus\n",
            "Vlera Marinis\n",
            "Compediosa Carratio.\n",
            "--------------------\n"
          ]
        }
      ],
      "source": [
        "import io\n",
        "import os\n",
        "from google.cloud import vision\n",
        "from google.oauth2 import service_account\n",
        "\n",
        "# --- Configuration ---\n",
        "# Update this path if the filename is slightly different\n",
        "JSON_FILE_PATH = '/content/renaissance-ocr-4aabe5b8dc65.json'\n",
        "IMAGE_FILENAME = 'IMG_2056.JPG'\n",
        "# ---------------------\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 1. Authenticate using the local service account key file\n",
        "# -----------------------------------------------------------\n",
        "try:\n",
        "    if not os.path.exists(JSON_FILE_PATH):\n",
        "        raise FileNotFoundError(f\"Credentials file not found at: {JSON_FILE_PATH}\")\n",
        "\n",
        "    # The library reads the file directly from disk\n",
        "    credentials = service_account.Credentials.from_service_account_file(JSON_FILE_PATH)\n",
        "    client = vision.ImageAnnotatorClient(credentials=credentials)\n",
        "    print(\"Authentication successful using local JSON file.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Authentication failed: {e}\")\n",
        "    # Stop execution if authentication fails\n",
        "    exit()\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 2. Define the function to perform OCR from a local file\n",
        "# -----------------------------------------------------------\n",
        "def detect_text_from_local_file(image_path):\n",
        "    \"\"\"Detects text in a local image file using the Google Cloud Vision API.\"\"\"\n",
        "\n",
        "    if not os.path.exists(image_path):\n",
        "        print(f\"Error: The image file '{image_path}' was not found in the current directory.\")\n",
        "        return\n",
        "\n",
        "    print(f\"--- Attempting OCR on local image file: {image_path} ---\")\n",
        "\n",
        "    # Read the file into memory\n",
        "    with io.open(image_path, 'rb') as image_file:\n",
        "        content = image_file.read()\n",
        "\n",
        "    # Pass the byte content directly to the Vision API\n",
        "    image = vision.Image(content=content)\n",
        "\n",
        "    # This is the correct method call for the client library\n",
        "    api_response = client.text_detection(image=image)\n",
        "    texts = api_response.text_annotations\n",
        "\n",
        "    if texts:\n",
        "        print('\\nDetected Text (Full):')\n",
        "        print(\"-\" * 20)\n",
        "        # *** FIX IS HERE: Access the FIRST element of the list (index 0) ***\n",
        "        full_text = texts[0].description\n",
        "        print(full_text)\n",
        "        print(\"-\" * 20)\n",
        "    else:\n",
        "        print('\\nNo text detected.')\n",
        "\n",
        "    # Error handling for the API call itself\n",
        "    if api_response.error.message:\n",
        "        error_url = 'https://cloud.google.com'\n",
        "        raise Exception(\n",
        "            f\"{api_response.error.message} For more info on error messages, check: {error_url}\"\n",
        "        )\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 3. Main execution block: Run the function\n",
        "# -----------------------------------------------------------\n",
        "if __name__ == '__main__':\n",
        "    detect_text_from_local_file(IMAGE_FILENAME)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggd2q6qn97c9",
        "outputId": "6e038ae8-327c-492f-8c37-46cdcf7341b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Authentication successful using local JSON file.\n",
            "--- Attempting OCR on local image file using DOCUMENT mode: IMG_2056.JPG ---\n",
            "\n",
            "Detected Text (Full Document Mode):\n",
            "--------------------\n",
            "MAXES\n",
            "ठ\n",
            "Lusiadis Leonina\n",
            "Libri Duodecim.\n",
            "Carmen SrCeroicum\n",
            "reni (simo\n",
            "Lusitania\n",
            "Principi Petro\n",
            "Dicatum.\n",
            "Patre Ignatio Archamone\n",
            "Neapolitano è Societate Jesu\n",
            "in Goana Provincia operario\n",
            "Je Rebus Gestis Lusitanorum\n",
            "in Regionibus\n",
            "Vlera Marinis\n",
            "Compediosa Carratio.\n",
            "--------------------\n"
          ]
        }
      ],
      "source": [
        "import io\n",
        "import os\n",
        "import json\n",
        "from google.cloud import vision\n",
        "from google.oauth2 import service_account\n",
        "\n",
        "# --- Configuration ---\n",
        "JSON_FILE_PATH = '/content/renaissance-ocr-4aabe5b8dc65.json'\n",
        "IMAGE_FILENAME = 'IMG_2056.JPG'\n",
        "# ---------------------\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 1. Authenticate using the local service account key file\n",
        "# -----------------------------------------------------------\n",
        "try:\n",
        "    if not os.path.exists(JSON_FILE_PATH):\n",
        "        raise FileNotFoundError(f\"Credentials file not found at: {JSON_FILE_PATH}\")\n",
        "\n",
        "    credentials = service_account.Credentials.from_service_account_file(JSON_FILE_PATH)\n",
        "    client = vision.ImageAnnotatorClient(credentials=credentials)\n",
        "    print(\"Authentication successful using local JSON file.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Authentication failed: {e}\")\n",
        "    exit()\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 2. Define the function to perform OCR from a local file\n",
        "# -----------------------------------------------------------\n",
        "def detect_document_text_from_local_file(image_path):\n",
        "    \"\"\"Detects text in a local image file using DOCUMENT_TEXT_DETECTION.\"\"\"\n",
        "\n",
        "    if not os.path.exists(image_path):\n",
        "        print(f\"Error: The image file '{image_path}' was not found in the current directory.\")\n",
        "        return\n",
        "\n",
        "    print(f\"--- Attempting OCR on local image file using DOCUMENT mode: {image_path} ---\")\n",
        "\n",
        "    with io.open(image_path, 'rb') as image_file:\n",
        "        content = image_file.read()\n",
        "\n",
        "    image = vision.Image(content=content)\n",
        "\n",
        "    # *** CHANGE IS HERE: Use document_text_detection instead of text_detection ***\n",
        "    api_response = client.document_text_detection(image=image)\n",
        "\n",
        "    # The response structure is slightly different for document mode\n",
        "    full_text = api_response.full_text_annotation.text\n",
        "\n",
        "    if full_text:\n",
        "        print('\\nDetected Text (Full Document Mode):')\n",
        "        print(\"-\" * 20)\n",
        "        print(full_text)\n",
        "        print(\"-\" * 20)\n",
        "    else:\n",
        "        print('\\nNo text detected in document mode.')\n",
        "\n",
        "    if api_response.error.message:\n",
        "        error_url = 'https://cloud.google.com'\n",
        "        raise Exception(\n",
        "            f\"{api_response.error.message} For more info on error messages, check: {error_url}\"\n",
        "        )\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 3. Main execution block: Run the function\n",
        "# -----------------------------------------------------------\n",
        "if __name__ == '__main__':\n",
        "    # Call the new function\n",
        "    detect_document_text_from_local_file(IMAGE_FILENAME)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kxKaxDDt54q"
      },
      "source": [
        "Then add language hint for Latin."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzqbCSo--Jzj",
        "outputId": "980cf08e-fb4d-4c21-8a71-893f28a13d03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Attempting OCR on local image file with Latin hint: IMG_2056.JPG ---\n",
            "\n",
            "Detected Text (Document Mode, Latin Hint):\n",
            "--------------------\n",
            "MAXES\n",
            "d\n",
            "Lusiadis Leonina\n",
            "Libri Duodecim.\n",
            "Carmen SrCeroicum\n",
            "reni (simo\n",
            "Lusitania\n",
            "Principi Petro\n",
            "Dicatum.\n",
            "Patre Ignatio Archamone\n",
            "Neapolitano è Societate Jesu\n",
            "in Goana Provincia operario\n",
            "Je Rebus Gestis Lusitanorum\n",
            "in Regionibus\n",
            "Vlera Marinis\n",
            "Compediosa Carratio.\n",
            "--------------------\n"
          ]
        }
      ],
      "source": [
        "# ... (imports and authentication code from previous response) ...\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 2. Define the function to perform OCR with Language Hint\n",
        "# -----------------------------------------------------------\n",
        "def detect_document_text_with_latin_hint(image_path):\n",
        "    \"\"\"Detects text in a local image file using DOCUMENT_TEXT_DETECTION with a Latin hint.\"\"\"\n",
        "\n",
        "    if not os.path.exists(image_path):\n",
        "        print(f\"Error: The image file '{image_path}' was not found.\")\n",
        "        return\n",
        "\n",
        "    print(f\"--- Attempting OCR on local image file with Latin hint: {image_path} ---\")\n",
        "\n",
        "    with io.open(image_path, 'rb') as image_file:\n",
        "        content = image_file.read()\n",
        "\n",
        "    image = vision.Image(content=content)\n",
        "\n",
        "    # *** ADD LANGUAGE HINT ***\n",
        "    image_context = vision.ImageContext(language_hints=['la'])\n",
        "\n",
        "    # Use document_text_detection for higher accuracy on documents\n",
        "    api_response = client.document_text_detection(\n",
        "        image=image,\n",
        "        image_context=image_context\n",
        "    )\n",
        "\n",
        "    full_text = api_response.full_text_annotation.text\n",
        "\n",
        "    if full_text:\n",
        "        print('\\nDetected Text (Document Mode, Latin Hint):')\n",
        "        print(\"-\" * 20)\n",
        "        print(full_text)\n",
        "        print(\"-\" * 20)\n",
        "    else:\n",
        "        print('\\nNo text detected in document mode.')\n",
        "\n",
        "    if api_response.error.message:\n",
        "        error_url = 'https://cloud.google.com'\n",
        "        raise Exception(\n",
        "            f\"{api_response.error.message} For more info on error messages, check: {error_url}\"\n",
        "        )\n",
        "\n",
        "# ... (main execution block __main__ below, remember to call the new function name) ...\n",
        "if __name__ == '__main__':\n",
        "    detect_document_text_with_latin_hint(IMAGE_FILENAME)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wr_wOHKkuXb0"
      },
      "source": [
        "Now, let's start with a pdf and extract the images from some of the first few pages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTw3ebrWueHl",
        "outputId": "fabd461c-2c81-44b8-c5c6-e0e3e31c59e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyMuPDF\n",
            "  Downloading pymupdf-1.26.7-cp310-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Downloading pymupdf-1.26.7-cp310-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDF\n",
            "Successfully installed PyMuPDF-1.26.7\n",
            "Created directory: extracted_images_pages_7_to_14\n",
            "--- Starting image extraction from confuciussinarum00conf_0.pdf (Pages 7 to 14) ---\n",
            "Saved extracted_images_pages_7_to_14/page_07.png\n",
            "Saved extracted_images_pages_7_to_14/page_08.png\n",
            "Saved extracted_images_pages_7_to_14/page_09.png\n",
            "Saved extracted_images_pages_7_to_14/page_10.png\n",
            "Saved extracted_images_pages_7_to_14/page_11.png\n",
            "Saved extracted_images_pages_7_to_14/page_12.png\n",
            "Saved extracted_images_pages_7_to_14/page_13.png\n",
            "Saved extracted_images_pages_7_to_14/page_14.png\n",
            "--- Extraction complete. Images saved in 'extracted_images_pages_7_to_14/' directory. ---\n"
          ]
        }
      ],
      "source": [
        "# --- Google Colab Code ---\n",
        "\n",
        "# 1. Install necessary libraries\n",
        "# PyMuPDF provides high-quality PDF rendering capabilities.\n",
        "!pip install PyMuPDF Pillow\n",
        "\n",
        "import fitz  # This is PyMuPDF\n",
        "import io\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# --- Configuration ---\n",
        "PDF_FILE_NAME = 'confuciussinarum00conf_0.pdf'\n",
        "START_PAGE = 7  # Page number to start from (inclusive)\n",
        "END_PAGE = 14   # Page number to end at (inclusive)\n",
        "OUTPUT_FOLDER = 'extracted_images_pages_7_to_14'\n",
        "DPI = 300 # Set a high DPI for better OCR quality (e.g., 300 or 500)\n",
        "# ---------------------\n",
        "\n",
        "# Create output directory if it doesn't exist\n",
        "if not os.path.exists(OUTPUT_FOLDER):\n",
        "    os.makedirs(OUTPUT_FOLDER)\n",
        "    print(f\"Created directory: {OUTPUT_FOLDER}\")\n",
        "\n",
        "# Check if the PDF file exists in the Colab environment\n",
        "if not os.path.exists(PDF_FILE_NAME):\n",
        "    print(f\"Error: The PDF file '{PDF_FILE_NAME}' was not found in the Colab environment.\")\n",
        "    print(\"Please upload the file using the Colab file browser (folder icon on the left sidebar).\")\n",
        "else:\n",
        "    print(f\"--- Starting image extraction from {PDF_FILE_NAME} (Pages {START_PAGE} to {END_PAGE}) ---\")\n",
        "    try:\n",
        "        # Open the PDF file\n",
        "        doc = fitz.open(PDF_FILE_NAME)\n",
        "\n",
        "        # Page numbers in fitz are 0-indexed, so we subtract 1\n",
        "        start_index = START_PAGE - 1\n",
        "        end_index = END_PAGE - 1\n",
        "\n",
        "        if end_index >= doc.page_count:\n",
        "            print(f\"Warning: PDF only has {doc.page_count} pages. Extracting up to the last page.\")\n",
        "            end_index = doc.page_count - 1\n",
        "\n",
        "        # Iterate through the specified pages\n",
        "        for page_num in range(start_index, end_index + 1):\n",
        "            page = doc.load_page(page_num)\n",
        "\n",
        "            # Set a matrix for high resolution (zoom factor based on DPI/72)\n",
        "            zoom = DPI / 72\n",
        "            matrix = fitz.Matrix(zoom, zoom)\n",
        "\n",
        "            # Render the page to a high-resolution pixmap (image)\n",
        "            pix = page.get_pixmap(matrix=matrix, alpha=False)\n",
        "\n",
        "            # Save the pixmap as a high-quality image file (e.g., PNG)\n",
        "            image_filename = os.path.join(OUTPUT_FOLDER, f'page_{page_num + 1:02d}.png')\n",
        "            pix.save(image_filename)\n",
        "\n",
        "            print(f\"Saved {image_filename}\")\n",
        "\n",
        "        doc.close()\n",
        "        print(f\"--- Extraction complete. Images saved in '{OUTPUT_FOLDER}/' directory. ---\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during PDF processing: {e}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X84bf4Kyvl1e"
      },
      "source": [
        "Now let's OCR this using the Google Vision API. We will create a txt file of the extracted text, and print the first 200 words just to make sure it works."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTZKezIAvmPU",
        "outputId": "2321a68d-0af3-40ba-e7f4-9f0bc167230e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyMuPDF in /usr/local/lib/python3.12/dist-packages (1.26.7)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (12.1.0)\n",
            "Requirement already satisfied: google-cloud-vision in /usr/local/lib/python3.12/dist-packages (3.12.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.5)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision) (2.29.0)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-cloud-vision) (2.47.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-vision) (1.76.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-vision) (1.27.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-vision) (5.29.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2026.1.4)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision) (1.72.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision) (1.71.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-vision) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-vision) (4.9.1)\n",
            "Requirement already satisfied: typing-extensions~=4.12 in /usr/local/lib/python3.12/dist-packages (from grpcio<2.0.0,>=1.33.2->google-cloud-vision) (4.15.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-vision) (0.6.2)\n",
            "Authentication successful using local JSON file.\n",
            "\n",
            "Starting image extraction from confuciussinarum00conf_0.pdf...\n",
            "Image extraction complete.\n",
            "\n",
            "Starting OCR process on 8 images...\n",
            "\n",
            "--- OCR Pipeline Finished ---\n",
            "All extracted text has been saved to: Extracted_OCR_Text.txt\n",
            "\n",
            "============================================================\n",
            "FIRST 200 WORDS OF EXTRACTED TEXT:\n",
            "============================================================\n",
            "OCR Results for confuciussinarum00conf_0.pdf (Pages 7 to 14) ============================================================ --- Start of OCR from page_07.png --- CONFUCIUS SINAR UM PHILOSOPHUS. SIVE SCIENTIA SINENSIS Studio Opera LATINE EXPOSIT A. > PROSPERI INTORCETTA, CHRISTIANI HERDT RICH, FRANCISCI ROUGEMONT, PHILIPPI COUPLET, J U S S U LUDOVICI S Patrum Societa- tis JESU. MAGNI Eximio Miffionum Orientalium & Litterarie Reipublicæ bono E BIBLIOTHECA REGIA IN LUCEM PRODIT, ADJECT A EST TABULA CHRONOLOGICA SINICE MONARCHIE AB HUJUS EXORDIO AD HÆC USQUE TEMPORA, PARISIIS, Apud DANIELEM HORTHEMELS, viâ Jacobæâ, fub Mæcenate. M. D C. LXXXVI I. CUM PRIVILEGIO REGIS --- End of OCR from page_07.png --- --- Start of OCR from page_08.png --- COMENCING MUARIE 2UH1020JIHT 37 13 212 M3M12 AT 1 IKDAN Aldo May TO i lood 17 --- End of OCR from page_08.png --- --- Start of OCR from page_09.png --- OT2 1 LUDOVICO MAGNO REGI CHRISTIANISSIMO. A P MOSTQUAM ab altero non ita pridem Orbe, Majeftatem tuam, REX MAGNE, adierunt cum infigni apparatu potentiffimi Siamenfium Regis Legati, exciti videlicet virtutis ac fapien- tia tua famâ, qua remotiffimas in oras jamdudum penetra- verat; adeft nunc ab extremo procul Oriente Princeps è A ij --- End of OCR from page_09.png --- --- Start of OCR\n",
            "\n",
            "[... Text truncated for display purposes ...]\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# --- Google Colab Complete OCR Pipeline (FIXED CODE) ---\n",
        "\n",
        "# 1. Install necessary libraries (Run this first!)\n",
        "!pip install PyMuPDF Pillow google-cloud-vision requests\n",
        "\n",
        "import io\n",
        "import os\n",
        "import json\n",
        "import fitz # PyMuPDF\n",
        "from PIL import Image\n",
        "from google.cloud import vision\n",
        "from google.oauth2 import service_account\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# --- Configuration Variables\n",
        "# -----------------------------------------------------------\n",
        "JSON_FILE_PATH = '/content/renaissance-ocr-4aabe5b8dc65.json'\n",
        "PDF_FILE_NAME = 'confuciussinarum00conf_0.pdf'\n",
        "START_PAGE = 7\n",
        "END_PAGE = 14\n",
        "DPI = 300 # High DPI for quality OCR\n",
        "OUTPUT_IMAGE_FOLDER = 'extracted_images'\n",
        "OUTPUT_TEXT_FILE = 'Extracted_OCR_Text.txt'\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 2. Authenticate using the local service account key file\n",
        "#    >>> THIS IS WHERE 'client' IS DEFINED <<<\n",
        "# -----------------------------------------------------------\n",
        "try:\n",
        "    if not os.path.exists(JSON_FILE_PATH):\n",
        "        raise FileNotFoundError(f\"Credentials file not found at: {JSON_FILE_PATH}\")\n",
        "\n",
        "    credentials = service_account.Credentials.from_service_account_file(JSON_FILE_PATH)\n",
        "    # The 'client' variable is defined here and is accessible globally within this script\n",
        "    client = vision.ImageAnnotatorClient(credentials=credentials)\n",
        "    print(\"Authentication successful using local JSON file.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Authentication failed: {e}\")\n",
        "    exit()\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 3. Define the function (The function body was merged into __main__ in the last script for simplicity)\n",
        "# -----------------------------------------------------------\n",
        "# The function was simplified and integrated into the main execution block in the prior response,\n",
        "# which required the 'client' variable to be defined *before* the __main__ block ran.\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 4. Main execution block: Extract images first, then OCR them\n",
        "# -----------------------------------------------------------\n",
        "if __name__ == '__main__':\n",
        "    # --- Image Extraction Phase ---\n",
        "    if not os.path.exists(OUTPUT_IMAGE_FOLDER):\n",
        "        os.makedirs(OUTPUT_IMAGE_FOLDER)\n",
        "\n",
        "    if os.path.exists(PDF_FILE_NAME):\n",
        "        print(f\"\\nStarting image extraction from {PDF_FILE_NAME}...\")\n",
        "        doc = fitz.open(PDF_FILE_NAME)\n",
        "        start_index = START_PAGE - 1\n",
        "        end_index = min(END_PAGE - 1, doc.page_count - 1)\n",
        "        image_files_to_process = []\n",
        "\n",
        "        for page_num in range(start_index, end_index + 1):\n",
        "            page = doc.load_page(page_num)\n",
        "            zoom = DPI / 72\n",
        "            matrix = fitz.Matrix(zoom, zoom)\n",
        "            pix = page.get_pixmap(matrix=matrix, alpha=False)\n",
        "            image_filename = os.path.join(OUTPUT_IMAGE_FOLDER, f'page_{page_num + 1:02d}.png')\n",
        "            pix.save(image_filename)\n",
        "            image_files_to_process.append(image_filename)\n",
        "        doc.close()\n",
        "        print(\"Image extraction complete.\")\n",
        "\n",
        "        # --- OCR Phase ---\n",
        "        print(f\"\\nStarting OCR process on {len(image_files_to_process)} images...\")\n",
        "\n",
        "        full_document_text = \"\"\n",
        "\n",
        "        with open(OUTPUT_TEXT_FILE, 'w', encoding='utf-8') as f_out:\n",
        "            header = f\"OCR Results for {PDF_FILE_NAME} (Pages {START_PAGE} to {END_PAGE})\\n\" + \"=\" * 60 + \"\\n\"\n",
        "            f_out.write(header)\n",
        "            full_document_text += header\n",
        "\n",
        "            for image_file in image_files_to_process:\n",
        "                # This section now successfully uses the 'client' variable defined above\n",
        "                with io.open(image_file, 'rb') as image_file_handle:\n",
        "                    content = image_file_handle.read()\n",
        "                image = vision.Image(content=content)\n",
        "                image_context = vision.ImageContext(language_hints=['la'])\n",
        "                api_response = client.document_text_detection(image=image, image_context=image_context)\n",
        "\n",
        "                page_text = api_response.full_text_annotation.text or \"\"\n",
        "\n",
        "                if page_text:\n",
        "                    section_text = f\"\\n\\n--- Start of OCR from {os.path.basename(image_file)} ---\\n\\n{page_text}\\n\\n--- End of OCR from {os.path.basename(image_file)} ---\\n\\n\"\n",
        "                    f_out.write(section_text)\n",
        "                    full_document_text += section_text\n",
        "\n",
        "\n",
        "        print(f\"\\n--- OCR Pipeline Finished ---\")\n",
        "        print(f\"All extracted text has been saved to: {OUTPUT_TEXT_FILE}\")\n",
        "\n",
        "        # --- Print First 200 Words ---\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"FIRST 200 WORDS OF EXTRACTED TEXT:\")\n",
        "        print(\"=\" * 60)\n",
        "        words = full_document_text.split()\n",
        "        print(' '.join(words[:200]))\n",
        "        if len(words) > 200:\n",
        "            print(\"\\n[... Text truncated for display purposes ...]\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "\n",
        "    else:\n",
        "        print(f\"Could not find PDF file '{PDF_FILE_NAME}'. Please upload it to Colab.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsLjLPziyxEq"
      },
      "source": [
        "Now, let's try Google Gemini model through the Vertext API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vadpIHi8iKb"
      },
      "source": [
        "First though let's check we can access the API by using it like a chatbot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rw50mSva8meL",
        "outputId": "29510957-e421-4854-afed-d30d5c797dee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/vertexai/generative_models/_generative_models.py:433: UserWarning: This feature is deprecated as of June 24, 2025 and will be removed on June 24, 2026. For details, see https://cloud.google.com/vertex-ai/generative-ai/docs/deprecations/genai-vertexai-sdk.\n",
            "  warning_logs.show_deprecation_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini Model 'gemini-2.5-flash' initialized successfully.\n",
            "\n",
            "Sending prompt to Gemini: 'What is the capital of France?'\n",
            "\n",
            "========================================\n",
            "--- Gemini Chatbox Answer ---\n",
            "========================================\n",
            "Question: What is the capital of France?\n",
            "Answer: The capital of France is **Paris**.\n",
            "========================================\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import vertexai\n",
        "from vertexai.generative_models import GenerativeModel, Part, Image\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# --- Configuration Variables: UPDATE THESE ---\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "# REPLACE THIS with the path to your service account JSON key file.\n",
        "# Example: '/Users/YourUser/Desktop/your-project-key.json'\n",
        "JSON_FILE_PATH = '/content/renaissance-ocr-4aabe5b8dc65.json'\n",
        "\n",
        "# REPLACE THESE with your specific project details\n",
        "PROJECT_ID = 'renaissance-ocr'\n",
        "LOCATION = 'global'\n",
        "GEMINI_MODEL = 'gemini-2.5-flash'\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 1. Authenticate and Initialize the Vertex AI Client\n",
        "# -----------------------------------------------------------\n",
        "try:\n",
        "    if not os.path.exists(JSON_FILE_PATH):\n",
        "        raise FileNotFoundError(f\"Credentials file not found at: {JSON_FILE_PATH}\")\n",
        "\n",
        "    # Set the environment variable required for authentication\n",
        "    os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = JSON_FILE_PATH\n",
        "\n",
        "    # Initialize the Vertex AI SDK\n",
        "    vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
        "\n",
        "    # Load the specific model instance\n",
        "    model = GenerativeModel(GEMINI_MODEL)\n",
        "    print(f\"Gemini Model '{GEMINI_MODEL}' initialized successfully.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Authentication or client initialization failed: {e}\")\n",
        "    # Exit the script if initialization fails\n",
        "    exit()\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 2. Define the function to ask a simple text question\n",
        "# -----------------------------------------------------------\n",
        "def ask_question(question_text):\n",
        "    \"\"\"Sends a simple text prompt to the Gemini API and returns the response.\"\"\"\n",
        "    print(f\"\\nSending prompt to Gemini: '{question_text}'\")\n",
        "\n",
        "    # The 'contents' list contains only the text prompt for a chat\n",
        "    contents = [question_text]\n",
        "\n",
        "    try:\n",
        "        # Generate content for a text-only prompt\n",
        "        response = model.generate_content(contents)\n",
        "        answer = response.text or \"No answer received.\"\n",
        "        return answer\n",
        "    except Exception as e:\n",
        "        print(f\"API call failed: {e}\")\n",
        "        return \"Error during API call.\"\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 3. Main execution to ask the capital of France\n",
        "# -----------------------------------------------------------\n",
        "if __name__ == '__main__':\n",
        "    # Define the specific question you want to ask\n",
        "    user_question = \"What is the capital of France?\"\n",
        "\n",
        "    # Get the answer using the function\n",
        "    capital_city = ask_question(user_question)\n",
        "\n",
        "    # Print the final result\n",
        "    print(\"\\n\" + \"=\" * 40)\n",
        "    print(\"--- Gemini Chatbox Answer ---\")\n",
        "    print(\"=\" * 40)\n",
        "    print(f\"Question: {user_question}\")\n",
        "    print(f\"Answer: {capital_city}\")\n",
        "    print(\"=\" * 40)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_5-LR_W8nLz"
      },
      "source": [
        "Now, let's try our task. This may take some time..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvUpCdVz9lMq",
        "outputId": "c0fc7184-105e-43c3-dd37-b72e84003d8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: google-cloud-aiplatform in /usr/local/lib/python3.12/dist-packages (1.134.0)\n",
            "Requirement already satisfied: PyMuPDF in /usr/local/lib/python3.12/dist-packages (1.26.7)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (12.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.5)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (2.29.0)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.47.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (2.47.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (1.27.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (5.29.5)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (25.0)\n",
            "Requirement already satisfied: google-cloud-storage<4.0.0,>=1.32.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (3.8.0)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (3.40.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0,>=1.3.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (1.16.0)\n",
            "Requirement already satisfied: google-genai<2.0.0,>=1.59.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (1.60.0)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (2.12.3)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (4.15.0)\n",
            "Requirement already satisfied: docstring_parser<1 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2026.1.4)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (1.72.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (1.76.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (1.71.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.47.0->google-cloud-aiplatform) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.47.0->google-cloud-aiplatform) (4.9.1)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.1 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform) (2.5.0)\n",
            "Requirement already satisfied: google-resumable-media<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform) (2.8.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform) (2.9.0.post0)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0,>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-resource-manager<3.0.0,>=1.3.3->google-cloud-aiplatform) (0.14.3)\n",
            "Requirement already satisfied: google-crc32c<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage<4.0.0,>=1.32.0->google-cloud-aiplatform) (1.8.0)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform) (4.12.1)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform) (0.28.1)\n",
            "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform) (9.1.2)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform) (15.0.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform) (1.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->google-cloud-aiplatform) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->google-cloud-aiplatform) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->google-cloud-aiplatform) (0.4.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform) (0.16.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.47.0->google-cloud-aiplatform) (0.6.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3.0.0,>=2.8.2->google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "# --- Google Colab OCR Pipeline using Gemini (Vertex AI) ---\n",
        "\n",
        "# 1. Install necessary libraries\n",
        "!pip install google-cloud-aiplatform PyMuPDF Pillow requests --upgrade\n",
        "\n",
        "import io\n",
        "import os\n",
        "import json\n",
        "# No need for PIL import if we use load_from_file\n",
        "import vertexai\n",
        "from vertexai.generative_models import GenerativeModel, Part, Image\n",
        "# Import the preview namespace as a fallback\n",
        "from vertexai.preview.generative_models import Image as PreviewImage\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# --- Configuration Variables: UPDATE THESE ---\n",
        "# -----------------------------------------------------------\n",
        "JSON_FILE_PATH = '/content/renaissance-ocr-4aabe5b8dc65.json'\n",
        "OUTPUT_IMAGE_FOLDER = 'extracted_images'\n",
        "OUTPUT_TEXT_FILE = 'Extracted_OCR_Text_Gemini.txt'\n",
        "PROJECT_ID = 'renaissance-ocr'\n",
        "LOCATION = 'global'\n",
        "GEMINI_MODEL = 'gemini-2.5-flash'\n",
        "OCR_PROMPT = \"Transcribe all visible text from this image. Do not print any comments or reasoning. Just the text from the book reconnecting any words that are split across lines and hyphenated. For context, it is a Latin book about China. Please correct the OCR to the most plausible Latin without being too creative. Standardize Latin spellings to OLD. Do not include page numbers from the image or anything apart from the text.\"\n",
        "# -----------------------------------------------------------\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anbpic6NyxRR",
        "outputId": "367cb4b9-0730-42cc-8632-c9ec06eb434c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gemini Model 'gemini-2.5-flash' initialized successfully.\n",
            "\n",
            "Starting Gemini OCR process on 8 images...\n",
            "  -> Processing image: extracted_images/page_07.png\n",
            "  -> Processing image: extracted_images/page_08.png\n",
            "  -> Processing image: extracted_images/page_09.png\n",
            "  -> Processing image: extracted_images/page_10.png\n",
            "  -> Processing image: extracted_images/page_11.png\n",
            "  -> Processing image: extracted_images/page_12.png\n",
            "  -> Processing image: extracted_images/page_13.png\n",
            "  -> Processing image: extracted_images/page_14.png\n",
            "\n",
            "--- Gemini OCR Pipeline Finished ---\n",
            "All extracted text has been saved to: Extracted_OCR_Text_Gemini.txt\n",
            "\n",
            "============================================================\n",
            "FIRST 200 WORDS OF EXTRACTED TEXT (Gemini):\n",
            "============================================================\n",
            "Gemini OCR Results for Pages 7 to 14 ============================================================ --- Start of OCR from page_07.png --- CONFUCIUS SINARUM PHILOSOPHUS, SIVE SCIENTIA SINENSIS LATINE EXPOSITA. Studio et Opera PROSPERI INTORCETTA, CHRISTIANI HERDTRICH, FRANCISCI ROUGEMONT, PHILIPPI COUPLET, Patrum Societatis IESU. IUSSU LUDOVICI MAGNI Eximio Missionum Orientalium et Litterariae Reipublicae bono E BIBLIOTHECA REGIA IN LUCEM PRODIT. ADIECTA EST TABULA CHRONOLOGICA SINICE MONARCHIA AB HUIUS EXORDIO AD HAEC USQUE TEMPORA, PARISIIS, Apud DANIELEM HORTHEMELS, via Iacobae, sub Maecenate. M. DC. LXXXVII. CUM PRIVILEGIO REGIS. --- End of OCR from page_07.png --- --- Start of OCR from page_08.png --- CONFUCIUS SINARUM PHILOSOPHUS SIVE SCIENTIA SINENSIUM LATINE EXPOSITA STUDIO ET OPERA PROLEGOMENA AD DOCTRINAM IPSIUS LIBRI QUATTUOR I. IUNGLUNG II. TA HIO III. LUN YU IV. MANG TZEU PARISIIS APUD SEBASTIANUM MABRE-CRAMOISY TYPOGRAPHUM REGIS & ACADEMIAE SCIENTIARUM M.DC.LXXXVII. --- End of OCR from page_08.png --- --- Start of OCR from page_09.png --- LUDOVICO MAGNO REGI CHRISTIANISSIMO. POSTQUAM ab altero non ita pridem Orbe, Maiestatem tuam, REX MAGNE, adierunt cum insigni apparatu potentissimi Siamensium Regis Legati, exciti videlicet virtutis ac sapientia tua fama, qua remotissimas in oras iam dudum penetraverat; adest nunc ab extremo procul Oriente Princeps e --- End of OCR from page_09.png --- ---\n",
            "\n",
            "[... Text truncated for display purposes ...]\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 2. Authenticate and Initialize the Vertex AI Client\n",
        "# -----------------------------------------------------------\n",
        "try:\n",
        "    if not os.path.exists(JSON_FILE_PATH):\n",
        "        raise FileNotFoundError(f\"Credentials file not found at: {JSON_FILE_PATH}\")\n",
        "\n",
        "    os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = JSON_FILE_PATH\n",
        "    vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
        "    model = GenerativeModel(GEMINI_MODEL)\n",
        "    print(f\"Gemini Model '{GEMINI_MODEL}' initialized successfully.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Authentication or client initialization failed: {e}\")\n",
        "    exit()\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 3. Define the function to perform OCR using the Gemini Model (FIXED AGAIN)\n",
        "# -----------------------------------------------------------\n",
        "def process_image_with_gemini(image_path, output_file_handle):\n",
        "    \"\"\"Processes a local image file using the Gemini multimodal model.\"\"\"\n",
        "\n",
        "    print(f\"  -> Processing image: {image_path}\")\n",
        "\n",
        "    try:\n",
        "        # Use Image.load_from_file which is the most reliable current method\n",
        "        vertex_ai_image = Image.load_from_file(image_path)\n",
        "    except AttributeError:\n",
        "        # Fallback for very old library versions using the preview namespace\n",
        "        vertex_ai_image = PreviewImage.load_from_file(image_path)\n",
        "    except Exception as e:\n",
        "        print(f\"Could not load image file {image_path}: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "    # Send the prompt and the image to the model\n",
        "    contents = [OCR_PROMPT, vertex_ai_image]\n",
        "\n",
        "    # Generate content (perform the OCR)\n",
        "    try:\n",
        "        response = model.generate_content(contents)\n",
        "        full_text = response.text or \"\"\n",
        "    except Exception as e:\n",
        "        print(f\"API call failed for {image_path}: {e}\")\n",
        "        full_text = \"\"\n",
        "\n",
        "    if full_text:\n",
        "        section_text = f\"\\n\\n--- Start of OCR from {os.path.basename(image_path)} ---\\n\\n{full_text}\\n\\n--- End of OCR from {os.path.basename(image_path)} ---\\n\\n\"\n",
        "        output_file_handle.write(section_text)\n",
        "        return section_text\n",
        "    else:\n",
        "        print(f'  -> No text detected in {image_path}.')\n",
        "        return \"\"\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 4. Main execution block: Process images in the folder\n",
        "# -----------------------------------------------------------\n",
        "if __name__ == '__main__':\n",
        "    if not os.path.exists(OUTPUT_IMAGE_FOLDER):\n",
        "        print(f\"Image folder '{OUTPUT_IMAGE_FOLDER}' not found. Please run the previous PDF extraction code first.\")\n",
        "        exit()\n",
        "\n",
        "    image_files_to_process = sorted([os.path.join(OUTPUT_IMAGE_FOLDER, f) for f in os.listdir(OUTPUT_IMAGE_FOLDER) if f.endswith('.png') or f.endswith('.jpeg')])\n",
        "\n",
        "    if not image_files_to_process:\n",
        "        print(\"No images found in the 'extracted_images' folder.\")\n",
        "        exit()\n",
        "\n",
        "    print(f\"\\nStarting Gemini OCR process on {len(image_files_to_process)} images...\")\n",
        "\n",
        "    full_document_text = \"\"\n",
        "    with open(OUTPUT_TEXT_FILE, 'w', encoding='utf-8') as f_out:\n",
        "        header = f\"Gemini OCR Results for Pages 7 to 14\\n\" + \"=\" * 60 + \"\\n\"\n",
        "        f_out.write(header)\n",
        "        full_document_text += header\n",
        "\n",
        "        for image_file in image_files_to_process:\n",
        "            processed_text = process_image_with_gemini(image_file, f_out)\n",
        "            full_document_text += processed_text\n",
        "\n",
        "    print(f\"\\n--- Gemini OCR Pipeline Finished ---\")\n",
        "    print(f\"All extracted text has been saved to: {OUTPUT_TEXT_FILE}\")\n",
        "\n",
        "    # --- Print First 200 Words ---\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"FIRST 200 WORDS OF EXTRACTED TEXT (Gemini):\")\n",
        "    print(\"=\" * 60)\n",
        "    words = full_document_text.split()\n",
        "    print(' '.join(words[:200]))\n",
        "    if len(words) > 200:\n",
        "        print(\"\\n[... Text truncated for display purposes ...]\")\n",
        "    print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZ6TFwO9EcSh"
      },
      "source": [
        "Any alternative method might be to OCR with Google Vision, and then correct the OCR with Gemini AI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbSFoUYjEjfw",
        "outputId": "c0e5ad79-e880-4d7e-e63d-0f1be5b42cfd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gemini Model 'gemini-2.5-flash' initialized successfully.\n",
            "\n",
            "Starting OCR correction process on Extracted_OCR_Text.txt...\n",
            "  -> Processing chunk 1...\n",
            "\n",
            "--- Gemini OCR Correction Pipeline Finished ---\n",
            "All corrected text has been saved to: Corrected_OCR_Text.txt\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from vertexai.generative_models import GenerativeModel, Part\n",
        "import vertexai\n",
        "\n",
        "# --- Configuration Constants (Define these as per your environment) ---\n",
        "# Replace with your actual project details\n",
        "PROJECT_ID = 'renaissance-ocr'\n",
        "LOCATION = 'global'\n",
        "GEMINI_MODEL = 'gemini-2.5-flash' # A fast model suitable for text processing\n",
        "JSON_FILE_PATH = 'renaissance-ocr-4aabe5b8dc65.json' # Path to your GCP credentials file\n",
        "\n",
        "INPUT_TEXT_FILE = 'Extracted_OCR_Text.txt'\n",
        "OUTPUT_CORRECTED_FILE = 'Corrected_OCR_Text.txt'\n",
        "\n",
        "# Define the chunk size in characters (adjust as needed to fit the model's context window)\n",
        "# 10,000 characters is a safe starting point.\n",
        "CHUNK_SIZE = 10000\n",
        "\n",
        "# Define the prompt for the AI\n",
        "CORRECTION_PROMPT = \"\"\"\n",
        "You are an expert proofreader of early modern Latin. TASK: Correct ONLY OCR errors in the input text. Do not rewrite or alter authentic early modern usage. RULES: 1. Preserve the original wording, grammar, and syntax. Fix ONLY: - misread letters - broken or split words - incorrect or missing spacing - duplicated characters - corrupted punctuation caused by OCR 2. Apply minimal normalization (OLD conventions): - u = vowel, v = consonant - use i only (never j) - expand æ → ae, œ → oe - replace & or &amp; with et Do NOT modernize vocabulary or regularize historical spellings unless the form is clearly an OCR mistake. 3. De hyphenate all words broken across line breaks: - remove hyphens that occur at the end of a line, - join the two fragments into a single continuous word, - and correct any spacing errors created by the line break. Do NOT remove hyphens that belong to real Latin compounds. Preserve all paragraph breaks and capitalization. Do not add new punctuation. 4. Keep all paragraph breaks and capitalization exactly as in the input. 5. Remove page furniture only when clearly not part of the running text: examples: “A ij”, “EPISTOLA.”, catchwords, signature marks. 6. Preserve Chinese or other exotic romanizations exactly as printed once corrected. Do NOT “improve,” standardize, or re interpret them (e.g., keep forms like “Tai Ki Gin”). 7. Output ONLY the corrected Latin text. Do NOT add commentary, explanation, or formatting.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 1. Authenticate and Initialize the Vertex AI Client\n",
        "# -----------------------------------------------------------\n",
        "try:\n",
        "    if not os.path.exists(JSON_FILE_PATH):\n",
        "        # In Colab, you might need to upload this file or use Colab secrets\n",
        "        print(f\"Credentials file not found at: {JSON_FILE_PATH}\")\n",
        "        # Placeholder for Colab file upload guidance\n",
        "        # from google.colab import files\n",
        "        # files.upload()\n",
        "        # Then update JSON_FILE_PATH accordingly\n",
        "        raise FileNotFoundError(f\"Credentials file not found: {JSON_FILE_PATH}\")\n",
        "\n",
        "    os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = JSON_FILE_PATH\n",
        "    vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
        "    model = GenerativeModel(GEMINI_MODEL)\n",
        "    print(f\"Gemini Model '{GEMINI_MODEL}' initialized successfully.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Authentication or client initialization failed: {e}\")\n",
        "    exit()\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 2. Define a function to read a file in chunks\n",
        "# -----------------------------------------------------------\n",
        "def read_in_chunks(file_path, chunk_size=CHUNK_SIZE):\n",
        "    \"\"\"Reads a large text file in chunks of a specified size.\"\"\"\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        while True:\n",
        "            chunk = f.read(chunk_size)\n",
        "            if not chunk:\n",
        "                break\n",
        "            yield chunk\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 3. Define a function to correct a chunk using Gemini AI\n",
        "# -----------------------------------------------------------\n",
        "def correct_ocr_chunk_with_gemini(chunk_text):\n",
        "    \"\"\"Sends a text chunk to Gemini for correction and returns clean text.\"\"\"\n",
        "\n",
        "    # Send the prompt and the text chunk to the model\n",
        "    contents = [\n",
        "        CORRECTION_PROMPT,\n",
        "        \"Here is the text to correct:\",\n",
        "        chunk_text\n",
        "    ]\n",
        "\n",
        "    try:\n",
        "        response = model.generate_content(contents)\n",
        "        # We explicitly ask the model to only return the text\n",
        "        corrected_text = response.text.strip() or \"\"\n",
        "        return corrected_text\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"API call failed for a chunk: {e}\")\n",
        "        return chunk_text # Return original text if API fails\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 4. Main execution block: Chunk, Process, and Save\n",
        "# -----------------------------------------------------------\n",
        "if __name__ == '__main__':\n",
        "    if not os.path.exists(INPUT_TEXT_FILE):\n",
        "        print(f\"Input file '{INPUT_TEXT_FILE}' not found. Ensure it is uploaded or available.\")\n",
        "        exit()\n",
        "\n",
        "    print(f\"\\nStarting OCR correction process on {INPUT_TEXT_FILE}...\")\n",
        "\n",
        "    # Open the output file in write mode\n",
        "    with open(OUTPUT_CORRECTED_FILE, 'w', encoding='utf-8') as f_out:\n",
        "        chunk_count = 0\n",
        "        # Iterate over the input file in chunks\n",
        "        for chunk in read_in_chunks(INPUT_TEXT_FILE, CHUNK_SIZE):\n",
        "            chunk_count += 1\n",
        "            print(f\"  -> Processing chunk {chunk_count}...\")\n",
        "\n",
        "            # Correct the chunk using Gemini\n",
        "            corrected_chunk = correct_ocr_chunk_with_gemini(chunk)\n",
        "\n",
        "            # Write the corrected chunk directly to the output file\n",
        "            if corrected_chunk:\n",
        "                f_out.write(corrected_chunk + \"\\n\\n\") # Add newlines between chunks for readability\n",
        "            else:\n",
        "                print(f'  -> Chunk {chunk_count} returned no corrected text.')\n",
        "\n",
        "    print(f\"\\n--- Gemini OCR Correction Pipeline Finished ---\")\n",
        "    print(f\"All corrected text has been saved to: {OUTPUT_CORRECTED_FILE}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_SVf2PXL1Sk"
      },
      "source": [
        "Now, let's try to start from Archive.org 's own bad OCR, and see if we can correct it using Gemini AI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "FZEF5IYUNQue",
        "outputId": "30b810ae-21a6-4cc9-fbe0-275199aa76dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gemini Model 'gemini-2.5-flash' initialized successfully.\n",
            "\n",
            "Starting OCR correction process on confuciussinarum00conf_0_djvu.txt...\n",
            "  -> Processing chunk 1...\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2840709378.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0;31m# Correct the chunk using Gemini\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0mcorrected_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorrect_ocr_chunk_with_gemini\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;31m# Write the corrected chunk directly to the output file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2840709378.py\u001b[0m in \u001b[0;36mcorrect_ocr_chunk_with_gemini\u001b[0;34m(chunk_text)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0;31m# We explicitly ask the model to only return the text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mcorrected_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/vertexai/generative_models/_generative_models.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, contents, generation_config, safety_settings, tools, tool_config, labels, stream)\u001b[0m\n\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             return self._generate_content(\n\u001b[0m\u001b[1;32m    711\u001b[0m                 \u001b[0mcontents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m                 \u001b[0mgeneration_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgeneration_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/vertexai/generative_models/_generative_models.py\u001b[0m in \u001b[0;36m_generate_content\u001b[0;34m(self, contents, generation_config, safety_settings, tools, tool_config, labels)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m         )\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mgapic_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prediction_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgapic_response\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/aiplatform_v1/services/prediction_service/client.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m   2318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2319\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2320\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m   2321\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2322\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/aiplatform_v1/services/prediction_service/transports/rest.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m   1746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1747\u001b[0m             \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1748\u001b[0;31m             response = PredictionServiceRestTransport._GenerateContent._get_response(\n\u001b[0m\u001b[1;32m   1749\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_host\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1750\u001b[0m                 \u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/aiplatform_v1/services/prediction_service/transports/rest.py\u001b[0m in \u001b[0;36m_get_response\u001b[0;34m(host, metadata, query_params, session, timeout, transcoded_request, body)\u001b[0m\n\u001b[1;32m   1661\u001b[0m             \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1662\u001b[0m             \u001b[0mheaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Content-Type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"application/json\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1663\u001b[0;31m             response = getattr(session, method)(\n\u001b[0m\u001b[1;32m   1664\u001b[0m                 \u001b[0;34m\"{host}{uri}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muri\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1665\u001b[0m                 \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    635\u001b[0m         \"\"\"\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"POST\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/auth/transport/requests.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, data, headers, max_allowed_time, timeout, **kwargs)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTimeoutGuard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining_time\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mguard\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             \u001b[0m_helpers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LOGGER\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m             response = super(AuthorizedSession, self).request(\n\u001b[0m\u001b[1;32m    544\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    645\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;31m# Make the request on the HTTPConnection object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m             response = self._make_request(\n\u001b[0m\u001b[1;32m    788\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;31m# Receive the response from the server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;31m# Get the response from http.client.HTTPConnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m         \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1428\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1430\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1431\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    718\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1249\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1251\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1101\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1103\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import os\n",
        "from vertexai.generative_models import GenerativeModel, Part\n",
        "import vertexai\n",
        "\n",
        "# --- Configuration Constants (Define these as per your environment) ---\n",
        "# Replace with your actual project details\n",
        "PROJECT_ID = 'renaissance-ocr'\n",
        "LOCATION = 'global'\n",
        "GEMINI_MODEL = 'gemini-2.5-flash' # A fast model suitable for text processing\n",
        "JSON_FILE_PATH = 'renaissance-ocr-4aabe5b8dc65.json' # Path to your GCP credentials file\n",
        "\n",
        "INPUT_TEXT_FILE = 'confuciussinarum00conf_0_djvu.txt'\n",
        "OUTPUT_CORRECTED_FILE = 'Corrected_OCR_Text_from_Archive2.txt'\n",
        "\n",
        "# Define the chunk size in characters (adjust as needed to fit the model's context window)\n",
        "# 30,000 characters is a safe starting point.\n",
        "CHUNK_SIZE = 30000\n",
        "\n",
        "# Define the prompt for the AI\n",
        "CORRECTION_PROMPT = \"\"\"\n",
        "You are an expert proofreader of early modern Latin. TASK: Correct ONLY OCR errors in the input text. Do not rewrite or alter authentic early modern usage. RULES: 1. Preserve the original wording, grammar, and syntax. Fix ONLY: - misread letters - broken or split words - incorrect or missing spacing - duplicated characters - corrupted punctuation caused by OCR 2. Apply minimal normalization (OLD conventions): - u = vowel, v = consonant - use i only (never j) - expand æ → ae, œ → oe - replace & or &amp; with et Do NOT modernize vocabulary or regularize historical spellings unless the form is clearly an OCR mistake. 3. This is very important: De hyphenate all words broken across line breaks: - remove hyphens that occur at the end of a line, - join the two fragments into a single continuous word, - and correct any spacing errors created by the line break. Also remove hyphens that belong to real Latin compounds, as hyphens are irrelevant. Do not add new punctuation. Do not retain paragraph breaks; just produce continuous text. 4. Keep all paragraph breaks and capitalization exactly as in the input. 5. Remove page furniture only when clearly not part of the running text: examples: “A ij”, “EPISTOLA.”, catchwords, signature marks. 6. Preserve Chinese or other exotic romanizations exactly as printed once corrected. Do NOT “improve,” standardize, or re interpret them (e.g., keep forms like “Tai Ki Gin”). 7. Output ONLY the corrected Latin text. Do NOT add commentary, explanation, or formatting.\n",
        "\"\"\"\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 1. Authenticate and Initialize the Vertex AI Client\n",
        "# -----------------------------------------------------------\n",
        "try:\n",
        "    if not os.path.exists(JSON_FILE_PATH):\n",
        "        # In Colab, you might need to upload this file or use Colab secrets\n",
        "        print(f\"Credentials file not found at: {JSON_FILE_PATH}\")\n",
        "        # Placeholder for Colab file upload guidance\n",
        "        # from google.colab import files\n",
        "        # files.upload()\n",
        "        # Then update JSON_FILE_PATH accordingly\n",
        "        raise FileNotFoundError(f\"Credentials file not found: {JSON_FILE_PATH}\")\n",
        "\n",
        "    os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = JSON_FILE_PATH\n",
        "    vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
        "    model = GenerativeModel(GEMINI_MODEL)\n",
        "    print(f\"Gemini Model '{GEMINI_MODEL}' initialized successfully.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Authentication or client initialization failed: {e}\")\n",
        "    exit()\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 2. Define a function to read a file in chunks\n",
        "# -----------------------------------------------------------\n",
        "def read_in_chunks(file_path, chunk_size=CHUNK_SIZE):\n",
        "    \"\"\"Reads a large text file in chunks of a specified size.\"\"\"\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        while True:\n",
        "            chunk = f.read(chunk_size)\n",
        "            if not chunk:\n",
        "                break\n",
        "            yield chunk\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 3. Define a function to correct a chunk using Gemini AI\n",
        "# -----------------------------------------------------------\n",
        "def correct_ocr_chunk_with_gemini(chunk_text):\n",
        "    \"\"\"Sends a text chunk to Gemini for correction and returns clean text.\"\"\"\n",
        "\n",
        "    # Send the prompt and the text chunk to the model\n",
        "    contents = [\n",
        "        CORRECTION_PROMPT,\n",
        "        chunk_text\n",
        "    ]\n",
        "\n",
        "    try:\n",
        "        response = model.generate_content(contents)\n",
        "        # We explicitly ask the model to only return the text\n",
        "        corrected_text = response.text.strip() or \"\"\n",
        "        return corrected_text\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"API call failed for a chunk: {e}\")\n",
        "        return chunk_text # Return original text if API fails\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 4. Main execution block: Chunk, Process, and Save\n",
        "# -----------------------------------------------------------\n",
        "if __name__ == '__main__':\n",
        "    if not os.path.exists(INPUT_TEXT_FILE):\n",
        "        print(f\"Input file '{INPUT_TEXT_FILE}' not found. Ensure it is uploaded or available.\")\n",
        "        exit()\n",
        "\n",
        "    print(f\"\\nStarting OCR correction process on {INPUT_TEXT_FILE}...\")\n",
        "\n",
        "    # Open the output file in write mode\n",
        "    with open(OUTPUT_CORRECTED_FILE, 'w', encoding='utf-8') as f_out:\n",
        "        chunk_count = 0\n",
        "        # Iterate over the input file in chunks\n",
        "        for chunk in read_in_chunks(INPUT_TEXT_FILE, CHUNK_SIZE):\n",
        "            chunk_count += 1\n",
        "            print(f\"  -> Processing chunk {chunk_count}...\")\n",
        "\n",
        "            # Correct the chunk using Gemini\n",
        "            corrected_chunk = correct_ocr_chunk_with_gemini(chunk)\n",
        "\n",
        "            # Write the corrected chunk directly to the output file\n",
        "            if corrected_chunk:\n",
        "                # Add newlines between chunks for readability/structure preservation\n",
        "                f_out.write(corrected_chunk + \"\\n\\n\")\n",
        "            else:\n",
        "                print(f'  -> Chunk {chunk_count} returned no corrected text.')\n",
        "\n",
        "    print(f\"\\n--- Gemini OCR Correction Pipeline Finished ---\")\n",
        "    print(f\"All corrected text has been saved to: {OUTPUT_CORRECTED_FILE}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ja6xYRwhFUKt"
      },
      "source": [
        "Can you speed it up by running the requests asynchronously ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yttR0PJIE4EY",
        "outputId": "03f1dcb6-8337-4c11-9783-9988ee7dd1eb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:REST async clients requires async credentials set using aiplatform.initializer._set_async_rest_credentials().\n",
            "Falling back to grpc since no async rest credentials were detected.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gemini Model 'gemini-2.5-flash' initialized successfully.\n",
            "\n",
            "Starting ASYNC OCR correction process on confuciussinarum00conf_0_djvu.txt...\n",
            "Created 53 tasks. Sending requests concurrently...\n",
            "  -> Finished processing chunk 53.\n",
            "  -> Finished processing chunk 35.\n",
            "  -> Finished processing chunk 1.\n",
            "  -> Finished processing chunk 29.\n",
            "  -> Finished processing chunk 20.\n",
            "  -> Finished processing chunk 21.\n",
            "  -> Finished processing chunk 4.\n",
            "  -> Finished processing chunk 49.\n",
            "  -> Finished processing chunk 13.\n",
            "  -> Finished processing chunk 42.\n",
            "  -> Finished processing chunk 7.\n",
            "  -> Finished processing chunk 10.\n",
            "  -> Finished processing chunk 30.\n",
            "  -> Finished processing chunk 6.\n",
            "  -> Finished processing chunk 51.\n",
            "  -> Finished processing chunk 37.\n",
            "  -> Finished processing chunk 8.\n",
            "  -> Finished processing chunk 45.\n",
            "  -> Finished processing chunk 3.\n",
            "  -> Finished processing chunk 38.\n",
            "  -> Finished processing chunk 16.\n",
            "  -> Finished processing chunk 44.\n",
            "  -> Finished processing chunk 52.\n",
            "  -> Finished processing chunk 47.\n",
            "  -> Finished processing chunk 9.\n",
            "  -> Finished processing chunk 2.\n",
            "  -> Finished processing chunk 5.\n",
            "  -> Finished processing chunk 27.\n",
            "  -> Finished processing chunk 32.\n",
            "  -> Finished processing chunk 33.\n",
            "  -> Finished processing chunk 39.\n",
            "  -> Finished processing chunk 17.\n",
            "  -> Finished processing chunk 14.\n",
            "  -> Finished processing chunk 12.\n",
            "  -> Finished processing chunk 43.\n",
            "  -> Finished processing chunk 46.\n",
            "  -> Finished processing chunk 26.\n",
            "  -> Finished processing chunk 25.\n",
            "  -> Finished processing chunk 48.\n",
            "  -> Finished processing chunk 36.\n",
            "  -> Finished processing chunk 31.\n",
            "  -> Finished processing chunk 34.\n",
            "  -> Finished processing chunk 22.\n",
            "  -> Finished processing chunk 18.\n",
            "  -> Finished processing chunk 15.\n",
            "  -> Finished processing chunk 50.\n",
            "  -> Finished processing chunk 24.\n",
            "  -> Finished processing chunk 23.\n",
            "  -> Finished processing chunk 19.\n",
            "  -> Finished processing chunk 41.\n",
            "  -> Finished processing chunk 40.\n",
            "  -> Finished processing chunk 28.\n",
            "  -> Finished processing chunk 11.\n",
            "\n",
            "--- Gemini ASYNC OCR Correction Pipeline Finished ---\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import asyncio\n",
        "import vertexai\n",
        "from vertexai.generative_models import GenerativeModel, Part\n",
        "\n",
        "# Use nest_asyncio to run async code easily in environments like Colab\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# --- Configuration Constants (Define these as per your environment) ---\n",
        "PROJECT_ID = 'renaissance-ocr'\n",
        "LOCATION = 'global'\n",
        "GEMINI_MODEL = 'gemini-2.5-flash'\n",
        "JSON_FILE_PATH = 'renaissance-ocr-4aabe5b8dc65.json'\n",
        "INPUT_TEXT_FILE = 'confuciussinarum00conf_0_djvu.txt'\n",
        "OUTPUT_CORRECTED_FILE = 'Corrected_OCR_Text_from_Archive3.txt'\n",
        "CHUNK_SIZE = 10000\n",
        "CORRECTION_PROMPT = \"\"\"\n",
        "You are an expert proofreader of early modern Latin. TASK: Correct ONLY OCR errors in the input text. Do not rewrite or alter authentic early modern usage. RULES: 1. Preserve the original wording, grammar, and syntax. Fix ONLY: - misread letters - broken or split words - incorrect or missing spacing - duplicated characters - corrupted punctuation caused by OCR 2. Apply minimal normalization (OLD conventions): - u = vowel, v = consonant - use i only (never j) - expand æ → ae, œ → oe - replace & or &amp; with et Do NOT modernize vocabulary or regularize historical spellings unless the form is clearly an OCR mistake. 3. This is very important: De hyphenate all words broken across line breaks: - remove hyphens that occur at the end of a line, - join the two fragments into a single continuous word, - and correct any spacing errors created by the line break. Also remove hyphens that belong to real Latin compounds, as hyphens are irrelevant. Do not add new punctuation. Do not retain paragraph breaks; just produce continuous text. 4. Keep all paragraph breaks and capitalization exactly as in the input. 5. Remove page furniture only when clearly not part of the running text: examples: “A ij”, “EPISTOLA.”, catchwords, signature marks. 6. Preserve Chinese or other exotic romanizations exactly as printed once corrected. Do NOT “improve,” standardize, or re interpret them (e.g., keep forms like “Tai Ki Gin”). 7. Output ONLY the corrected Latin text. Do NOT add commentary, explanation, or formatting.\n",
        "\"\"\"\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 1. Authenticate and Initialize the Vertex AI Client\n",
        "# -----------------------------------------------------------\n",
        "try:\n",
        "    if not os.path.exists(JSON_FILE_PATH):\n",
        "        print(f\"Credentials file not found at: {JSON_FILE_PATH}\")\n",
        "        raise FileNotFoundError(f\"Credentials file not found: {JSON_FILE_PATH}\")\n",
        "\n",
        "    os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = JSON_FILE_PATH\n",
        "    vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
        "    # Initialize the *one* model client we will reuse everywhere\n",
        "    model = GenerativeModel(GEMINI_MODEL)\n",
        "    print(f\"Gemini Model '{GEMINI_MODEL}' initialized successfully.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Authentication or client initialization failed: {e}\")\n",
        "    exit()\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 2. Define a function to read a file in chunks\n",
        "# -----------------------------------------------------------\n",
        "def read_in_chunks(file_path, chunk_size=CHUNK_SIZE):\n",
        "    # (This function remains the same)\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        while True:\n",
        "            chunk = f.read(chunk_size)\n",
        "            if not chunk:\n",
        "                break\n",
        "            yield chunk\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 3. Define an ASYNCHRONOUS function to correct a chunk\n",
        "# -----------------------------------------------------------\n",
        "async def correct_ocr_chunk_with_gemini_async(model_client, chunk_text, chunk_id):\n",
        "    \"\"\"Sends a text chunk to Gemini for correction asynchronously.\"\"\"\n",
        "\n",
        "    contents = [\n",
        "        CORRECTION_PROMPT,\n",
        "        chunk_text\n",
        "    ]\n",
        "\n",
        "    try:\n",
        "        # Await the response using the provided model_client instance\n",
        "        response = await model_client.generate_content_async(contents)\n",
        "\n",
        "        corrected_text = response.text.strip() or \"\"\n",
        "        print(f\"  -> Finished processing chunk {chunk_id}.\")\n",
        "        return chunk_id, corrected_text # Return ID to sort results later\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"API call failed for chunk {chunk_id}: {e}\")\n",
        "        return chunk_id, chunk_text # Return original text if API fails\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 4. Main asynchronous execution block\n",
        "# -----------------------------------------------------------\n",
        "async def main():\n",
        "    if not os.path.exists(INPUT_TEXT_FILE):\n",
        "        print(f\"Input file '{INPUT_TEXT_FILE}' not found. Ensure it is uploaded or available.\")\n",
        "        return\n",
        "\n",
        "    print(f\"\\nStarting ASYNC OCR correction process on {INPUT_TEXT_FILE}...\")\n",
        "\n",
        "    tasks = []\n",
        "    chunk_count = 0\n",
        "    for chunk in read_in_chunks(INPUT_TEXT_FILE, CHUNK_SIZE):\n",
        "        chunk_count += 1\n",
        "        # Pass the initialized 'model' instance to the async function\n",
        "        tasks.append(correct_ocr_chunk_with_gemini_async(model, chunk, chunk_count))\n",
        "\n",
        "    print(f\"Created {len(tasks)} tasks. Sending requests concurrently...\")\n",
        "\n",
        "    results = await asyncio.gather(*tasks, return_exceptions=True)\n",
        "\n",
        "    processed_results = []\n",
        "    for res in results:\n",
        "        if isinstance(res, Exception):\n",
        "            print(f\"An exception occurred during one of the API calls: {res}\")\n",
        "        else:\n",
        "            processed_results.append(res)\n",
        "\n",
        "    processed_results.sort(key=lambda x: x[0]) # Sort by the chunk_id (index 0)\n",
        "\n",
        "    with open(OUTPUT_CORRECTED_FILE, 'w', encoding='utf-8') as f_out:\n",
        "        for chunk_id, corrected_chunk in processed_results:\n",
        "            if corrected_chunk:\n",
        "                f_out.write(corrected_chunk + \"\\n\\n\")\n",
        "\n",
        "    print(f\"\\n--- Gemini ASYNC OCR Correction Pipeline Finished ---\")\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 5. Run the asynchronous main function in Colab\n",
        "# -----------------------------------------------------------\n",
        "if __name__ == '__main__':\n",
        "    # asyncio.run handles running the async main loop\n",
        "    asyncio.run(main())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ga3h9BElncn-"
      },
      "source": [
        "Try playing with the chunk sizes. Reduce to 3k."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8aWxWnyoyCU",
        "outputId": "bae847d3-da26-48aa-d622-da623a4f6637"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:REST async clients requires async credentials set using aiplatform.initializer._set_async_rest_credentials().\n",
            "Falling back to grpc since no async rest credentials were detected.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gemini Model 'gemini-2.5-flash' initialized successfully.\n",
            "\n",
            "Starting ASYNC OCR correction process on confuciussinarum00conf_0_djvu.txt...\n",
            "Created 523 tasks. Sending requests concurrently...\n",
            "  -> Finished processing chunk 60.\n",
            "  -> Finished processing chunk 93.\n",
            "  -> Finished processing chunk 83.\n",
            "  -> Finished processing chunk 86.\n",
            "  -> Finished processing chunk 78.\n",
            "  -> Finished processing chunk 47.\n",
            "  -> Finished processing chunk 51.\n",
            "  -> Finished processing chunk 98.\n",
            "  -> Finished processing chunk 43.\n",
            "  -> Finished processing chunk 77.\n",
            "API call failed for chunk 12: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "  -> Finished processing chunk 75.\n",
            "  -> Finished processing chunk 72.\n",
            "  -> Finished processing chunk 97.\n",
            "  -> Finished processing chunk 90.\n",
            "API call failed for chunk 91: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "  -> Finished processing chunk 42.\n",
            "  -> Finished processing chunk 58.\n",
            "  -> Finished processing chunk 26.\n",
            "  -> Finished processing chunk 27.\n",
            "  -> Finished processing chunk 15.\n",
            "  -> Finished processing chunk 89.\n",
            "  -> Finished processing chunk 76.\n",
            "  -> Finished processing chunk 6.\n",
            "API call failed for chunk 121: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 122: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "  -> Finished processing chunk 22.\n",
            "  -> Finished processing chunk 54.\n",
            "  -> Finished processing chunk 49.\n",
            "  -> Finished processing chunk 71.\n",
            "API call failed for chunk 7: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "  -> Finished processing chunk 41.\n",
            "  -> Finished processing chunk 25.\n",
            "API call failed for chunk 10: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "  -> Finished processing chunk 23.\n",
            "  -> Finished processing chunk 45.\n",
            "  -> Finished processing chunk 19.\n",
            "API call failed for chunk 128: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "  -> Finished processing chunk 46.\n",
            "API call failed for chunk 36: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "  -> Finished processing chunk 96.\n",
            "  -> Finished processing chunk 62.\n",
            "  -> Finished processing chunk 55.\n",
            "  -> Finished processing chunk 38.\n",
            "API call failed for chunk 135: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "  -> Finished processing chunk 17.\n",
            "API call failed for chunk 102: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "  -> Finished processing chunk 53.\n",
            "  -> Finished processing chunk 4.\n",
            "  -> Finished processing chunk 92.\n",
            "  -> Finished processing chunk 79.\n",
            "  -> Finished processing chunk 1.\n",
            "  -> Finished processing chunk 85.\n",
            "  -> Finished processing chunk 69.\n",
            "  -> Finished processing chunk 39.\n",
            "API call failed for chunk 141: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "  -> Finished processing chunk 35.\n",
            "  -> Finished processing chunk 56.\n",
            "  -> Finished processing chunk 34.\n",
            "  -> Finished processing chunk 18.\n",
            "  -> Finished processing chunk 59.\n",
            "  -> Finished processing chunk 66.\n",
            "  -> Finished processing chunk 37.\n",
            "  -> Finished processing chunk 70.\n",
            "  -> Finished processing chunk 94.\n",
            "  -> Finished processing chunk 84.\n",
            "  -> Finished processing chunk 33.\n",
            "  -> Finished processing chunk 52.\n",
            "  -> Finished processing chunk 65.\n",
            "  -> Finished processing chunk 50.\n",
            "API call failed for chunk 170: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "  -> Finished processing chunk 82.\n",
            "API call failed for chunk 172: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 173: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 174: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "  -> Finished processing chunk 81.\n",
            "  -> Finished processing chunk 40.\n",
            "API call failed for chunk 177: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 178: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 179: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 180: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 181: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "  -> Finished processing chunk 5.\n",
            "  -> Finished processing chunk 73.\n",
            "  -> Finished processing chunk 68.\n",
            "  -> Finished processing chunk 9.\n",
            "  -> Finished processing chunk 13.\n",
            "  -> Finished processing chunk 87.\n",
            "  -> Finished processing chunk 8.\n",
            "  -> Finished processing chunk 11.\n",
            "  -> Finished processing chunk 32.\n",
            "  -> Finished processing chunk 104.\n",
            "  -> Finished processing chunk 29.\n",
            "  -> Finished processing chunk 20.\n",
            "  -> Finished processing chunk 24.\n",
            "  -> Finished processing chunk 64.\n",
            "  -> Finished processing chunk 95.\n",
            "  -> Finished processing chunk 99.\n",
            "  -> Finished processing chunk 30.\n",
            "  -> Finished processing chunk 14.\n",
            "  -> Finished processing chunk 108.\n",
            "  -> Finished processing chunk 31.\n",
            "  -> Finished processing chunk 117.\n",
            "  -> Finished processing chunk 88.\n",
            "  -> Finished processing chunk 67.\n",
            "  -> Finished processing chunk 139.\n",
            "  -> Finished processing chunk 44.\n",
            "  -> Finished processing chunk 151.\n",
            "  -> Finished processing chunk 120.\n",
            "  -> Finished processing chunk 126.\n",
            "  -> Finished processing chunk 106.\n",
            "  -> Finished processing chunk 137.\n",
            "  -> Finished processing chunk 132.\n",
            "  -> Finished processing chunk 133.\n",
            "  -> Finished processing chunk 21.\n",
            "  -> Finished processing chunk 111.\n",
            "API call failed for chunk 61: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "  -> Finished processing chunk 116.\n",
            "  -> Finished processing chunk 80.\n",
            "  -> Finished processing chunk 159.\n",
            "  -> Finished processing chunk 154.\n",
            "  -> Finished processing chunk 184.\n",
            "  -> Finished processing chunk 131.\n",
            "  -> Finished processing chunk 157.\n",
            "  -> Finished processing chunk 74.\n",
            "  -> Finished processing chunk 145.\n",
            "  -> Finished processing chunk 103.\n",
            "  -> Finished processing chunk 164.\n",
            "  -> Finished processing chunk 144.\n",
            "  -> Finished processing chunk 183.\n",
            "  -> Finished processing chunk 150.\n",
            "  -> Finished processing chunk 57.\n",
            "  -> Finished processing chunk 142.\n",
            "  -> Finished processing chunk 175.\n",
            "  -> Finished processing chunk 186.\n",
            "  -> Finished processing chunk 156.\n",
            "  -> Finished processing chunk 168.\n",
            "  -> Finished processing chunk 28.\n",
            "  -> Finished processing chunk 182.\n",
            "  -> Finished processing chunk 191.\n",
            "  -> Finished processing chunk 165.\n",
            "  -> Finished processing chunk 155.\n",
            "  -> Finished processing chunk 2.\n",
            "  -> Finished processing chunk 119.\n",
            "  -> Finished processing chunk 115.\n",
            "  -> Finished processing chunk 189.\n",
            "  -> Finished processing chunk 138.\n",
            "  -> Finished processing chunk 143.\n",
            "  -> Finished processing chunk 123.\n",
            "  -> Finished processing chunk 161.\n",
            "  -> Finished processing chunk 153.\n",
            "API call failed for chunk 249: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "  -> Finished processing chunk 187.\n",
            "  -> Finished processing chunk 112.\n",
            "  -> Finished processing chunk 107.\n",
            "  -> Finished processing chunk 149.\n",
            "  -> Finished processing chunk 158.\n",
            "  -> Finished processing chunk 193.\n",
            "  -> Finished processing chunk 166.\n",
            "  -> Finished processing chunk 147.\n",
            "  -> Finished processing chunk 148.\n",
            "  -> Finished processing chunk 192.\n",
            "  -> Finished processing chunk 218.\n",
            "  -> Finished processing chunk 162.\n",
            "API call failed for chunk 262: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "  -> Finished processing chunk 16.\n",
            "  -> Finished processing chunk 101.\n",
            "  -> Finished processing chunk 200.\n",
            "API call failed for chunk 140: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "  -> Finished processing chunk 48.\n",
            "  -> Finished processing chunk 194.\n",
            "  -> Finished processing chunk 197.\n",
            "  -> Finished processing chunk 190.\n",
            "  -> Finished processing chunk 136.\n",
            "  -> Finished processing chunk 146.\n",
            "  -> Finished processing chunk 105.\n",
            "  -> Finished processing chunk 113.\n",
            "  -> Finished processing chunk 114.\n",
            "  -> Finished processing chunk 230.\n",
            "  -> Finished processing chunk 209.\n",
            "  -> Finished processing chunk 202.\n",
            "  -> Finished processing chunk 124.\n",
            "  -> Finished processing chunk 167.\n",
            "  -> Finished processing chunk 213.\n",
            "  -> Finished processing chunk 152.\n",
            "  -> Finished processing chunk 195.\n",
            "  -> Finished processing chunk 125.\n",
            "  -> Finished processing chunk 185.\n",
            "  -> Finished processing chunk 129.\n",
            "  -> Finished processing chunk 134.\n",
            "  -> Finished processing chunk 3.\n",
            "  -> Finished processing chunk 199.\n",
            "  -> Finished processing chunk 211.\n",
            "  -> Finished processing chunk 215.\n",
            "  -> Finished processing chunk 100.\n",
            "  -> Finished processing chunk 255.\n",
            "  -> Finished processing chunk 229.\n",
            "API call failed for chunk 286: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "  -> Finished processing chunk 212.\n",
            "API call failed for chunk 284: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 283: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "  -> Finished processing chunk 240.\n",
            "API call failed for chunk 285: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "  -> Finished processing chunk 207.\n",
            "  -> Finished processing chunk 214.\n",
            "  -> Finished processing chunk 231.\n",
            "API call failed for chunk 287: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 269: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 289: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 288: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "  -> Finished processing chunk 110.\n",
            "API call failed for chunk 293: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 292: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "  -> Finished processing chunk 163.\n",
            "  -> Finished processing chunk 118.\n",
            "  -> Finished processing chunk 221.\n",
            "API call failed for chunk 295: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "  -> Finished processing chunk 63.\n",
            "API call failed for chunk 291: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 290: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 294: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 296: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "  -> Finished processing chunk 232.\n",
            "API call failed for chunk 297: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "  -> Finished processing chunk 109.\n",
            "  -> Finished processing chunk 196.\n",
            "  -> Finished processing chunk 176.\n",
            "API call failed for chunk 299: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 298: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 300: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 305: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 301: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 307: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 310: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 302: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 306: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 308: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "  -> Finished processing chunk 237.\n",
            "API call failed for chunk 304: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 311: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "  -> Finished processing chunk 169.\n",
            "API call failed for chunk 303: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 309: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 316: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 315: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 313: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 317: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 319: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 318: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "  -> Finished processing chunk 188.\n",
            "API call failed for chunk 312: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "  -> Finished processing chunk 258.\n",
            "API call failed for chunk 314: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 320: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 321: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 322: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "  -> Finished processing chunk 206.\n",
            "  -> Finished processing chunk 130.\n",
            "  -> Finished processing chunk 171.\n",
            "API call failed for chunk 323: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "  -> Finished processing chunk 247.\n",
            "  -> Finished processing chunk 238.\n",
            "API call failed for chunk 324: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "  -> Finished processing chunk 228.\n",
            "  -> Finished processing chunk 250.\n",
            "  -> Finished processing chunk 204.\n",
            "API call failed for chunk 325: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "  -> Finished processing chunk 227.\n",
            "API call failed for chunk 332: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 335: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 327: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 328: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 329: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 326: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 334: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "  -> Finished processing chunk 210.\n",
            "API call failed for chunk 339: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 330: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 331: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "  -> Finished processing chunk 203.\n",
            "API call failed for chunk 336: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "  -> Finished processing chunk 220.\n",
            "API call failed for chunk 333: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 338: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 342: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 341: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 340: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 344: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "  -> Finished processing chunk 281.\n",
            "API call failed for chunk 337: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 346: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 343: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 354: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 349: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 347: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 350: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 353: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 351: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 348: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 345: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "  -> Finished processing chunk 217.\n",
            "API call failed for chunk 356: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 352: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 359: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 355: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 361: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 357: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 358: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 362: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "  -> Finished processing chunk 254.\n",
            "  -> Finished processing chunk 265.\n",
            "API call failed for chunk 360: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 365: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "  -> Finished processing chunk 252.\n",
            "API call failed for chunk 366: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 368: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 363: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 371: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 369: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 364: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 372: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 373: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 374: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 367: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 375: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 380: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 382: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "  -> Finished processing chunk 282.\n",
            "  -> Finished processing chunk 235.\n",
            "API call failed for chunk 381: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 376: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 370: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 389: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 378: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 379: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 377: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "  -> Finished processing chunk 276.\n",
            "  -> Finished processing chunk 208.\n",
            "API call failed for chunk 383: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 386: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 395: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 390: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 396: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 393: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "  -> Finished processing chunk 261.\n",
            "API call failed for chunk 398: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 391: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "  -> Finished processing chunk 274.\n",
            "API call failed for chunk 401: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 385: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 387: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 388: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 403: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 384: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 392: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 399: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 402: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 400: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 394: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "  -> Finished processing chunk 260.\n",
            "API call failed for chunk 397: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "  -> Finished processing chunk 201.\n",
            "API call failed for chunk 404: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 405: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 409: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 411: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "  -> Finished processing chunk 270.\n",
            "API call failed for chunk 406: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 413: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 408: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 407: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 410: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "  -> Finished processing chunk 216.\n",
            "API call failed for chunk 416: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 412: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 415: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 426: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 414: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 421: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 422: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "  -> Finished processing chunk 251.\n",
            "API call failed for chunk 419: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 417: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 431: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "  -> Finished processing chunk 257.\n",
            "API call failed for chunk 424: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 420: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 434: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 428: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "  -> Finished processing chunk 271.\n",
            "API call failed for chunk 427: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 418: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 430: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 429: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 433: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 435: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 425: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 440: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 437: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 442: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "  -> Finished processing chunk 198.\n",
            "API call failed for chunk 436: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 446: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 423: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 448: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 432: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 449: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 454: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 456: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 452: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "  -> Finished processing chunk 256.\n",
            "API call failed for chunk 444: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 457: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 453: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 443: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 441: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 438: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 450: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 455: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "  -> Finished processing chunk 226.\n",
            "  -> Finished processing chunk 205.\n",
            "API call failed for chunk 439: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 447: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 458: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 445: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 451: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "  -> Finished processing chunk 246.\n",
            "API call failed for chunk 468: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 464: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 461: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 459: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "  -> Finished processing chunk 234.\n",
            "  -> Finished processing chunk 245.\n",
            "  -> Finished processing chunk 264.\n",
            "API call failed for chunk 466: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 465: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "  -> Finished processing chunk 241.\n",
            "API call failed for chunk 460: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 475: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 469: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 462: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "  -> Finished processing chunk 242.\n",
            "API call failed for chunk 471: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 463: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 467: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 476: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 473: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 470: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 477: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 479: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 474: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 480: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 481: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 487: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 489: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 484: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 472: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 491: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 488: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 490: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 494: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 478: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "  -> Finished processing chunk 222.\n",
            "API call failed for chunk 485: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 501: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 482: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 505: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 493: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 495: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 497: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "  -> Finished processing chunk 225.\n",
            "API call failed for chunk 504: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 499: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 483: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 503: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 486: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 498: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 506: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 508: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 492: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 496: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "  -> Finished processing chunk 263.\n",
            "API call failed for chunk 512: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "  -> Finished processing chunk 253.\n",
            "API call failed for chunk 507: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 509: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 513: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 511: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 500: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 521: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 515: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 517: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 519: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 514: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 502: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 510: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "  -> Finished processing chunk 266.\n",
            "API call failed for chunk 522: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 516: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 520: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 518: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "API call failed for chunk 523: 429 Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.\n",
            "  -> Finished processing chunk 160.\n",
            "  -> Finished processing chunk 224.\n",
            "  -> Finished processing chunk 127.\n",
            "  -> Finished processing chunk 239.\n",
            "  -> Finished processing chunk 244.\n",
            "  -> Finished processing chunk 259.\n",
            "  -> Finished processing chunk 236.\n",
            "  -> Finished processing chunk 273.\n",
            "  -> Finished processing chunk 223.\n",
            "  -> Finished processing chunk 275.\n",
            "  -> Finished processing chunk 268.\n",
            "  -> Finished processing chunk 243.\n",
            "  -> Finished processing chunk 272.\n",
            "  -> Finished processing chunk 277.\n",
            "  -> Finished processing chunk 219.\n",
            "  -> Finished processing chunk 267.\n",
            "  -> Finished processing chunk 233.\n",
            "  -> Finished processing chunk 279.\n",
            "  -> Finished processing chunk 280.\n",
            "  -> Finished processing chunk 248.\n",
            "  -> Finished processing chunk 278.\n",
            "\n",
            "--- Gemini ASYNC OCR Correction Pipeline Finished ---\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import asyncio\n",
        "import vertexai\n",
        "from vertexai.generative_models import GenerativeModel, Part\n",
        "\n",
        "# Use nest_asyncio to run async code easily in environments like Colab\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# --- Configuration Constants (Define these as per your environment) ---\n",
        "PROJECT_ID = 'renaissance-ocr'\n",
        "LOCATION = 'global'\n",
        "GEMINI_MODEL = 'gemini-2.5-flash'\n",
        "JSON_FILE_PATH = 'renaissance-ocr-4aabe5b8dc65.json'\n",
        "INPUT_TEXT_FILE = 'confuciussinarum00conf_0_djvu.txt'\n",
        "OUTPUT_CORRECTED_FILE = 'Corrected_OCR_Text_from_Archive4.txt'\n",
        "CHUNK_SIZE = 3000\n",
        "CORRECTION_PROMPT = \"\"\"\n",
        "You are an expert proofreader of early modern Latin. TASK: Correct ONLY OCR errors in the input text. Do not rewrite or alter authentic early modern usage. RULES: 1. Preserve the original wording, grammar, and syntax. Fix ONLY: - misread letters - broken or split words - incorrect or missing spacing - duplicated characters - corrupted punctuation caused by OCR 2. Apply minimal normalization (OLD conventions): - u = vowel, v = consonant - use i only (never j) - expand æ → ae, œ → oe - replace & or &amp; with et Do NOT modernize vocabulary or regularize historical spellings unless the form is clearly an OCR mistake. 3. This is very important: De hyphenate all words broken across line breaks: - remove hyphens that occur at the end of a line, - join the two fragments into a single continuous word, - and correct any spacing errors created by the line break. Also remove hyphens that belong to real Latin compounds, as hyphens are irrelevant. Do not add new punctuation. Do not retain paragraph breaks; just produce continuous text. 4. Keep all paragraph breaks and capitalization exactly as in the input. 5. Remove page furniture only when clearly not part of the running text: examples: “A ij”, “EPISTOLA.”, catchwords, signature marks. 6. Preserve Chinese or other exotic romanizations exactly as printed once corrected. Do NOT “improve,” standardize, or re interpret them (e.g., keep forms like “Tai Ki Gin”). 7. Output ONLY the corrected Latin text. Do NOT add commentary, explanation, or formatting.\n",
        "\"\"\"\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 1. Authenticate and Initialize the Vertex AI Client\n",
        "# -----------------------------------------------------------\n",
        "try:\n",
        "    if not os.path.exists(JSON_FILE_PATH):\n",
        "        print(f\"Credentials file not found at: {JSON_FILE_PATH}\")\n",
        "        raise FileNotFoundError(f\"Credentials file not found: {JSON_FILE_PATH}\")\n",
        "\n",
        "    os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = JSON_FILE_PATH\n",
        "    vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
        "    # Initialize the *one* model client we will reuse everywhere\n",
        "    model = GenerativeModel(GEMINI_MODEL)\n",
        "    print(f\"Gemini Model '{GEMINI_MODEL}' initialized successfully.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Authentication or client initialization failed: {e}\")\n",
        "    exit()\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 2. Define a function to read a file in chunks\n",
        "# -----------------------------------------------------------\n",
        "def read_in_chunks(file_path, chunk_size=CHUNK_SIZE):\n",
        "    # (This function remains the same)\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        while True:\n",
        "            chunk = f.read(chunk_size)\n",
        "            if not chunk:\n",
        "                break\n",
        "            yield chunk\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 3. Define an ASYNCHRONOUS function to correct a chunk\n",
        "# -----------------------------------------------------------\n",
        "async def correct_ocr_chunk_with_gemini_async(model_client, chunk_text, chunk_id):\n",
        "    \"\"\"Sends a text chunk to Gemini for correction asynchronously.\"\"\"\n",
        "\n",
        "    contents = [\n",
        "        CORRECTION_PROMPT,\n",
        "        chunk_text\n",
        "    ]\n",
        "\n",
        "    try:\n",
        "        # Await the response using the provided model_client instance\n",
        "        response = await model_client.generate_content_async(contents)\n",
        "\n",
        "        corrected_text = response.text.strip() or \"\"\n",
        "        print(f\"  -> Finished processing chunk {chunk_id}.\")\n",
        "        return chunk_id, corrected_text # Return ID to sort results later\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"API call failed for chunk {chunk_id}: {e}\")\n",
        "        return chunk_id, chunk_text # Return original text if API fails\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 4. Main asynchronous execution block\n",
        "# -----------------------------------------------------------\n",
        "async def main():\n",
        "    if not os.path.exists(INPUT_TEXT_FILE):\n",
        "        print(f\"Input file '{INPUT_TEXT_FILE}' not found. Ensure it is uploaded or available.\")\n",
        "        return\n",
        "\n",
        "    print(f\"\\nStarting ASYNC OCR correction process on {INPUT_TEXT_FILE}...\")\n",
        "\n",
        "    tasks = []\n",
        "    chunk_count = 0\n",
        "    for chunk in read_in_chunks(INPUT_TEXT_FILE, CHUNK_SIZE):\n",
        "        chunk_count += 1\n",
        "        # Pass the initialized 'model' instance to the async function\n",
        "        tasks.append(correct_ocr_chunk_with_gemini_async(model, chunk, chunk_count))\n",
        "\n",
        "    print(f\"Created {len(tasks)} tasks. Sending requests concurrently...\")\n",
        "\n",
        "    results = await asyncio.gather(*tasks, return_exceptions=True)\n",
        "\n",
        "    processed_results = []\n",
        "    for res in results:\n",
        "        if isinstance(res, Exception):\n",
        "            print(f\"An exception occurred during one of the API calls: {res}\")\n",
        "        else:\n",
        "            processed_results.append(res)\n",
        "\n",
        "    processed_results.sort(key=lambda x: x[0]) # Sort by the chunk_id (index 0)\n",
        "\n",
        "    with open(OUTPUT_CORRECTED_FILE, 'w', encoding='utf-8') as f_out:\n",
        "        for chunk_id, corrected_chunk in processed_results:\n",
        "            if corrected_chunk:\n",
        "                f_out.write(corrected_chunk + \"\\n\\n\")\n",
        "\n",
        "    print(f\"\\n--- Gemini ASYNC OCR Correction Pipeline Finished ---\")\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 5. Run the asynchronous main function in Colab\n",
        "# -----------------------------------------------------------\n",
        "if __name__ == '__main__':\n",
        "    # asyncio.run handles running the async main loop\n",
        "    asyncio.run(main())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOPVDxQitv9T"
      },
      "source": [
        "Awesome—here’s a compact, production‑ready **Python script** that implements the **minimal, high‑ROI pre‑processing** we discussed for re‑OCR’d historical Latin (e.g., Archive.org). It’s modular, fast, and safe by default (reversible where reasonable). You can run it file‑by‑file or batch a folder.\n",
        "\n",
        "> What it does (in this order):\n",
        ">\n",
        "> 1.  Strip page furniture (headers/footers/page numbers/catchwords)\n",
        "> 2.  De‑hyphenate line breaks (`word-\\nnext` → `wordnext`) with a small safeguard list\n",
        "> 3.  Unicode normalize + glyph maps: long‑s, ligatures, curly quotes/dashes\n",
        "> 4.  Optional orthography normalization (**u↔v**, **i↔j**) — *off by default*\n",
        "> 5.  Whitespace normalization (preserve paragraph breaks)\n",
        "> 6.  Protected terms pass (names/terms you never want normalized)\n",
        "\n",
        "> Output: a cleaned `.txt` next to the input (or a chosen output file).  \n",
        "> Reproducibility: you get a simple JSON log of basic counts (what lines were dropped, hyphens joined, etc.).\n",
        "\n",
        "***\n",
        "\n",
        "## `preprocess_early_modern_latin.py`\n",
        "\n",
        "```python\n",
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Minimal pre-processing for early-modern Latin OCR (Archive.org etc.).\n",
        "- Removes page furniture (headers/footers/page numbers/catchwords)\n",
        "- De-hyphenates line-break hyphens safely\n",
        "- Applies Unicode normalization + glyph maps (ſ, æ/œ, curly quotes/dashes)\n",
        "- (Optional) orthography normalization (u/v, i/j)  -- OFF by default\n",
        "- Preserves paragraph boundaries; collapses intra-paragraph spaces\n",
        "- Respects a protected-terms list (no changes inside those tokens)\n",
        "\n",
        "Usage:\n",
        "  python preprocess_early_modern_latin.py input.txt [-o output.txt]\n",
        "       [--protect protected_terms.txt]\n",
        "       [--normalize-uv] [--normalize-ij]\n",
        "       [--keep-ligatures]    # if you DON'T want æ→ae / œ→oe\n",
        "       [--no-page-furniture] # if the OCR has no headers/footers\n",
        "       [--log log.json]\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import re\n",
        "import sys\n",
        "import json\n",
        "import argparse\n",
        "import unicodedata\n",
        "from pathlib import Path\n",
        "\n",
        "# --------------------------\n",
        "# Helpers / configuration\n",
        "# --------------------------\n",
        "\n",
        "HEADER_FOOTER_MAXLEN = 80  # many running heads are short/centered\n",
        "CATCHWORD_MAXLEN = 14      # page-end catchwords are very short\n",
        "ROMAN_RE = re.compile(r'^[IVXLCDM.\\s]{2,}$')  # roman-numeral-only line\n",
        "PAGE_NUM_RE = re.compile(r'^\\s*\\d{1,4}\\s*$')  # bare page numbers\n",
        "CENTERED_DOTS_RE = re.compile(r'^\\s*[•··•]+?\\s*$')\n",
        "\n",
        "# Things that often show up as “furniture-like” lines\n",
        "FURNITURE_CUES = (\n",
        "    'PROEMIALIS DECLARATIO', 'PROEMIALIS', 'DECLARATIO', 'OPERIS',\n",
        "    'PARAGRAPHUS', 'CHRONOLOGICA', 'CUM PRIVILEGIO REGIS'\n",
        ")\n",
        "\n",
        "SAFE_COMPOUND_PREFIXES = {\n",
        "    # Minimal whitelist: do NOT de-hyphenate if exactly these prefixes\n",
        "    # (extend if you see false joins in your corpus)\n",
        "    'co', 're', 'pre', 'semi', 'anti', 'inter', 'intra', 'super', 'sub', 'trans'\n",
        "}\n",
        "\n",
        "# Map curly quotes/dashes to ASCII; leave apostrophes\n",
        "PUNCT_MAP = {\n",
        "    '\\u2018': \"'\", '\\u2019': \"'\", '\\u201A': ',', '\\u201B': \"'\",\n",
        "    '\\u201C': '\"', '\\u201D': '\"', '\\u201E': '\"',\n",
        "    '\\u2013': '-', '\\u2014': '-', '\\u2212': '-',  # en/em/minus\n",
        "    '\\u00A0': ' ',  # non-breaking space\n",
        "}\n",
        "\n",
        "# Glyph maps (reversible in principle; keep raw elsewhere)\n",
        "def glyph_normalize(s: str, keep_ligatures: bool) -> str:\n",
        "    # long s\n",
        "    s = s.replace('\\u017F', 's')\n",
        "    if not keep_ligatures:\n",
        "        s = s.replace('æ', 'ae').replace('Æ', 'AE')\n",
        "        s = s.replace('œ', 'oe').replace('Œ', 'OE')\n",
        "    # straight quotes/dashes\n",
        "    for k, v in PUNCT_MAP.items():\n",
        "        s = s.replace(k, v)\n",
        "    # NFKC helps normalize compatibility glyphs while preserving text\n",
        "    s = unicodedata.normalize('NFKC', s)\n",
        "    return s\n",
        "\n",
        "def load_protected_terms(path: Path):\n",
        "    if not path or not path.exists():\n",
        "        return set()\n",
        "    terms = set()\n",
        "    for line in path.read_text(encoding='utf-8', errors='ignore').splitlines():\n",
        "        t = line.strip()\n",
        "        if t and not t.startswith('#'):\n",
        "            terms.add(t)\n",
        "    return terms\n",
        "\n",
        "def protect_terms(text: str, protected: set):\n",
        "    # Wrap protected tokens with sentinel markers so later passes don't alter them\n",
        "    # Use \\b-like behavior with Latin word boundaries (letters only)\n",
        "    # We protect case-insensitively but preserve original casing.\n",
        "    if not protected:\n",
        "        return text, {}\n",
        "    MARK_L = '\\uE000'  # Private Use Area\n",
        "    MARK_R = '\\uE001'\n",
        "    replacements = {}\n",
        "    # Sort longer first to avoid partial overlaps\n",
        "    for term in sorted(protected, key=len, reverse=True):\n",
        "        # Word-ish boundaries: allow letters/digits around; avoid splitting punctuation\n",
        "        pattern = re.compile(rf'(?<!\\w)({re.escape(term)})', flags=re.IGNORECASE)\n",
        "        def repl(m):\n",
        "            original = m.group(1)\n",
        "            wrapped = f\"{MARK_L}{original}{MARK_R}\"\n",
        "            replacements[wrapped] = original\n",
        "            return wrapped\n",
        "        text = pattern.sub(repl, text)\n",
        "    return text, {'MARK_L': MARK_L, 'MARK_R': MARK_R}\n",
        "\n",
        "def unprotect_terms(text: str, replacements_map: dict):\n",
        "    if not replacements_map:\n",
        "        return text\n",
        "    # Simply remove the sentinels; original casing remains since we wrapped the matched form\n",
        "    text = text.replace(replacements_map['MARK_L'], '').replace(replacements_map['MARK_R'], '')\n",
        "    return text\n",
        "\n",
        "# --------------------------\n",
        "# Page furniture removal\n",
        "# --------------------------\n",
        "\n",
        "def is_page_furniture(line: str) -> bool:\n",
        "    L = line.strip()\n",
        "    if not L:\n",
        "        return False\n",
        "    if PAGE_NUM_RE.match(L):\n",
        "        return True\n",
        "    if ROMAN_RE.match(L):\n",
        "        return True\n",
        "    if len(L) <= CATCHWORD_MAXLEN and L.isalpha() and L[0].islower():\n",
        "        # common catchword signal: short lowercase token alone near a page break\n",
        "        return True\n",
        "    if CENTERED_DOTS_RE.match(L):\n",
        "        return True\n",
        "    if len(L) <= HEADER_FOOTER_MAXLEN and L.isupper():\n",
        "        # all-caps short line (running head)\n",
        "        # check for typical cues\n",
        "        for cue in FURNITURE_CUES:\n",
        "            if cue in L:\n",
        "                return True\n",
        "    return False\n",
        "\n",
        "def remove_page_furniture(text: str):\n",
        "    lines = text.splitlines()\n",
        "    kept = []\n",
        "    removed = 0\n",
        "    for i, L in enumerate(lines):\n",
        "        if is_page_furniture(L):\n",
        "            removed += 1\n",
        "            continue\n",
        "        kept.append(L)\n",
        "    return \"\\n\".join(kept), removed\n",
        "\n",
        "# --------------------------\n",
        "# De-hyphenation at line breaks\n",
        "# --------------------------\n",
        "\n",
        "def should_join(left_token: str, right_token: str) -> bool:\n",
        "    # Avoid joining if left_token is in a safe prefix list (e.g., \"co-\")\n",
        "    # Very conservative: only block if the entire left_token is a prefix\n",
        "    return left_token.lower() not in SAFE_COMPOUND_PREFIXES\n",
        "\n",
        "def dehyphenate(text: str):\n",
        "    \"\"\"\n",
        "    Join lines ending with hyphen:\n",
        "       \"... verbo-\\nrum ...\" -> \"... verborum ...\"\n",
        "    but skip if left piece is a protected prefix (e.g., \"co-\")\n",
        "    \"\"\"\n",
        "    # We'll work on raw text to keep paragraphing\n",
        "    # Replace pattern word-<newline>lowercase\n",
        "    count = 0\n",
        "    def repl(m):\n",
        "        nonlocal count\n",
        "        left = m.group(1)\n",
        "        right_first = m.group(2)\n",
        "        if should_join(left, right_first):\n",
        "            count += 1\n",
        "            return left + right_first\n",
        "        # keep hyphen + newline if it's a safe prefix case\n",
        "        return left + '-\\n' + right_first\n",
        "\n",
        "    # Do multiple passes for rare cascades\n",
        "    pattern = re.compile(r'([A-Za-zÀ-ÿ]+)-\\n([a-zà-ÿ])')\n",
        "    new_text = pattern.sub(repl, text)\n",
        "    return new_text, count\n",
        "\n",
        "# --------------------------\n",
        "# Orthography normalization (optional)\n",
        "# --------------------------\n",
        "\n",
        "def normalize_uv(text: str) -> str:\n",
        "    # Conservative: change \"v\" as consonant before vowel at word start to \"v\", \"u\" otherwise.\n",
        "    # For analytics, many choose to map all u/v to \"u\" or to \"v\". We'll provide a simple policy:\n",
        "    # - Map all \"v\" between vowels to \"u\" (e.g., \"aue\" variants) and all standalone \"u\" at word start before vowel to \"v\".\n",
        "    # This is simplistic but serviceable for counts; tune if needed.\n",
        "    # 1) u->v at word start before vowel\n",
        "    text = re.sub(r'\\buU', lambda m: 'v' if m.group(0).islower() else 'V', text)\n",
        "    # 2) v->u between vowels (a simple heuristic)\n",
        "    text = re.sub(r'([aeiouAEIOU])vV',\n",
        "                  lambda m: m.group(1) + ('u' if m.group(0)[1].islower() else 'U') + m.group(2), text)\n",
        "    return text\n",
        "\n",
        "def normalize_ij(text: str) -> str:\n",
        "    # Very conservative: map \"j\" in vowel context to \"i\", but do NOT touch \"J\" initials of proper names.\n",
        "    # Many projects prefer a flat map j→i; we give a safer default.\n",
        "    text = re.sub(r'(?<!\\b[J])j', 'i', text)  # replace lower j unless \"J\" initial\n",
        "    return text\n",
        "\n",
        "# --------------------------\n",
        "# Whitespace normalization\n",
        "# --------------------------\n",
        "\n",
        "def normalize_whitespace(text: str) -> str:\n",
        "    # Preserve paragraph breaks but normalize intra-paragraph spaces\n",
        "    # 1) Canonicalize Windows newlines\n",
        "    text = text.replace('\\r\\n', '\\n').replace('\\r', '\\n')\n",
        "    # 2) Compress >2 blank lines down to 2 (paragraph spacing)\n",
        "    text = re.sub(r'\\n{3,}', '\\n\\n', text)\n",
        "    # 3) Within paragraphs, collapse multiple spaces/tabs\n",
        "    paras = [re.sub(r'[ \\t]+', ' ', p).strip() for p in text.split('\\n')]\n",
        "    return \"\\n\".join(paras)\n",
        "\n",
        "# --------------------------\n",
        "# Main pipeline\n",
        "# --------------------------\n",
        "\n",
        "def preprocess(\n",
        "    raw_text: str,\n",
        "    keep_ligatures: bool = False,\n",
        "    drop_furniture: bool = True,\n",
        "    do_uv: bool = False,\n",
        "    do_ij: bool = False,\n",
        "    protected_terms: set = None\n",
        "):\n",
        "    log = {\n",
        "        'removed_furniture_lines': 0,\n",
        "        'dehyphen_joins': 0,\n",
        "        'applied_uv': do_uv,\n",
        "        'applied_ij': do_ij,\n",
        "        'keep_ligatures': keep_ligatures,\n",
        "        'protected_terms': len(protected_terms or [])\n",
        "    }\n",
        "\n",
        "    # 0) Protect terms\n",
        "    protected_map = {}\n",
        "    if protected_terms:\n",
        "        raw_text, protected_map = protect_terms(raw_text, protected_terms)\n",
        "\n",
        "    # 1) Page furniture\n",
        "    if drop_furniture:\n",
        "        raw_text, removed = remove_page_furniture(raw_text)\n",
        "        log['removed_furniture_lines'] = removed\n",
        "\n",
        "    # 2) Dehyphenate\n",
        "    raw_text, joins = dehyphenate(raw_text)\n",
        "    log['dehyphen_joins'] = joins\n",
        "\n",
        "    # 3) Glyph normalization\n",
        "    raw_text = glyph_normalize(raw_text, keep_ligatures=keep_ligatures)\n",
        "\n",
        "    # 4) Optional orthography normalization\n",
        "    if do_uv:\n",
        "        raw_text = normalize_uv(raw_text)\n",
        "    if do_ij:\n",
        "        raw_text = normalize_ij(raw_text)\n",
        "\n",
        "    # 5) Whitespace normalization (preserve paragraph breaks)\n",
        "    raw_text = normalize_whitespace(raw_text)\n",
        "\n",
        "    # 6) Unprotect terms\n",
        "    raw_text = unprotect_terms(raw_text, protected_map)\n",
        "\n",
        "    return raw_text, log\n",
        "\n",
        "def main():\n",
        "    ap = argparse.ArgumentParser(description=\"Minimal pre-processing for early-modern Latin OCR.\")\n",
        "    ap.add_argument(\"input\", type=str, help=\"Path to input .txt\")\n",
        "    ap.add_argument(\"-o\", \"--output\", type=str, help=\"Path to output .txt (default: alongside input)\")\n",
        "    ap.add_argument(\"--protect\", type=str, help=\"Optional protected-terms file (one term per line)\")\n",
        "    ap.add_argument(\"--normalize-uv\", action=\"store_true\", help=\"Apply u/v normalization (conservative heuristic)\")\n",
        "    ap.add_argument(\"--normalize-ij\", action=\"store_true\", help=\"Apply i/j normalization (conservative heuristic)\")\n",
        "    ap.add_argument(\"--keep-ligatures\", action=\"store_true\", help=\"Keep æ/œ ligatures instead of expanding to ae/oe\")\n",
        "    ap.add_argument(\"--no-page-furniture\", action=\"store_true\", help=\"Do not strip page furniture\")\n",
        "    ap.add_argument(\"--log\", type=str, help=\"Write summary log JSON\")\n",
        "    args = ap.parse_args()\n",
        "\n",
        "    in_path = Path(args.input)\n",
        "    if not in_path.exists():\n",
        "        print(f\"ERROR: Input not found: {in_path}\", file=sys.stderr)\n",
        "        sys.exit(1)\n",
        "\n",
        "    out_path = Path(args.output) if args.output else in_path.with_suffix(\".clean.txt\")\n",
        "    prot_set = load_protected_terms(Path(args.protect)) if args.protect else set()\n",
        "\n",
        "    raw = in_path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
        "    cleaned, log = preprocess(\n",
        "        raw_text=raw,\n",
        "        keep_ligatures=args.keep_ligatures,\n",
        "        drop_furniture=not args.no_page_furniture,\n",
        "        do_uv=args.normalize_uv,\n",
        "        do_ij=args.normalize_ij,\n",
        "        protected_terms=prot_set\n",
        "    )\n",
        "    out_path.write_text(cleaned, encoding=\"utf-8\")\n",
        "\n",
        "    if args.log:\n",
        "        Path(args.log).write_text(json.dumps({\n",
        "            'input': str(in_path),\n",
        "            'output': str(out_path),\n",
        "            **log\n",
        "        }, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
        "\n",
        "    print(f\"✓ Wrote: {out_path}\")\n",
        "    if args.log:\n",
        "        print(f\"✓ Log:   {args.log}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "```\n",
        "\n",
        "***\n",
        "\n",
        "## How to use\n",
        "\n",
        "```bash\n",
        "# 1) Basic cleaning (recommended defaults)\n",
        "python preprocess_early_modern_latin.py Corrected_OCR_Text_from_Archive4.txt \\\n",
        "  -o Corrected_OCR_Text_from_Archive4.clean.txt \\\n",
        "  --log Corrected_OCR_Text_from_Archive4.log.json\n",
        "\n",
        "# 2) With protected terms (names, Latinized Sinological terms you never want changed)\n",
        "python preprocess_early_modern_latin.py Corrected_OCR_Text_from_Archive4.txt \\\n",
        "  -o Corrected_OCR_Text_from_Archive4.clean.txt \\\n",
        "  --protect protected_terms.txt \\\n",
        "  --log Corrected_OCR_Text_from_Archive4.log.json\n",
        "\n",
        "# 3) If you want orthography normalization for analytics tracks\n",
        "python preprocess_early_modern_latin.py Corrected_OCR_Text_from_Archive4.txt \\\n",
        "  -o Corrected_OCR_Text_from_Archive4.norm.txt \\\n",
        "  --normalize-uv --normalize-ij \\\n",
        "  --protect protected_terms.txt \\\n",
        "  --log Corrected_OCR_Text_from_Archive4.norm.log.json\n",
        "```\n",
        "\n",
        "**`protected_terms.txt` example**\n",
        "\n",
        "    Confucius\n",
        "    Confucium\n",
        "    Philippus Couplet\n",
        "    Intorcetta\n",
        "    Herdtrich\n",
        "    Rougemont\n",
        "    Siamensium\n",
        "    Sinensium\n",
        "    Xam ti\n",
        "    Tai Kie\n",
        "\n",
        "> Tip: keep two parallel versions:  \n",
        "> **(A)** “clean” (glyphs normalized; paragraphing preserved; no u/v or i/j changes)  \n",
        "> **(B)** “norm” (with u/v and/or i/j normalization)  \n",
        "> Use **(B)** for aggregation (n‑grams, topics); use **(A)** to quote or cross‑check.\n",
        "\n",
        "***\n",
        "\n",
        "## What to expect\n",
        "\n",
        "*   This minimal pass typically lowers normalized WER a few points “for free,” especially by removing page furniture and fixing line‑break hyphens.\n",
        "*   It’s safe: no paraphrasing, and the optional orthography step is **off by default**.\n",
        "*   If you later want to add a **confusion‑model post‑correction** layer or **short‑span LLM cleanups**, we can hook those right after this script.\n",
        "\n",
        "If you’d like, I can **drop in a confusion‑map booster** (learned from your aligned epistle) as a small, optional post‑pass and re‑run WER/CER so you can see before/after deltas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mSYmVcYECRA",
        "outputId": "423bc2e5-f378-4cef-fdc3-402d44913610"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully cleaned text written to 'OCR_Error_Cleaned.txt'\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "import re\n",
        "import unicodedata\n",
        "from pathlib import Path\n",
        "import os\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "# --- Configuration (Kept simple) ---\n",
        "INPUT_TEXT_FILE  = 'confuciussinarum00conf_0_djvu.txt'\n",
        "OUTPUT_CLEANED_FILE = 'OCR_Error_Cleaned.txt'\n",
        "\n",
        "# Map curly quotes/dashes/ligatures/OCR errors\n",
        "PUNCT_MAP = {\n",
        "    '\\u017F': 's',         # long s (ſ)\n",
        "    'æ': 'ae', 'Æ': 'AE',\n",
        "    'œ': 'oe', 'Œ': 'OE',\n",
        "    '\\u2018': \"'\", '\\u2019': \"'\", '\\u201A': ',', '\\u201B': \"'\",\n",
        "    '\\u201C': '\"', '\\u201D': '\"', '\\u201E': '\"',\n",
        "    '\\u2013': '-', '\\u2014': '-', '\\u2212': '-',   # en/em/minus → hyphen\n",
        "    '\\u00AD': '-',                                 # soft hyphen → hyphen\n",
        "    '\\u00A0': ' ', '\\u2002': ' ', '\\u2003': ' ', '\\u2009': ' ', # spaces\n",
        "}\n",
        "\n",
        "# --- Patterns for Removal (Page Numbers Only) ---\n",
        "\n",
        "# Roman-only line (common for front matter page numbers)\n",
        "# Requires at least one character and optional surrounding whitespace/periods.\n",
        "ROMAN_LINE = re.compile(r'^\\s*[IVXLCDM]+\\.*\\s*$')\n",
        "\n",
        "# A page-number line: bare arabic up to 4 digits\n",
        "ARABIC_PAGE = re.compile(r'^\\s*\\d{1,4}\\s*$')\n",
        "\n",
        "# Centered dot filler or dot leaders which often appear with page numbers in TOCs\n",
        "FILLER_LINE = re.compile(r'^\\s*[•·.\\u2022]{3,}\\s*$')\n",
        "\n",
        "\n",
        "# --- Patterns for Fixing OCR Errors ---\n",
        "\n",
        "# A token of single-letter small-caps separated by spaces: \"L U D O V I C O\"\n",
        "SPACED_SMALLCAPS = re.compile(r'\\b(?:[A-Z]\\s){2,}[A-Z]\\b')\n",
        "\n",
        "\n",
        "# --- Utilities ---\n",
        "\n",
        "def normalize_glyphs(s: str) -> str:\n",
        "    \"\"\"Standardize unicode punctuation, ligatures, and OCR noise characters.\"\"\"\n",
        "    for k, v in PUNCT_MAP.items():\n",
        "        s = s.replace(k, v)\n",
        "    s = unicodedata.normalize('NFKC', s)\n",
        "    return s\n",
        "\n",
        "def strip_scanner_artifacts(s: str) -> str:\n",
        "    \"\"\"Remove common stray OCR artifacts like escaped parentheses/backslashes.\"\"\"\n",
        "    s = s.replace('\\\\(', '(').replace('\\\\)', ')')\n",
        "    # collapse runs of stray backslashes left by OCR\n",
        "    s = re.sub(r'\\\\{2,}', r'\\\\', s)\n",
        "    return s\n",
        "\n",
        "def fix_spaced_smallcaps(s: str) -> str:\n",
        "    \"\"\"Join sequences like \"L U D O V I C O\" -> \"LUDOVICO\".\"\"\"\n",
        "    def _join(m):\n",
        "        return m.group(0).replace(' ', '')\n",
        "    return SPACED_SMALLCAPS.sub(_join, s)\n",
        "\n",
        "def remove_page_numbers_and_fillers(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Iterates through lines and removes only lines matching known page number formats\n",
        "    or filler dots/leaders.\n",
        "    \"\"\"\n",
        "    lines = text.splitlines()\n",
        "    kept = []\n",
        "    for L in lines:\n",
        "        S = L.strip()\n",
        "        if not S:\n",
        "            kept.append(L) # Keep blank lines\n",
        "            continue\n",
        "\n",
        "        # Explicitly remove only identified page furniture\n",
        "        if ARABIC_PAGE.match(S):\n",
        "            continue\n",
        "        if ROMAN_LINE.match(S):\n",
        "            continue\n",
        "        if FILLER_LINE.match(S):\n",
        "            continue\n",
        "\n",
        "        # If it doesn't match a page number pattern, keep it (including headings)\n",
        "        kept.append(L)\n",
        "    return \"\\n\".join(kept)\n",
        "\n",
        "def smart_dehyphenate(s: str) -> str:\n",
        "    \"\"\"\n",
        "    Join end-of-line hyphens when the following line clearly continues the word\n",
        "    (i.e., starts with a lowercase letter).\n",
        "    Avoids joining across structural breaks or legitimate compound words.\n",
        "    \"\"\"\n",
        "    # Join standard hyphenated word parts (e.g., 'contin-uation' -> 'continuation')\n",
        "    s = re.sub(r'([A-Za-zÀ-ÿ]{2,})-\\n([a-zà-ÿ]{2,})', r'\\1\\2', s)\n",
        "    # Also handle cases where there might be leading whitespace/noise on the next line\n",
        "    s = re.sub(r'([A-Za-zÀ-ÿ]{2,})-\\n([^\\S\\r\\n]*[a-zà-ÿ]{1,})', r'\\1\\2', s)\n",
        "\n",
        "    # Simple heuristic to remove soft hyphens that were normalized to '-' *within* a line\n",
        "    s = re.sub(r'(\\w)-(\\w)', lambda m: m.group(1)+m.group(2) if len(m.group(1))>1 and len(m.group(2))>1 else m.group(0), s)\n",
        "    return s\n",
        "\n",
        "def normalize_whitespace_preserve_structure(s: str) -> str:\n",
        "    \"\"\"\n",
        "    Cleans up excessive spaces/newlines while trying to preserve paragraph breaks.\n",
        "    \"\"\"\n",
        "    # Normalize internal whitespace in paragraphs but preserve blank lines\n",
        "    paragraphs = re.split(r'\\n{2,}', s)\n",
        "    cleaned = []\n",
        "    for p in paragraphs:\n",
        "        # collapse spaces/tabs but keep single newlines inside blocks\n",
        "        p1 = re.sub(r'[ \\t]+', ' ', p.strip())\n",
        "        # collapse 3+ newlines to 2 within a 'paragraph' processing block if they exist\n",
        "        p1 = re.sub(r'\\n{3,}', '\\n\\n', p1)\n",
        "        cleaned.append(p1)\n",
        "    out = \"\\n\\n\".join([x for x in cleaned if x])\n",
        "    # final trim of trailing whitespace on lines\n",
        "    out = re.sub(r'[ \\t]+$', '', out, flags=re.MULTILINE)\n",
        "    return out\n",
        "\n",
        "def process(text: str) -> str:\n",
        "    \"\"\"Main processing pipeline.\"\"\"\n",
        "    t = normalize_glyphs(text)                   # 1) Unicode/Glyphs first\n",
        "    t = strip_scanner_artifacts(t)               # 2) Remove OCR noise artifacts\n",
        "    t = remove_page_numbers_and_fillers(t)       # 3) Remove ONLY page numbers/fillers\n",
        "    t = smart_dehyphenate(t)                     # 4) Join hyphenated words\n",
        "    t = fix_spaced_smallcaps(t)                  # 5) Fix \"L U D O V I C O\" -> \"LUDOVICO\"\n",
        "    t = normalize_whitespace_preserve_structure(t)# 6) Clean up spacing/newlines\n",
        "    return t\n",
        "\n",
        "# --- Execution ---\n",
        "\n",
        "def main():\n",
        "    try:\n",
        "        with open(INPUT_TEXT_FILE, 'r', encoding='utf-8') as f:\n",
        "            raw_text = f.read()\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Input file '{INPUT_TEXT_FILE}' not found.\")\n",
        "        return\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading input file: {e}\")\n",
        "        return\n",
        "\n",
        "    cleaned_text = process(raw_text)\n",
        "\n",
        "    try:\n",
        "        with open(OUTPUT_CLEANED_FILE, 'w', encoding='utf-8') as f:\n",
        "            f.write(cleaned_text)\n",
        "        print(f\"Successfully cleaned text written to '{OUTPUT_CLEANED_FILE}'\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error writing output file: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InBFXNu1EY2P"
      },
      "source": [
        "OK, so now let's clean this pre-processed text with Gemini"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvr06y-SEdAY",
        "outputId": "0b3b7692-016e-49c0-9f44-d875385739c2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/vertexai/generative_models/_generative_models.py:433: UserWarning: This feature is deprecated as of June 24, 2025 and will be removed on June 24, 2026. For details, see https://cloud.google.com/vertex-ai/generative-ai/docs/deprecations/genai-vertexai-sdk.\n",
            "  warning_logs.show_deprecation_warning()\n",
            "WARNING:root:REST async clients requires async credentials set using aiplatform.initializer._set_async_rest_credentials().\n",
            "Falling back to grpc since no async rest credentials were detected.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gemini Model 'gemini-2.5-flash' initialized successfully.\n",
            "\n",
            "Starting ASYNC OCR correction process on OCR_Error_Cleaned.txt...\n",
            "Created 138 tasks. Sending requests concurrently...\n",
            "  -> Finished processing chunk 131.\n",
            "  -> Finished processing chunk 23.\n",
            "  -> Finished processing chunk 52.\n",
            "  -> Finished processing chunk 5.\n",
            "  -> Finished processing chunk 6.\n",
            "  -> Finished processing chunk 106.\n",
            "  -> Finished processing chunk 123.\n",
            "  -> Finished processing chunk 46.\n",
            "  -> Finished processing chunk 44.\n",
            "  -> Finished processing chunk 111.\n",
            "  -> Finished processing chunk 42.\n",
            "  -> Finished processing chunk 21.\n",
            "  -> Finished processing chunk 80.\n",
            "  -> Finished processing chunk 98.\n",
            "  -> Finished processing chunk 110.\n",
            "  -> Finished processing chunk 41.\n",
            "  -> Finished processing chunk 102.\n",
            "  -> Finished processing chunk 95.\n",
            "  -> Finished processing chunk 75.\n",
            "  -> Finished processing chunk 121.\n",
            "  -> Finished processing chunk 2.\n",
            "  -> Finished processing chunk 7.\n",
            "  -> Finished processing chunk 39.\n",
            "  -> Finished processing chunk 101.\n",
            "  -> Finished processing chunk 60.\n",
            "  -> Finished processing chunk 57.\n",
            "  -> Finished processing chunk 127.\n",
            "  -> Finished processing chunk 125.\n",
            "  -> Finished processing chunk 78.\n",
            "  -> Finished processing chunk 28.\n",
            "  -> Finished processing chunk 50.\n",
            "  -> Finished processing chunk 138.\n",
            "  -> Finished processing chunk 56.\n",
            "  -> Finished processing chunk 14.\n",
            "  -> Finished processing chunk 35.\n",
            "  -> Finished processing chunk 37.\n",
            "  -> Finished processing chunk 115.\n",
            "  -> Finished processing chunk 87.\n",
            "  -> Finished processing chunk 43.\n",
            "  -> Finished processing chunk 58.\n",
            "  -> Finished processing chunk 109.\n",
            "  -> Finished processing chunk 16.\n",
            "  -> Finished processing chunk 20.\n",
            "  -> Finished processing chunk 54.\n",
            "  -> Finished processing chunk 82.\n",
            "  -> Finished processing chunk 25.\n",
            "  -> Finished processing chunk 65.\n",
            "  -> Finished processing chunk 126.\n",
            "  -> Finished processing chunk 103.\n",
            "  -> Finished processing chunk 122.\n",
            "  -> Finished processing chunk 120.\n",
            "  -> Finished processing chunk 84.\n",
            "  -> Finished processing chunk 59.\n",
            "  -> Finished processing chunk 69.\n",
            "  -> Finished processing chunk 53.\n",
            "  -> Finished processing chunk 24.\n",
            "  -> Finished processing chunk 26.\n",
            "  -> Finished processing chunk 90.\n",
            "  -> Finished processing chunk 32.\n",
            "  -> Finished processing chunk 85.\n",
            "  -> Finished processing chunk 136.\n",
            "  -> Finished processing chunk 79.\n",
            "  -> Finished processing chunk 11.\n",
            "  -> Finished processing chunk 129.\n",
            "  -> Finished processing chunk 89.\n",
            "  -> Finished processing chunk 137.\n",
            "  -> Finished processing chunk 108.\n",
            "  -> Finished processing chunk 30.\n",
            "  -> Finished processing chunk 134.\n",
            "  -> Finished processing chunk 33.\n",
            "  -> Finished processing chunk 100.\n",
            "  -> Finished processing chunk 81.\n",
            "  -> Finished processing chunk 34.\n",
            "  -> Finished processing chunk 13.\n",
            "  -> Finished processing chunk 3.\n",
            "  -> Finished processing chunk 40.\n",
            "  -> Finished processing chunk 10.\n",
            "  -> Finished processing chunk 114.\n",
            "  -> Finished processing chunk 135.\n",
            "  -> Finished processing chunk 8.\n",
            "  -> Finished processing chunk 117.\n",
            "  -> Finished processing chunk 91.\n",
            "  -> Finished processing chunk 12.\n",
            "  -> Finished processing chunk 119.\n",
            "  -> Finished processing chunk 93.\n",
            "  -> Finished processing chunk 105.\n",
            "  -> Finished processing chunk 116.\n",
            "  -> Finished processing chunk 118.\n",
            "  -> Finished processing chunk 72.\n",
            "  -> Finished processing chunk 112.\n",
            "  -> Finished processing chunk 63.\n",
            "  -> Finished processing chunk 124.\n",
            "  -> Finished processing chunk 113.\n",
            "  -> Finished processing chunk 99.\n",
            "  -> Finished processing chunk 96.\n",
            "  -> Finished processing chunk 22.\n",
            "  -> Finished processing chunk 51.\n",
            "  -> Finished processing chunk 68.\n",
            "  -> Finished processing chunk 18.\n",
            "  -> Finished processing chunk 92.\n",
            "  -> Finished processing chunk 74.\n",
            "  -> Finished processing chunk 94.\n",
            "  -> Finished processing chunk 83.\n",
            "  -> Finished processing chunk 47.\n",
            "  -> Finished processing chunk 19.\n",
            "  -> Finished processing chunk 107.\n",
            "  -> Finished processing chunk 104.\n",
            "  -> Finished processing chunk 4.\n",
            "  -> Finished processing chunk 132.\n",
            "  -> Finished processing chunk 128.\n",
            "  -> Finished processing chunk 36.\n",
            "  -> Finished processing chunk 17.\n",
            "  -> Finished processing chunk 29.\n",
            "  -> Finished processing chunk 55.\n",
            "  -> Finished processing chunk 76.\n",
            "  -> Finished processing chunk 86.\n",
            "  -> Finished processing chunk 66.\n",
            "  -> Finished processing chunk 130.\n",
            "  -> Finished processing chunk 71.\n",
            "  -> Finished processing chunk 49.\n",
            "  -> Finished processing chunk 88.\n",
            "  -> Finished processing chunk 67.\n",
            "  -> Finished processing chunk 31.\n",
            "  -> Finished processing chunk 64.\n",
            "  -> Finished processing chunk 97.\n",
            "  -> Finished processing chunk 38.\n",
            "  -> Finished processing chunk 9.\n",
            "  -> Finished processing chunk 48.\n",
            "  -> Finished processing chunk 62.\n",
            "  -> Finished processing chunk 61.\n",
            "  -> Finished processing chunk 70.\n",
            "  -> Finished processing chunk 1.\n",
            "  -> Finished processing chunk 73.\n",
            "  -> Finished processing chunk 77.\n",
            "  -> Finished processing chunk 45.\n",
            "  -> Finished processing chunk 133.\n",
            "  -> Finished processing chunk 27.\n",
            "  -> Finished processing chunk 15.\n",
            "\n",
            "--- Gemini ASYNC OCR Correction Pipeline Finished ---\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import asyncio\n",
        "import vertexai\n",
        "from vertexai.generative_models import GenerativeModel, Part\n",
        "\n",
        "# Use nest_asyncio to run async code easily in environments like Colab\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# --- Configuration Constants (Define these as per your environment) ---\n",
        "PROJECT_ID = 'renaissance-ocr'\n",
        "LOCATION = 'global'\n",
        "GEMINI_MODEL = 'gemini-2.5-flash'\n",
        "JSON_FILE_PATH = 'renaissance-ocr-4aabe5b8dc65.json'\n",
        "INPUT_TEXT_FILE = 'OCR_Error_Cleaned.txt'\n",
        "OUTPUT_CORRECTED_FILE = 'Corrected_Pre-Processed_OCR_Text_from_Archive3.txt'\n",
        "CHUNK_SIZE = 10000\n",
        "CORRECTION_PROMPT = \"\"\"\n",
        "You are an expert proofreader of early modern Latin. TASK: Correct ONLY OCR errors in the input text. Do not rewrite or alter authentic early modern usage. RULES: 1. Preserve the original wording, grammar, and syntax. Fix ONLY: - misread letters - broken or split words - incorrect or missing spacing - duplicated characters - corrupted punctuation caused by OCR 2. Apply minimal normalization (OLD conventions): - u = vowel, v = consonant - use i only (never j) - expand æ → ae, œ → oe - replace & or &amp; with et Do NOT modernize vocabulary or regularize historical spellings unless the form is clearly an OCR mistake. 3. This is very important: De hyphenate all words broken across line breaks: - remove hyphens that occur at the end of a line, - join the two fragments into a single continuous word, - and correct any spacing errors created by the line break. Also remove hyphens that belong to real Latin compounds, as hyphens are irrelevant. Do not add new punctuation. Do not retain paragraph breaks; just produce continuous text. 4. Keep all paragraph breaks and capitalization exactly as in the input. 5. Remove page furniture only when clearly not part of the running text: examples: “A ij”, “EPISTOLA.”, catchwords, signature marks. 6. Preserve Chinese or other exotic romanizations exactly as printed once corrected. Do NOT “improve,” standardize, or re interpret them (e.g., keep forms like “Tai Ki Gin”). 7. Output ONLY the corrected Latin text. Do NOT add commentary, explanation, or formatting.\n",
        "\"\"\"\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 1. Authenticate and Initialize the Vertex AI Client\n",
        "# -----------------------------------------------------------\n",
        "try:\n",
        "    if not os.path.exists(JSON_FILE_PATH):\n",
        "        print(f\"Credentials file not found at: {JSON_FILE_PATH}\")\n",
        "        raise FileNotFoundError(f\"Credentials file not found: {JSON_FILE_PATH}\")\n",
        "\n",
        "    os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = JSON_FILE_PATH\n",
        "    vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
        "    # Initialize the *one* model client we will reuse everywhere\n",
        "    model = GenerativeModel(GEMINI_MODEL)\n",
        "    print(f\"Gemini Model '{GEMINI_MODEL}' initialized successfully.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Authentication or client initialization failed: {e}\")\n",
        "    exit()\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 2. Define a function to read a file in chunks\n",
        "# -----------------------------------------------------------\n",
        "def read_in_chunks(file_path, chunk_size=CHUNK_SIZE):\n",
        "    # (This function remains the same)\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        while True:\n",
        "            chunk = f.read(chunk_size)\n",
        "            if not chunk:\n",
        "                break\n",
        "            yield chunk\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 3. Define an ASYNCHRONOUS function to correct a chunk\n",
        "# -----------------------------------------------------------\n",
        "async def correct_ocr_chunk_with_gemini_async(model_client, chunk_text, chunk_id):\n",
        "    \"\"\"Sends a text chunk to Gemini for correction asynchronously.\"\"\"\n",
        "\n",
        "    contents = [\n",
        "        CORRECTION_PROMPT,\n",
        "        chunk_text\n",
        "    ]\n",
        "\n",
        "    try:\n",
        "        # Await the response using the provided model_client instance\n",
        "        response = await model_client.generate_content_async(contents)\n",
        "\n",
        "        corrected_text = response.text.strip() or \"\"\n",
        "        print(f\"  -> Finished processing chunk {chunk_id}.\")\n",
        "        return chunk_id, corrected_text # Return ID to sort results later\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"API call failed for chunk {chunk_id}: {e}\")\n",
        "        return chunk_id, chunk_text # Return original text if API fails\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 4. Main asynchronous execution block\n",
        "# -----------------------------------------------------------\n",
        "async def main():\n",
        "    if not os.path.exists(INPUT_TEXT_FILE):\n",
        "        print(f\"Input file '{INPUT_TEXT_FILE}' not found. Ensure it is uploaded or available.\")\n",
        "        return\n",
        "\n",
        "    print(f\"\\nStarting ASYNC OCR correction process on {INPUT_TEXT_FILE}...\")\n",
        "\n",
        "    tasks = []\n",
        "    chunk_count = 0\n",
        "    for chunk in read_in_chunks(INPUT_TEXT_FILE, CHUNK_SIZE):\n",
        "        chunk_count += 1\n",
        "        # Pass the initialized 'model' instance to the async function\n",
        "        tasks.append(correct_ocr_chunk_with_gemini_async(model, chunk, chunk_count))\n",
        "\n",
        "    print(f\"Created {len(tasks)} tasks. Sending requests concurrently...\")\n",
        "\n",
        "    results = await asyncio.gather(*tasks, return_exceptions=True)\n",
        "\n",
        "    processed_results = []\n",
        "    for res in results:\n",
        "        if isinstance(res, Exception):\n",
        "            print(f\"An exception occurred during one of the API calls: {res}\")\n",
        "        else:\n",
        "            processed_results.append(res)\n",
        "\n",
        "    processed_results.sort(key=lambda x: x[0]) # Sort by the chunk_id (index 0)\n",
        "\n",
        "    with open(OUTPUT_CORRECTED_FILE, 'w', encoding='utf-8') as f_out:\n",
        "        for chunk_id, corrected_chunk in processed_results:\n",
        "            if corrected_chunk:\n",
        "                f_out.write(corrected_chunk + \"\\n\\n\")\n",
        "\n",
        "    print(f\"\\n--- Gemini ASYNC OCR Correction Pipeline Finished ---\")\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 5. Run the asynchronous main function in Colab\n",
        "# -----------------------------------------------------------\n",
        "if __name__ == '__main__':\n",
        "    # asyncio.run handles running the async main loop\n",
        "    asyncio.run(main())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBnjRU-NhA6P"
      },
      "source": [
        "Let's try it with the medical text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xwNGAp8hDVA",
        "outputId": "721b29d6-c108-425f-9576-61cfdf14e1c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully cleaned text written to 'Medicinae_OCR_Error_Cleaned.txt'\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "import re\n",
        "import unicodedata\n",
        "from pathlib import Path\n",
        "import os\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "# --- Configuration (Kept simple) ---\n",
        "INPUT_TEXT_FILE  = 'BIUSante_154971_djvu.txt'\n",
        "OUTPUT_CLEANED_FILE = 'Medicinae_OCR_Error_Cleaned.txt'\n",
        "\n",
        "# Map curly quotes/dashes/ligatures/OCR errors\n",
        "PUNCT_MAP = {\n",
        "    '\\u017F': 's',         # long s (ſ)\n",
        "    'æ': 'ae', 'Æ': 'AE',\n",
        "    'œ': 'oe', 'Œ': 'OE',\n",
        "    '\\u2018': \"'\", '\\u2019': \"'\", '\\u201A': ',', '\\u201B': \"'\",\n",
        "    '\\u201C': '\"', '\\u201D': '\"', '\\u201E': '\"',\n",
        "    '\\u2013': '-', '\\u2014': '-', '\\u2212': '-',   # en/em/minus → hyphen\n",
        "    '\\u00AD': '-',                                 # soft hyphen → hyphen\n",
        "    '\\u00A0': ' ', '\\u2002': ' ', '\\u2003': ' ', '\\u2009': ' ', # spaces\n",
        "}\n",
        "\n",
        "# --- Patterns for Removal (Page Numbers Only) ---\n",
        "\n",
        "# Roman-only line (common for front matter page numbers)\n",
        "# Requires at least one character and optional surrounding whitespace/periods.\n",
        "ROMAN_LINE = re.compile(r'^\\s*[IVXLCDM]+\\.*\\s*$')\n",
        "\n",
        "# A page-number line: bare arabic up to 4 digits\n",
        "ARABIC_PAGE = re.compile(r'^\\s*\\d{1,4}\\s*$')\n",
        "\n",
        "# Centered dot filler or dot leaders which often appear with page numbers in TOCs\n",
        "FILLER_LINE = re.compile(r'^\\s*[•·.\\u2022]{3,}\\s*$')\n",
        "\n",
        "\n",
        "# --- Patterns for Fixing OCR Errors ---\n",
        "\n",
        "# A token of single-letter small-caps separated by spaces: \"L U D O V I C O\"\n",
        "SPACED_SMALLCAPS = re.compile(r'\\b(?:[A-Z]\\s){2,}[A-Z]\\b')\n",
        "\n",
        "\n",
        "# --- Utilities ---\n",
        "\n",
        "def normalize_glyphs(s: str) -> str:\n",
        "    \"\"\"Standardize unicode punctuation, ligatures, and OCR noise characters.\"\"\"\n",
        "    for k, v in PUNCT_MAP.items():\n",
        "        s = s.replace(k, v)\n",
        "    s = unicodedata.normalize('NFKC', s)\n",
        "    return s\n",
        "\n",
        "def strip_scanner_artifacts(s: str) -> str:\n",
        "    \"\"\"Remove common stray OCR artifacts like escaped parentheses/backslashes.\"\"\"\n",
        "    s = s.replace('\\\\(', '(').replace('\\\\)', ')')\n",
        "    # collapse runs of stray backslashes left by OCR\n",
        "    s = re.sub(r'\\\\{2,}', r'\\\\', s)\n",
        "    return s\n",
        "\n",
        "def fix_spaced_smallcaps(s: str) -> str:\n",
        "    \"\"\"Join sequences like \"L U D O V I C O\" -> \"LUDOVICO\".\"\"\"\n",
        "    def _join(m):\n",
        "        return m.group(0).replace(' ', '')\n",
        "    return SPACED_SMALLCAPS.sub(_join, s)\n",
        "\n",
        "def remove_page_numbers_and_fillers(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Iterates through lines and removes only lines matching known page number formats\n",
        "    or filler dots/leaders.\n",
        "    \"\"\"\n",
        "    lines = text.splitlines()\n",
        "    kept = []\n",
        "    for L in lines:\n",
        "        S = L.strip()\n",
        "        if not S:\n",
        "            kept.append(L) # Keep blank lines\n",
        "            continue\n",
        "\n",
        "        # Explicitly remove only identified page furniture\n",
        "        if ARABIC_PAGE.match(S):\n",
        "            continue\n",
        "        if ROMAN_LINE.match(S):\n",
        "            continue\n",
        "        if FILLER_LINE.match(S):\n",
        "            continue\n",
        "\n",
        "        # If it doesn't match a page number pattern, keep it (including headings)\n",
        "        kept.append(L)\n",
        "    return \"\\n\".join(kept)\n",
        "\n",
        "def smart_dehyphenate(s: str) -> str:\n",
        "    \"\"\"\n",
        "    Join end-of-line hyphens when the following line clearly continues the word\n",
        "    (i.e., starts with a lowercase letter).\n",
        "    Avoids joining across structural breaks or legitimate compound words.\n",
        "    \"\"\"\n",
        "    # Join standard hyphenated word parts (e.g., 'contin-uation' -> 'continuation')\n",
        "    s = re.sub(r'([A-Za-zÀ-ÿ]{2,})-\\n([a-zà-ÿ]{2,})', r'\\1\\2', s)\n",
        "    # Also handle cases where there might be leading whitespace/noise on the next line\n",
        "    s = re.sub(r'([A-Za-zÀ-ÿ]{2,})-\\n([^\\S\\r\\n]*[a-zà-ÿ]{1,})', r'\\1\\2', s)\n",
        "\n",
        "    # Simple heuristic to remove soft hyphens that were normalized to '-' *within* a line\n",
        "    s = re.sub(r'(\\w)-(\\w)', lambda m: m.group(1)+m.group(2) if len(m.group(1))>1 and len(m.group(2))>1 else m.group(0), s)\n",
        "    return s\n",
        "\n",
        "def normalize_whitespace_preserve_structure(s: str) -> str:\n",
        "    \"\"\"\n",
        "    Cleans up excessive spaces/newlines while trying to preserve paragraph breaks.\n",
        "    \"\"\"\n",
        "    # Normalize internal whitespace in paragraphs but preserve blank lines\n",
        "    paragraphs = re.split(r'\\n{2,}', s)\n",
        "    cleaned = []\n",
        "    for p in paragraphs:\n",
        "        # collapse spaces/tabs but keep single newlines inside blocks\n",
        "        p1 = re.sub(r'[ \\t]+', ' ', p.strip())\n",
        "        # collapse 3+ newlines to 2 within a 'paragraph' processing block if they exist\n",
        "        p1 = re.sub(r'\\n{3,}', '\\n\\n', p1)\n",
        "        cleaned.append(p1)\n",
        "    out = \"\\n\\n\".join([x for x in cleaned if x])\n",
        "    # final trim of trailing whitespace on lines\n",
        "    out = re.sub(r'[ \\t]+$', '', out, flags=re.MULTILINE)\n",
        "    return out\n",
        "\n",
        "def process(text: str) -> str:\n",
        "    \"\"\"Main processing pipeline.\"\"\"\n",
        "    t = normalize_glyphs(text)                   # 1) Unicode/Glyphs first\n",
        "    t = strip_scanner_artifacts(t)               # 2) Remove OCR noise artifacts\n",
        "    t = remove_page_numbers_and_fillers(t)       # 3) Remove ONLY page numbers/fillers\n",
        "    t = smart_dehyphenate(t)                     # 4) Join hyphenated words\n",
        "    t = fix_spaced_smallcaps(t)                  # 5) Fix \"L U D O V I C O\" -> \"LUDOVICO\"\n",
        "    t = normalize_whitespace_preserve_structure(t)# 6) Clean up spacing/newlines\n",
        "    return t\n",
        "\n",
        "# --- Execution ---\n",
        "\n",
        "def main():\n",
        "    try:\n",
        "        with open(INPUT_TEXT_FILE, 'r', encoding='utf-8') as f:\n",
        "            raw_text = f.read()\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Input file '{INPUT_TEXT_FILE}' not found.\")\n",
        "        return\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading input file: {e}\")\n",
        "        return\n",
        "\n",
        "    cleaned_text = process(raw_text)\n",
        "\n",
        "    try:\n",
        "        with open(OUTPUT_CLEANED_FILE, 'w', encoding='utf-8') as f:\n",
        "            f.write(cleaned_text)\n",
        "        print(f\"Successfully cleaned text written to '{OUTPUT_CLEANED_FILE}'\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error writing output file: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zz-U9zchgje"
      },
      "source": [
        "And now let's clean up the medical text with Gemini"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSP0gfp1hi3E",
        "outputId": "b26b7655-6db5-47d6-ecbf-1ed715268ea7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/vertexai/generative_models/_generative_models.py:433: UserWarning: This feature is deprecated as of June 24, 2025 and will be removed on June 24, 2026. For details, see https://cloud.google.com/vertex-ai/generative-ai/docs/deprecations/genai-vertexai-sdk.\n",
            "  warning_logs.show_deprecation_warning()\n",
            "WARNING:root:REST async clients requires async credentials set using aiplatform.initializer._set_async_rest_credentials().\n",
            "Falling back to grpc since no async rest credentials were detected.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gemini Model 'gemini-2.5-flash' initialized successfully.\n",
            "\n",
            "Starting ASYNC OCR correction process on Medicinae_OCR_Error_Cleaned.txt...\n",
            "Created 46 tasks. Sending requests concurrently...\n",
            "  -> Finished processing chunk 46.\n",
            "  -> Finished processing chunk 10.\n",
            "  -> Finished processing chunk 39.\n",
            "  -> Finished processing chunk 35.\n",
            "  -> Finished processing chunk 41.\n",
            "  -> Finished processing chunk 45.\n",
            "  -> Finished processing chunk 5.\n",
            "  -> Finished processing chunk 6.\n",
            "  -> Finished processing chunk 21.\n",
            "  -> Finished processing chunk 11.\n",
            "  -> Finished processing chunk 25.\n",
            "  -> Finished processing chunk 40.\n",
            "  -> Finished processing chunk 26.\n",
            "  -> Finished processing chunk 32.\n",
            "  -> Finished processing chunk 37.\n",
            "  -> Finished processing chunk 8.\n",
            "  -> Finished processing chunk 7.\n",
            "  -> Finished processing chunk 44.\n",
            "  -> Finished processing chunk 2.\n",
            "  -> Finished processing chunk 22.\n",
            "  -> Finished processing chunk 34.\n",
            "  -> Finished processing chunk 42.\n",
            "  -> Finished processing chunk 23.\n",
            "  -> Finished processing chunk 19.\n",
            "  -> Finished processing chunk 24.\n",
            "  -> Finished processing chunk 16.\n",
            "  -> Finished processing chunk 18.\n",
            "  -> Finished processing chunk 27.\n",
            "  -> Finished processing chunk 4.\n",
            "  -> Finished processing chunk 1.\n",
            "  -> Finished processing chunk 15.\n",
            "  -> Finished processing chunk 29.\n",
            "  -> Finished processing chunk 30.\n",
            "  -> Finished processing chunk 33.\n",
            "  -> Finished processing chunk 31.\n",
            "  -> Finished processing chunk 36.\n",
            "  -> Finished processing chunk 9.\n",
            "  -> Finished processing chunk 17.\n",
            "  -> Finished processing chunk 43.\n",
            "  -> Finished processing chunk 28.\n",
            "  -> Finished processing chunk 20.\n",
            "  -> Finished processing chunk 38.\n",
            "  -> Finished processing chunk 12.\n",
            "  -> Finished processing chunk 13.\n",
            "  -> Finished processing chunk 3.\n",
            "  -> Finished processing chunk 14.\n",
            "\n",
            "--- Gemini ASYNC OCR Correction Pipeline Finished ---\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import asyncio\n",
        "import vertexai\n",
        "from vertexai.generative_models import GenerativeModel, Part\n",
        "\n",
        "# Use nest_asyncio to run async code easily in environments like Colab\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# --- Configuration Constants (Define these as per your environment) ---\n",
        "PROJECT_ID = 'renaissance-ocr'\n",
        "LOCATION = 'global'\n",
        "GEMINI_MODEL = 'gemini-2.5-flash'\n",
        "JSON_FILE_PATH = 'renaissance-ocr-4aabe5b8dc65.json'\n",
        "INPUT_TEXT_FILE = 'Medicinae_OCR_Error_Cleaned.txt'\n",
        "OUTPUT_CORRECTED_FILE = 'Gemini_Medicinae_OCR_Error_Cleaned.txt'\n",
        "CHUNK_SIZE = 10000\n",
        "CORRECTION_PROMPT = \"\"\"\n",
        "You are an expert proofreader of early modern Latin. TASK: Correct ONLY OCR errors in the input text. Do not rewrite or alter authentic early modern usage. RULES: 1. Preserve the original wording, grammar, and syntax. Fix ONLY: - misread letters - broken or split words - incorrect or missing spacing - duplicated characters - corrupted punctuation caused by OCR 2. Apply minimal normalization (OLD conventions): - u = vowel, v = consonant - use i only (never j) - expand æ → ae, œ → oe - replace & or &amp; with et Do NOT modernize vocabulary or regularize historical spellings unless the form is clearly an OCR mistake. 3. This is very important: De hyphenate all words broken across line breaks: - remove hyphens that occur at the end of a line, - join the two fragments into a single continuous word, - and correct any spacing errors created by the line break. Also remove hyphens that belong to real Latin compounds, as hyphens are irrelevant. Do not add new punctuation. Do not retain paragraph breaks; just produce continuous text. 4. Keep all paragraph breaks and capitalization exactly as in the input. 5. Remove page furniture only when clearly not part of the running text: examples: “A ij”, “EPISTOLA.”, catchwords, signature marks. 6. Preserve Chinese or other exotic romanizations exactly as printed once corrected. Do NOT “improve,” standardize, or re interpret them (e.g., keep forms like “Tai Ki Gin”). 7. Output ONLY the corrected Latin text. Do NOT add commentary, explanation, or formatting.\n",
        "\"\"\"\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 1. Authenticate and Initialize the Vertex AI Client\n",
        "# -----------------------------------------------------------\n",
        "try:\n",
        "    if not os.path.exists(JSON_FILE_PATH):\n",
        "        print(f\"Credentials file not found at: {JSON_FILE_PATH}\")\n",
        "        raise FileNotFoundError(f\"Credentials file not found: {JSON_FILE_PATH}\")\n",
        "\n",
        "    os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = JSON_FILE_PATH\n",
        "    vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
        "    # Initialize the *one* model client we will reuse everywhere\n",
        "    model = GenerativeModel(GEMINI_MODEL)\n",
        "    print(f\"Gemini Model '{GEMINI_MODEL}' initialized successfully.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Authentication or client initialization failed: {e}\")\n",
        "    exit()\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 2. Define a function to read a file in chunks\n",
        "# -----------------------------------------------------------\n",
        "def read_in_chunks(file_path, chunk_size=CHUNK_SIZE):\n",
        "    # (This function remains the same)\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        while True:\n",
        "            chunk = f.read(chunk_size)\n",
        "            if not chunk:\n",
        "                break\n",
        "            yield chunk\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 3. Define an ASYNCHRONOUS function to correct a chunk\n",
        "# -----------------------------------------------------------\n",
        "async def correct_ocr_chunk_with_gemini_async(model_client, chunk_text, chunk_id):\n",
        "    \"\"\"Sends a text chunk to Gemini for correction asynchronously.\"\"\"\n",
        "\n",
        "    contents = [\n",
        "        CORRECTION_PROMPT,\n",
        "        chunk_text\n",
        "    ]\n",
        "\n",
        "    try:\n",
        "        # Await the response using the provided model_client instance\n",
        "        response = await model_client.generate_content_async(contents)\n",
        "\n",
        "        corrected_text = response.text.strip() or \"\"\n",
        "        print(f\"  -> Finished processing chunk {chunk_id}.\")\n",
        "        return chunk_id, corrected_text # Return ID to sort results later\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"API call failed for chunk {chunk_id}: {e}\")\n",
        "        return chunk_id, chunk_text # Return original text if API fails\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 4. Main asynchronous execution block\n",
        "# -----------------------------------------------------------\n",
        "async def main():\n",
        "    if not os.path.exists(INPUT_TEXT_FILE):\n",
        "        print(f\"Input file '{INPUT_TEXT_FILE}' not found. Ensure it is uploaded or available.\")\n",
        "        return\n",
        "\n",
        "    print(f\"\\nStarting ASYNC OCR correction process on {INPUT_TEXT_FILE}...\")\n",
        "\n",
        "    tasks = []\n",
        "    chunk_count = 0\n",
        "    for chunk in read_in_chunks(INPUT_TEXT_FILE, CHUNK_SIZE):\n",
        "        chunk_count += 1\n",
        "        # Pass the initialized 'model' instance to the async function\n",
        "        tasks.append(correct_ocr_chunk_with_gemini_async(model, chunk, chunk_count))\n",
        "\n",
        "    print(f\"Created {len(tasks)} tasks. Sending requests concurrently...\")\n",
        "\n",
        "    results = await asyncio.gather(*tasks, return_exceptions=True)\n",
        "\n",
        "    processed_results = []\n",
        "    for res in results:\n",
        "        if isinstance(res, Exception):\n",
        "            print(f\"An exception occurred during one of the API calls: {res}\")\n",
        "        else:\n",
        "            processed_results.append(res)\n",
        "\n",
        "    processed_results.sort(key=lambda x: x[0]) # Sort by the chunk_id (index 0)\n",
        "\n",
        "    with open(OUTPUT_CORRECTED_FILE, 'w', encoding='utf-8') as f_out:\n",
        "        for chunk_id, corrected_chunk in processed_results:\n",
        "            if corrected_chunk:\n",
        "                f_out.write(corrected_chunk + \"\\n\\n\")\n",
        "\n",
        "    print(f\"\\n--- Gemini ASYNC OCR Correction Pipeline Finished ---\")\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 5. Run the asynchronous main function in Colab\n",
        "# -----------------------------------------------------------\n",
        "if __name__ == '__main__':\n",
        "    # asyncio.run handles running the async main loop\n",
        "    asyncio.run(main())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQzpEqn2Tw3B"
      },
      "source": [
        "OK, now let's try a Spanish text, Mendoza's Historia del gran reyno de la China."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_pVX9KCT2co",
        "outputId": "26396e87-2cc5-424b-8021-1329afc8f497"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully cleaned text written to 'OCR_Error_Cleaned_Spanish.txt'\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "import re\n",
        "import unicodedata\n",
        "from pathlib import Path\n",
        "import os\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "# --- Configuration (Kept simple) ---\n",
        "INPUT_TEXT_FILE  = 'bub_gb_6QiHhHwp8MMC_djvu.txt'\n",
        "OUTPUT_CLEANED_FILE = 'OCR_Error_Cleaned_Spanish.txt'\n",
        "\n",
        "# Character ranges for Spanish-inclusive alphanumeric (A-Z, a-z, plus accents and ñ)\n",
        "SPANISH_ALPHA_PATTERN = r'[A-Za-z\\u00C0-\\u017F]'\n",
        "\n",
        "# Map curly quotes/dashes/ligatures/OCR errors\n",
        "PUNCT_MAP = {\n",
        "    '\\u017F': 's',         # long s (ſ)\n",
        "    'æ': 'ae', 'Æ': 'AE',\n",
        "    'œ': 'oe', 'Œ': 'OE',\n",
        "    '\\u2018': \"'\", '\\u2019': \"'\", '\\u201A': ',', '\\u201B': \"'\", # quotes\n",
        "    '\\u201C': '\"', '\\u201D': '\"', '\\u201E': '\"',\n",
        "    '\\u2013': '-', '\\u2014': '-', '\\u2212': '-',   # en/em/minus → hyphen\n",
        "    '\\u00AD': '-',                                 # soft hyphen → hyphen\n",
        "    '\\u00A0': ' ', '\\u2002': ' ', '\\u2003': ' ', '\\u2009': ' ', # spaces\n",
        "    # Specific OCR errors for Spanish (e.g. n followed by tilde symbol as two chars)\n",
        "    'ñ': 'ñ',\n",
        "    'Ñ': 'Ñ',\n",
        "}\n",
        "\n",
        "# --- Patterns for Removal (Page Numbers Only) ---\n",
        "\n",
        "# Roman-only line (common for front matter page numbers)\n",
        "ROMAN_LINE = re.compile(r'^\\s*[IVXLCDM]+\\.*\\s*$', re.IGNORECASE)\n",
        "\n",
        "# A page-number line: bare arabic up to 4 digits\n",
        "ARABIC_PAGE = re.compile(r'^\\s*\\d{1,4}\\s*$')\n",
        "\n",
        "# Centered dot filler or dot leaders which often appear with page numbers in TOCs\n",
        "FILLER_LINE = re.compile(r'^\\s*[•·.\\u2022]{3,}\\s*$')\n",
        "\n",
        "\n",
        "# --- Patterns for Fixing OCR Errors ---\n",
        "\n",
        "# A token of single-letter small-caps separated by spaces: \"L U D O V I C O\"\n",
        "SPACED_SMALLCAPS = re.compile(r'\\b(?:[A-Z]\\s){2,}[A-Z]\\b')\n",
        "\n",
        "\n",
        "# --- Utilities ---\n",
        "\n",
        "def normalize_glyphs_spanish(s: str) -> str:\n",
        "    \"\"\"Standardize unicode punctuation, ligatures, and OCR noise characters.\"\"\"\n",
        "    for k, v in PUNCT_MAP.items():\n",
        "        s = s.replace(k, v)\n",
        "    # NFKC normalizes many common presentation forms into canonical forms (e.g. ligatures if they weren't in PUNCT_MAP)\n",
        "    s = unicodedata.normalize('NFKC', s)\n",
        "    return s\n",
        "\n",
        "def strip_scanner_artifacts(s: str) -> str:\n",
        "    \"\"\"Remove common stray OCR artifacts like escaped parentheses/backslashes.\"\"\"\n",
        "    s = s.replace('\\\\(', '(').replace('\\\\)', ')')\n",
        "    # collapse runs of stray backslashes left by OCR\n",
        "    s = re.sub(r'\\\\{2,}', r'\\\\', s)\n",
        "    return s\n",
        "\n",
        "def fix_spaced_smallcaps(s: str) -> str:\n",
        "    \"\"\"Join sequences like \"L U D O V I C O\" -> \"LUDOVICO\".\"\"\"\n",
        "    def _join(m):\n",
        "        return m.group(0).replace(' ', '')\n",
        "    return SPACED_SMALLCAPS.sub(_join, s)\n",
        "\n",
        "def remove_page_numbers_and_fillers(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Iterates through lines and removes only lines matching known page number formats\n",
        "    or filler dots/leaders.\n",
        "    \"\"\"\n",
        "    lines = text.splitlines()\n",
        "    kept = []\n",
        "    for L in lines:\n",
        "        S = L.strip()\n",
        "        if not S:\n",
        "            kept.append(L) # Keep blank lines\n",
        "            continue\n",
        "\n",
        "        # Explicitly remove only identified page furniture\n",
        "        if ARABIC_PAGE.match(S):\n",
        "            continue\n",
        "        if ROMAN_LINE.match(S):\n",
        "            continue\n",
        "        if FILLER_LINE.match(S):\n",
        "            continue\n",
        "\n",
        "        # If it doesn't match a page number pattern, keep it\n",
        "        kept.append(L)\n",
        "    return \"\\n\".join(kept)\n",
        "\n",
        "def smart_dehyphenate_spanish(s: str) -> str:\n",
        "    \"\"\"\n",
        "    Join end-of-line hyphens when the following line clearly continues the word\n",
        "    (i.e., starts with a lowercase letter, including Spanish accented lowercase).\n",
        "    \"\"\"\n",
        "    # Regex pattern to match a hyphen at the end of a line followed by a word starting with a lowercase char.\n",
        "    # We use the defined SPANISH_ALPHA_PATTERN for robustness.\n",
        "    lowercase_alpha_range = r'[a-z\\u00E0-\\u00FF]'\n",
        "\n",
        "    # Pattern 1: Match multi-char word part, hyphen, newline, multi-char lowercase word part\n",
        "    pattern_eol = re.compile(rf'({SPANISH_ALPHA_PATTERN}{{2,}})-\\n({lowercase_alpha_range}{{2,}})', re.MULTILINE)\n",
        "    s = pattern_eol.sub(r'\\1\\2', s)\n",
        "\n",
        "    # Pattern 2: Also handle cases where there might be leading whitespace/noise on the next line before lowercase char\n",
        "    pattern_eol_whitespace = re.compile(rf'({SPANISH_ALPHA_PATTERN}{{2,}})-\\n([^\\S\\r\\n]*{lowercase_alpha_range}{{1,}})', re.MULTILINE)\n",
        "    s = pattern_eol_whitespace.sub(r'\\1\\2', s)\n",
        "\n",
        "    # Simple heuristic to remove soft hyphens that were normalized to '-' *within* a line\n",
        "    # Only join if both sides of the hyphen are at least two characters long, to avoid joining legitimate compound words like 'well-being' (though less common in Spanish)\n",
        "    pattern_in_line = re.compile(r'(\\w)-(\\w)')\n",
        "    s = pattern_in_line.sub(lambda m: m.group(1)+m.group(2) if len(m.group(1))>1 and len(m.group(2))>1 else m.group(0), s)\n",
        "\n",
        "    return s\n",
        "\n",
        "def normalize_whitespace_preserve_structure(s: str) -> str:\n",
        "    \"\"\"\n",
        "    Cleans up excessive spaces/newlines while trying to preserve paragraph breaks.\n",
        "    \"\"\"\n",
        "    # Normalize internal whitespace in paragraphs but preserve blank lines\n",
        "    paragraphs = re.split(r'\\n{2,}', s)\n",
        "    cleaned = []\n",
        "    for p in paragraphs:\n",
        "        # collapse spaces/tabs but keep single newlines inside blocks\n",
        "        p1 = re.sub(r'[ \\t]+', ' ', p.strip())\n",
        "        # collapse 3+ newlines to 2 within a 'paragraph' processing block if they exist\n",
        "        p1 = re.sub(r'\\n{3,}', '\\n\\n', p1)\n",
        "        cleaned.append(p1)\n",
        "    out = \"\\n\\n\".join([x for x in cleaned if x])\n",
        "    # final trim of trailing whitespace on lines\n",
        "    out = re.sub(r'[ \\t]+$', '', out, flags=re.MULTILINE)\n",
        "    return out\n",
        "\n",
        "def process(text: str) -> str:\n",
        "    \"\"\"Main processing pipeline for Early Modern Spanish OCR.\"\"\"\n",
        "    t = normalize_glyphs_spanish(text)            # 1) Unicode/Glyphs first (includes ñ fixes)\n",
        "    t = strip_scanner_artifacts(t)               # 2) Remove OCR noise artifacts\n",
        "    t = remove_page_numbers_and_fillers(t)       # 3) Remove ONLY page numbers/fillers\n",
        "    t = smart_dehyphenate_spanish(t)             # 4) Join hyphenated words (Spanish specific regex)\n",
        "    t = fix_spaced_smallcaps(t)                  # 5) Fix \"L U D O V I C O\" -> \"LUDOVICO\"\n",
        "    t = normalize_whitespace_preserve_structure(t)# 6) Clean up spacing/newlines\n",
        "    return t\n",
        "\n",
        "# --- Execution ---\n",
        "\n",
        "def main():\n",
        "    try:\n",
        "        with open(INPUT_TEXT_FILE, 'r', encoding='utf-8') as f:\n",
        "            raw_text = f.read()\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Input file '{INPUT_TEXT_FILE}' not found.\")\n",
        "        return\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading input file: {e}\")\n",
        "        return\n",
        "\n",
        "    cleaned_text = process(raw_text)\n",
        "\n",
        "    try:\n",
        "        with open(OUTPUT_CLEANED_FILE, 'w', encoding='utf-8') as f:\n",
        "            f.write(cleaned_text)\n",
        "        print(f\"Successfully cleaned text written to '{OUTPUT_CLEANED_FILE}'\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error writing output file: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2kkkWILUa3_"
      },
      "source": [
        "**Now let's clean it with Gemini**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yu7MqhFLUbGl",
        "outputId": "807759e1-2726-4f65-f01d-7d4aa680d0ce"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/vertexai/generative_models/_generative_models.py:433: UserWarning: This feature is deprecated as of June 24, 2025 and will be removed on June 24, 2026. For details, see https://cloud.google.com/vertex-ai/generative-ai/docs/deprecations/genai-vertexai-sdk.\n",
            "  warning_logs.show_deprecation_warning()\n",
            "WARNING:root:REST async clients requires async credentials set using aiplatform.initializer._set_async_rest_credentials().\n",
            "Falling back to grpc since no async rest credentials were detected.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gemini Model 'gemini-2.5-flash' initialized successfully.\n",
            "\n",
            "Starting ASYNC OCR correction process on OCR_Error_Cleaned_Spanish.txt...\n",
            "Created 75 tasks. Sending requests concurrently...\n",
            "  -> Finished processing chunk 70.\n",
            "  -> Finished processing chunk 62.\n",
            "  -> Finished processing chunk 36.\n",
            "  -> Finished processing chunk 9.\n",
            "  -> Finished processing chunk 24.\n",
            "  -> Finished processing chunk 64.\n",
            "  -> Finished processing chunk 72.\n",
            "  -> Finished processing chunk 66.\n",
            "  -> Finished processing chunk 21.\n",
            "  -> Finished processing chunk 61.\n",
            "  -> Finished processing chunk 13.\n",
            "  -> Finished processing chunk 27.\n",
            "  -> Finished processing chunk 6.\n",
            "  -> Finished processing chunk 5.\n",
            "  -> Finished processing chunk 8.\n",
            "  -> Finished processing chunk 19.\n",
            "  -> Finished processing chunk 58.\n",
            "  -> Finished processing chunk 67.\n",
            "  -> Finished processing chunk 14.\n",
            "  -> Finished processing chunk 47.\n",
            "  -> Finished processing chunk 26.\n",
            "  -> Finished processing chunk 45.\n",
            "  -> Finished processing chunk 42.\n",
            "  -> Finished processing chunk 15.\n",
            "  -> Finished processing chunk 50.\n",
            "  -> Finished processing chunk 65.\n",
            "  -> Finished processing chunk 52.\n",
            "  -> Finished processing chunk 56.\n",
            "  -> Finished processing chunk 38.\n",
            "  -> Finished processing chunk 59.\n",
            "  -> Finished processing chunk 2.\n",
            "  -> Finished processing chunk 22.\n",
            "  -> Finished processing chunk 32.\n",
            "  -> Finished processing chunk 20.\n",
            "  -> Finished processing chunk 33.\n",
            "  -> Finished processing chunk 12.\n",
            "  -> Finished processing chunk 31.\n",
            "  -> Finished processing chunk 54.\n",
            "  -> Finished processing chunk 55.\n",
            "  -> Finished processing chunk 34.\n",
            "  -> Finished processing chunk 7.\n",
            "  -> Finished processing chunk 75.\n",
            "  -> Finished processing chunk 48.\n",
            "  -> Finished processing chunk 63.\n",
            "  -> Finished processing chunk 18.\n",
            "  -> Finished processing chunk 11.\n",
            "  -> Finished processing chunk 71.\n",
            "  -> Finished processing chunk 37.\n",
            "  -> Finished processing chunk 41.\n",
            "  -> Finished processing chunk 4.\n",
            "  -> Finished processing chunk 40.\n",
            "  -> Finished processing chunk 39.\n",
            "  -> Finished processing chunk 69.\n",
            "  -> Finished processing chunk 1.\n",
            "  -> Finished processing chunk 68.\n",
            "  -> Finished processing chunk 60.\n",
            "  -> Finished processing chunk 17.\n",
            "  -> Finished processing chunk 25.\n",
            "  -> Finished processing chunk 10.\n",
            "  -> Finished processing chunk 49.\n",
            "  -> Finished processing chunk 16.\n",
            "  -> Finished processing chunk 43.\n",
            "  -> Finished processing chunk 74.\n",
            "  -> Finished processing chunk 73.\n",
            "  -> Finished processing chunk 28.\n",
            "  -> Finished processing chunk 23.\n",
            "  -> Finished processing chunk 30.\n",
            "  -> Finished processing chunk 46.\n",
            "  -> Finished processing chunk 35.\n",
            "  -> Finished processing chunk 29.\n",
            "  -> Finished processing chunk 53.\n",
            "  -> Finished processing chunk 3.\n",
            "  -> Finished processing chunk 44.\n",
            "  -> Finished processing chunk 51.\n",
            "  -> Finished processing chunk 57.\n",
            "\n",
            "--- Gemini ASYNC OCR Correction Pipeline Finished ---\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import asyncio\n",
        "import vertexai\n",
        "from vertexai.generative_models import GenerativeModel, Part\n",
        "\n",
        "# Use nest_asyncio to run async code easily in environments like Colab\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# --- Configuration Constants (Define these as per your environment) ---\n",
        "PROJECT_ID = 'renaissance-ocr'\n",
        "LOCATION = 'global'\n",
        "GEMINI_MODEL = 'gemini-2.5-flash'\n",
        "JSON_FILE_PATH = 'renaissance-ocr-4aabe5b8dc65.json'\n",
        "INPUT_TEXT_FILE = 'OCR_Error_Cleaned_Spanish.txt'\n",
        "OUTPUT_CORRECTED_FILE = 'Gemini_OCR_Error_Cleaned_Spanish.txt'\n",
        "CHUNK_SIZE = 10000\n",
        "CORRECTION_PROMPT = \"\"\"Eres un corrector experto de textos en español moderno temprano. TU TAREA es corregir ÚNICAMENTE los errores de OCR en el texto de entrada. No reescribas ni alteres el uso auténtico del período.\n",
        "\n",
        "REGLAS ESPECÍFICAS PARA ESPAÑOL MODERNO TEMPRANO:\n",
        "\n",
        "1.  **Preservar el texto original (uso auténtico):**\n",
        "    *   Mantén la redacción, gramática, sintaxis, y la ortografía histórica original (e.g., `hazienda`, `quando`, `scrito`, `vuestra merced`).\n",
        "    *   Corrige SOLAMENTE errores evidentes de OCR:\n",
        "        *   Letras mal leídas por el OCR.\n",
        "        *   Palabras rotas o divididas incorrectamente.\n",
        "        *   Espacios incorrectos o faltantes.\n",
        "        *   Caracteres duplicados o puntuación corrompida.\n",
        "\n",
        "2.  **Normalización mínima (convenciones de la época):**\n",
        "    *   Mantén el uso original de `u` (vocal) y `v` (consonante), `i` (vocal) e `j` (consonante), si la fuente original los diferencia. Si la fuente usa `i` para ambos sonidos, mantén `i`.\n",
        "    *   Reemplazar `&` o `&amp;` con `y`.\n",
        "    *   Asegurar que la `ñ` (e.g., `n~o` -> `ño`) esté correctamente formada.\n",
        "    *   NO modernices el vocabulario ni regularices la ortografía histórica a menos que la forma sea claramente un error de OCR.\n",
        "\n",
        "3.  **Desguionizado e Hiphenación:**\n",
        "    *   Elimina todos los guiones de final de línea que unan una palabra partida: retira el guion y une las dos partes en una sola palabra continua.\n",
        "    *   Corrige cualquier error de espaciado resultante de la rotura de línea.\n",
        "\n",
        "4.  **Formato:**\n",
        "    *   Conserva todas las pausas de párrafo y la capitalización exactamente igual que en la entrada.\n",
        "    *   Elimina el mobiliario de página (elementos de imprenta) solo cuando esté claro que no forma parte del texto corrido: ejemplos: \"A ij\", \"EPISTOLA.\", signaturas, reclamos tipográficos.\n",
        "\n",
        "5.  **Salida:**\n",
        "    *   Produce ÚNICAMENTE el texto en español corregido. NO añadas comentarios, explicaciones, ni formato adicional (como negritas o cursivas).\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 1. Authenticate and Initialize the Vertex AI Client\n",
        "# -----------------------------------------------------------\n",
        "try:\n",
        "    if not os.path.exists(JSON_FILE_PATH):\n",
        "        print(f\"Credentials file not found at: {JSON_FILE_PATH}\")\n",
        "        raise FileNotFoundError(f\"Credentials file not found: {JSON_FILE_PATH}\")\n",
        "\n",
        "    os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = JSON_FILE_PATH\n",
        "    vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
        "    # Initialize the *one* model client we will reuse everywhere\n",
        "    model = GenerativeModel(GEMINI_MODEL)\n",
        "    print(f\"Gemini Model '{GEMINI_MODEL}' initialized successfully.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Authentication or client initialization failed: {e}\")\n",
        "    exit()\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 2. Define a function to read a file in chunks\n",
        "# -----------------------------------------------------------\n",
        "def read_in_chunks(file_path, chunk_size=CHUNK_SIZE):\n",
        "    # (This function remains the same)\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        while True:\n",
        "            chunk = f.read(chunk_size)\n",
        "            if not chunk:\n",
        "                break\n",
        "            yield chunk\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 3. Define an ASYNCHRONOUS function to correct a chunk\n",
        "# -----------------------------------------------------------\n",
        "async def correct_ocr_chunk_with_gemini_async(model_client, chunk_text, chunk_id):\n",
        "    \"\"\"Sends a text chunk to Gemini for correction asynchronously.\"\"\"\n",
        "\n",
        "    contents = [\n",
        "        CORRECTION_PROMPT,\n",
        "        chunk_text\n",
        "    ]\n",
        "\n",
        "    try:\n",
        "        # Await the response using the provided model_client instance\n",
        "        response = await model_client.generate_content_async(contents)\n",
        "\n",
        "        corrected_text = response.text.strip() or \"\"\n",
        "        print(f\"  -> Finished processing chunk {chunk_id}.\")\n",
        "        return chunk_id, corrected_text # Return ID to sort results later\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"API call failed for chunk {chunk_id}: {e}\")\n",
        "        return chunk_id, chunk_text # Return original text if API fails\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 4. Main asynchronous execution block\n",
        "# -----------------------------------------------------------\n",
        "async def main():\n",
        "    if not os.path.exists(INPUT_TEXT_FILE):\n",
        "        print(f\"Input file '{INPUT_TEXT_FILE}' not found. Ensure it is uploaded or available.\")\n",
        "        return\n",
        "\n",
        "    print(f\"\\nStarting ASYNC OCR correction process on {INPUT_TEXT_FILE}...\")\n",
        "\n",
        "    tasks = []\n",
        "    chunk_count = 0\n",
        "    for chunk in read_in_chunks(INPUT_TEXT_FILE, CHUNK_SIZE):\n",
        "        chunk_count += 1\n",
        "        # Pass the initialized 'model' instance to the async function\n",
        "        tasks.append(correct_ocr_chunk_with_gemini_async(model, chunk, chunk_count))\n",
        "\n",
        "    print(f\"Created {len(tasks)} tasks. Sending requests concurrently...\")\n",
        "\n",
        "    results = await asyncio.gather(*tasks, return_exceptions=True)\n",
        "\n",
        "    processed_results = []\n",
        "    for res in results:\n",
        "        if isinstance(res, Exception):\n",
        "            print(f\"An exception occurred during one of the API calls: {res}\")\n",
        "        else:\n",
        "            processed_results.append(res)\n",
        "\n",
        "    processed_results.sort(key=lambda x: x[0]) # Sort by the chunk_id (index 0)\n",
        "\n",
        "    with open(OUTPUT_CORRECTED_FILE, 'w', encoding='utf-8') as f_out:\n",
        "        for chunk_id, corrected_chunk in processed_results:\n",
        "            if corrected_chunk:\n",
        "                f_out.write(corrected_chunk + \"\\n\\n\")\n",
        "\n",
        "    print(f\"\\n--- Gemini ASYNC OCR Correction Pipeline Finished ---\")\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 5. Run the asynchronous main function in Colab\n",
        "# -----------------------------------------------------------\n",
        "if __name__ == '__main__':\n",
        "    # asyncio.run handles running the async main loop\n",
        "    asyncio.run(main())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKPKKomTWk0F"
      },
      "source": [
        "OK, now let's try OCR'ing using Gemini 2.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDEB-uvtYu2K",
        "outputId": "353ddd13-ed13-435c-94c4-0c00b35ab077"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting installation of system dependencies and python libraries...\n",
            "Installation steps finished. Attempting import statements now.\n",
            "\n",
            "SUCCESS: All modules were imported correctly!\n",
            "You can now proceed with the full OCR pipeline code.\n",
            "pdf2image found: True\n"
          ]
        }
      ],
      "source": [
        "# --- Single Cell Code to Verify Installation and Import ---\n",
        "\n",
        "print(\"Starting installation of system dependencies and python libraries...\")\n",
        "\n",
        "# 1. Install necessary libraries\n",
        "# apt-get installs the 'poppler-utils' system dependency required by pdf2image\n",
        "!apt-get install -y poppler-utils > /dev/null\n",
        "!pip install pdf2image Pillow requests > /dev/null\n",
        "\n",
        "print(\"Installation steps finished. Attempting import statements now.\")\n",
        "\n",
        "# 2. Attempt imports to verify success\n",
        "try:\n",
        "    import os\n",
        "    import requests\n",
        "    from pdf2image import convert_from_path\n",
        "    from PIL import Image\n",
        "    print(\"\\nSUCCESS: All modules were imported correctly!\")\n",
        "    print(\"You can now proceed with the full OCR pipeline code.\")\n",
        "except ImportError as e:\n",
        "    print(f\"\\nERROR: Failed to import modules. Traceback: {e}\")\n",
        "\n",
        "# 3. Quick verification function\n",
        "def verify_pdf2image():\n",
        "    print(f\"pdf2image found: {convert_from_path is not None}\")\n",
        "\n",
        "verify_pdf2image()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z4l0Gqq4bC3n"
      },
      "outputs": [],
      "source": [
        "# -----------------------------------------------------------\n",
        "# --- Full Google Colab OCR Pipeline (Asynchronous/Fastest Way) ---\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "import os\n",
        "import io\n",
        "import json\n",
        "import vertexai\n",
        "import asyncio\n",
        "import concurrent.futures\n",
        "from pdf2image import convert_from_path, pdfinfo_from_path\n",
        "from PIL import Image\n",
        "from vertexai.generative_models import GenerativeModel, Part, Image as VertexImage\n",
        "from vertexai.preview.generative_models import Image as PreviewImage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTNg6Z4jXDjv",
        "outputId": "7ef1b21c-4c50-4400-fb57-9e675fd1fdab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ensuring dependencies are installed...\n",
            "Dependencies check complete.\n",
            "Gemini Model 'gemini-2.5-flash' initialized successfully for project 'renaissance-ocr'.\n",
            "PDF detected to have a total of 452 pages.\n",
            "Converting pages 1 to 452 into high-quality images (300 DPI)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/vertexai/generative_models/_generative_models.py:433: UserWarning: This feature is deprecated as of June 24, 2025 and will be removed on June 24, 2026. For details, see https://cloud.google.com/vertex-ai/generative-ai/docs/deprecations/genai-vertexai-sdk.\n",
            "  warning_logs.show_deprecation_warning()\n",
            "WARNING:root:REST async clients requires async credentials set using aiplatform.initializer._set_async_rest_credentials().\n",
            "Falling back to grpc since no async rest credentials were detected.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image extraction complete for 452 pages.\n",
            "\n",
            "Starting ASYNC Gemini OCR process on 452 images...\n",
            "\n",
            "--- Gemini OCR Pipeline Finished ---\n",
            "  -> Finished processing page_0001.png\n",
            "  -> Finished processing page_0002.png\n",
            "  -> Finished processing page_0003.png\n",
            "  -> Finished processing page_0004.png\n",
            "  -> Finished processing page_0005.png\n",
            "  -> Finished processing page_0006.png\n",
            "  -> Finished processing page_0007.png\n",
            "  -> Finished processing page_0008.png\n",
            "  -> Finished processing page_0009.png\n",
            "  -> Finished processing page_0010.png\n",
            "  -> Finished processing page_0011.png\n",
            "  -> Finished processing page_0012.png\n",
            "  -> Finished processing page_0013.png\n",
            "  -> Finished processing page_0014.png\n",
            "  -> Finished processing page_0015.png\n",
            "  -> Finished processing page_0016.png\n",
            "  -> Finished processing page_0017.png\n",
            "  -> Finished processing page_0018.png\n",
            "  -> Finished processing page_0019.png\n",
            "  -> Finished processing page_0020.png\n",
            "  -> Finished processing page_0021.png\n",
            "  -> Finished processing page_0022.png\n",
            "  -> Finished processing page_0023.png\n",
            "  -> Finished processing page_0024.png\n",
            "  -> Finished processing page_0025.png\n",
            "  -> Finished processing page_0026.png\n",
            "  -> Finished processing page_0027.png\n",
            "  -> Finished processing page_0028.png\n",
            "  -> Finished processing page_0029.png\n",
            "  -> Finished processing page_0030.png\n",
            "  -> Finished processing page_0031.png\n",
            "  -> Finished processing page_0032.png\n",
            "  -> Finished processing page_0033.png\n",
            "  -> Finished processing page_0034.png\n",
            "  -> Finished processing page_0035.png\n",
            "  -> Finished processing page_0036.png\n",
            "  -> Finished processing page_0037.png\n",
            "  -> Finished processing page_0038.png\n",
            "  -> Finished processing page_0039.png\n",
            "  -> Finished processing page_0040.png\n",
            "  -> Finished processing page_0041.png\n",
            "  -> Finished processing page_0042.png\n",
            "  -> Finished processing page_0043.png\n",
            "  -> Finished processing page_0044.png\n",
            "  -> Finished processing page_0045.png\n",
            "  -> Finished processing page_0046.png\n",
            "  -> Finished processing page_0047.png\n",
            "  -> Finished processing page_0048.png\n",
            "  -> Finished processing page_0049.png\n",
            "  -> Finished processing page_0050.png\n",
            "  -> Finished processing page_0051.png\n",
            "  -> Finished processing page_0052.png\n",
            "  -> Finished processing page_0053.png\n",
            "  -> Finished processing page_0054.png\n",
            "  -> Finished processing page_0055.png\n",
            "  -> Finished processing page_0056.png\n",
            "  -> Finished processing page_0057.png\n",
            "  -> Finished processing page_0058.png\n",
            "  -> Finished processing page_0059.png\n",
            "  -> Finished processing page_0060.png\n",
            "  -> Finished processing page_0061.png\n",
            "  -> Finished processing page_0062.png\n",
            "  -> Finished processing page_0063.png\n",
            "  -> Finished processing page_0064.png\n",
            "  -> Finished processing page_0065.png\n",
            "  -> Finished processing page_0066.png\n",
            "  -> Finished processing page_0067.png\n",
            "  -> Finished processing page_0068.png\n",
            "  -> Finished processing page_0069.png\n",
            "  -> Finished processing page_0070.png\n",
            "  -> Finished processing page_0071.png\n",
            "  -> Finished processing page_0072.png\n",
            "  -> Finished processing page_0073.png\n",
            "  -> Finished processing page_0074.png\n",
            "  -> Finished processing page_0075.png\n",
            "  -> Finished processing page_0076.png\n",
            "  -> Finished processing page_0077.png\n",
            "  -> Finished processing page_0078.png\n",
            "  -> Finished processing page_0079.png\n",
            "  -> Finished processing page_0080.png\n",
            "  -> Finished processing page_0081.png\n",
            "  -> Finished processing page_0082.png\n",
            "  -> Finished processing page_0083.png\n",
            "  -> Finished processing page_0084.png\n",
            "  -> Finished processing page_0085.png\n",
            "  -> Finished processing page_0086.png\n",
            "  -> Finished processing page_0087.png\n",
            "  -> Finished processing page_0088.png\n",
            "  -> Finished processing page_0089.png\n",
            "  -> Finished processing page_0090.png\n",
            "  -> Finished processing page_0091.png\n",
            "  -> Finished processing page_0092.png\n",
            "  -> Finished processing page_0093.png\n",
            "  -> Finished processing page_0094.png\n",
            "  -> Finished processing page_0095.png\n",
            "  -> Finished processing page_0096.png\n",
            "  -> Finished processing page_0097.png\n",
            "  -> Finished processing page_0098.png\n",
            "  -> Finished processing page_0099.png\n",
            "  -> Finished processing page_0100.png\n",
            "  -> Finished processing page_0101.png\n",
            "  -> Finished processing page_0102.png\n",
            "  -> Finished processing page_0103.png\n",
            "  -> Finished processing page_0104.png\n",
            "  -> Finished processing page_0105.png\n",
            "  -> Finished processing page_0106.png\n",
            "  -> Finished processing page_0107.png\n",
            "  -> Finished processing page_0108.png\n",
            "  -> Finished processing page_0109.png\n",
            "  -> Finished processing page_0110.png\n",
            "  -> Finished processing page_0111.png\n",
            "  -> Finished processing page_0112.png\n",
            "  -> Finished processing page_0113.png\n",
            "  -> Finished processing page_0114.png\n",
            "  -> Finished processing page_0115.png\n",
            "  -> Finished processing page_0116.png\n",
            "  -> Finished processing page_0117.png\n",
            "  -> Finished processing page_0118.png\n",
            "  -> Finished processing page_0119.png\n",
            "  -> Finished processing page_0120.png\n",
            "  -> Finished processing page_0121.png\n",
            "  -> Finished processing page_0122.png\n",
            "  -> Finished processing page_0123.png\n",
            "  -> Finished processing page_0124.png\n",
            "  -> Finished processing page_0125.png\n",
            "  -> Finished processing page_0126.png\n",
            "  -> Finished processing page_0127.png\n",
            "  -> Finished processing page_0128.png\n",
            "  -> Finished processing page_0129.png\n",
            "  -> Finished processing page_0130.png\n",
            "  -> Finished processing page_0131.png\n",
            "  -> Finished processing page_0132.png\n",
            "  -> Finished processing page_0133.png\n",
            "  -> Finished processing page_0134.png\n",
            "  -> Finished processing page_0135.png\n",
            "  -> Finished processing page_0136.png\n",
            "  -> Finished processing page_0137.png\n",
            "  -> Finished processing page_0138.png\n",
            "  -> Finished processing page_0139.png\n",
            "  -> Finished processing page_0140.png\n",
            "  -> Finished processing page_0141.png\n",
            "  -> Finished processing page_0142.png\n",
            "  -> Finished processing page_0143.png\n",
            "  -> Finished processing page_0144.png\n",
            "  -> Finished processing page_0145.png\n",
            "  -> Finished processing page_0146.png\n",
            "  -> Finished processing page_0147.png\n",
            "  -> Finished processing page_0148.png\n",
            "  -> Finished processing page_0149.png\n",
            "  -> Finished processing page_0150.png\n",
            "  -> Finished processing page_0151.png\n",
            "  -> Finished processing page_0152.png\n",
            "  -> Finished processing page_0153.png\n",
            "  -> Finished processing page_0154.png\n",
            "  -> Finished processing page_0155.png\n",
            "  -> Finished processing page_0156.png\n",
            "  -> Finished processing page_0157.png\n",
            "  -> Finished processing page_0158.png\n",
            "  -> Finished processing page_0159.png\n",
            "  -> Finished processing page_0160.png\n",
            "  -> Finished processing page_0161.png\n",
            "  -> Finished processing page_0162.png\n",
            "  -> Finished processing page_0163.png\n",
            "  -> Finished processing page_0164.png\n",
            "  -> Finished processing page_0165.png\n",
            "  -> Finished processing page_0166.png\n",
            "  -> Finished processing page_0167.png\n",
            "  -> Finished processing page_0168.png\n",
            "  -> Finished processing page_0169.png\n",
            "  -> Finished processing page_0170.png\n",
            "  -> Finished processing page_0171.png\n",
            "  -> Finished processing page_0172.png\n",
            "  -> Finished processing page_0173.png\n",
            "  -> Finished processing page_0174.png\n",
            "  -> Finished processing page_0175.png\n",
            "  -> Finished processing page_0176.png\n",
            "  -> Finished processing page_0177.png\n",
            "  -> Finished processing page_0178.png\n",
            "  -> Finished processing page_0179.png\n",
            "  -> Finished processing page_0180.png\n",
            "  -> Finished processing page_0181.png\n",
            "  -> Finished processing page_0182.png\n",
            "  -> Finished processing page_0183.png\n",
            "  -> Finished processing page_0184.png\n",
            "  -> Finished processing page_0185.png\n",
            "  -> Finished processing page_0186.png\n",
            "  -> Finished processing page_0187.png\n",
            "  -> Finished processing page_0188.png\n",
            "  -> Finished processing page_0189.png\n",
            "  -> Finished processing page_0190.png\n",
            "  -> Finished processing page_0191.png\n",
            "  -> Finished processing page_0192.png\n",
            "  -> Finished processing page_0193.png\n",
            "  -> Finished processing page_0194.png\n",
            "  -> Finished processing page_0195.png\n",
            "  -> Finished processing page_0196.png\n",
            "  -> Finished processing page_0197.png\n",
            "  -> Finished processing page_0198.png\n",
            "  -> Finished processing page_0199.png\n",
            "  -> Finished processing page_0200.png\n",
            "  -> Finished processing page_0201.png\n",
            "  -> Finished processing page_0202.png\n",
            "  -> Finished processing page_0203.png\n",
            "  -> Finished processing page_0204.png\n",
            "  -> Finished processing page_0205.png\n",
            "  -> Finished processing page_0206.png\n",
            "  -> Finished processing page_0207.png\n",
            "  -> Finished processing page_0208.png\n",
            "  -> Finished processing page_0209.png\n",
            "  -> Finished processing page_0210.png\n",
            "  -> Finished processing page_0211.png\n",
            "  -> Finished processing page_0212.png\n",
            "  -> Finished processing page_0213.png\n",
            "  -> Finished processing page_0214.png\n",
            "  -> Finished processing page_0215.png\n",
            "  -> Finished processing page_0216.png\n",
            "  -> Finished processing page_0217.png\n",
            "  -> Finished processing page_0218.png\n",
            "  -> Finished processing page_0219.png\n",
            "  -> Finished processing page_0220.png\n",
            "  -> Finished processing page_0221.png\n",
            "  -> Finished processing page_0222.png\n",
            "  -> Finished processing page_0223.png\n",
            "  -> Finished processing page_0224.png\n",
            "  -> Finished processing page_0225.png\n",
            "  -> Finished processing page_0226.png\n",
            "  -> Finished processing page_0227.png\n",
            "  -> Finished processing page_0228.png\n",
            "  -> Finished processing page_0229.png\n",
            "  -> Finished processing page_0230.png\n",
            "  -> Finished processing page_0231.png\n",
            "  -> Finished processing page_0232.png\n",
            "  -> Finished processing page_0233.png\n",
            "  -> Finished processing page_0234.png\n",
            "  -> Finished processing page_0235.png\n",
            "  -> Finished processing page_0236.png\n",
            "  -> Finished processing page_0237.png\n",
            "  -> Finished processing page_0238.png\n",
            "  -> Finished processing page_0239.png\n",
            "  -> Finished processing page_0240.png\n",
            "  -> Finished processing page_0241.png\n",
            "  -> Finished processing page_0242.png\n",
            "  -> Finished processing page_0243.png\n",
            "  -> Finished processing page_0244.png\n",
            "  -> Finished processing page_0245.png\n",
            "  -> Finished processing page_0246.png\n",
            "  -> Finished processing page_0247.png\n",
            "  -> Finished processing page_0248.png\n",
            "  -> Finished processing page_0249.png\n",
            "  -> Finished processing page_0250.png\n",
            "  -> Finished processing page_0251.png\n",
            "  -> Finished processing page_0252.png\n",
            "  -> Finished processing page_0253.png\n",
            "  -> Finished processing page_0254.png\n",
            "  -> Finished processing page_0255.png\n",
            "  -> Finished processing page_0256.png\n",
            "  -> Finished processing page_0257.png\n",
            "  -> Finished processing page_0258.png\n",
            "  -> Finished processing page_0259.png\n",
            "  -> Finished processing page_0260.png\n",
            "  -> Finished processing page_0261.png\n",
            "  -> Finished processing page_0262.png\n",
            "  -> Finished processing page_0263.png\n",
            "  -> Finished processing page_0264.png\n",
            "  -> Finished processing page_0265.png\n",
            "  -> Finished processing page_0266.png\n",
            "  -> Finished processing page_0267.png\n",
            "  -> Finished processing page_0268.png\n",
            "  -> Finished processing page_0269.png\n",
            "  -> Finished processing page_0270.png\n",
            "  -> Finished processing page_0271.png\n",
            "  -> Finished processing page_0272.png\n",
            "  -> Finished processing page_0273.png\n",
            "  -> Finished processing page_0274.png\n",
            "  -> Finished processing page_0275.png\n",
            "  -> Finished processing page_0276.png\n",
            "  -> Finished processing page_0277.png\n",
            "  -> Finished processing page_0278.png\n",
            "  -> Finished processing page_0279.png\n",
            "  -> Finished processing page_0280.png\n",
            "  -> Finished processing page_0281.png\n",
            "  -> Finished processing page_0282.png\n",
            "  -> Finished processing page_0283.png\n",
            "  -> Finished processing page_0284.png\n",
            "  -> Finished processing page_0285.png\n",
            "  -> Finished processing page_0286.png\n",
            "  -> Finished processing page_0287.png\n",
            "  -> Finished processing page_0288.png\n",
            "  -> Finished processing page_0289.png\n",
            "  -> Finished processing page_0290.png\n",
            "  -> Finished processing page_0291.png\n",
            "  -> Finished processing page_0292.png\n",
            "  -> Finished processing page_0293.png\n",
            "  -> Finished processing page_0294.png\n",
            "  -> Finished processing page_0295.png\n",
            "  -> Finished processing page_0296.png\n",
            "  -> Finished processing page_0297.png\n",
            "  -> Finished processing page_0298.png\n",
            "  -> Finished processing page_0299.png\n",
            "  -> Finished processing page_0300.png\n",
            "  -> Finished processing page_0301.png\n",
            "  -> Finished processing page_0302.png\n",
            "  -> Finished processing page_0303.png\n",
            "  -> Finished processing page_0304.png\n",
            "  -> Finished processing page_0305.png\n",
            "  -> Finished processing page_0306.png\n",
            "  -> Finished processing page_0307.png\n",
            "  -> Finished processing page_0308.png\n",
            "  -> Finished processing page_0309.png\n",
            "  -> Finished processing page_0310.png\n",
            "  -> Finished processing page_0311.png\n",
            "  -> Finished processing page_0312.png\n",
            "  -> Finished processing page_0313.png\n",
            "  -> Finished processing page_0314.png\n",
            "  -> Finished processing page_0315.png\n",
            "  -> Finished processing page_0316.png\n",
            "  -> Finished processing page_0317.png\n",
            "  -> Finished processing page_0318.png\n",
            "  -> Finished processing page_0319.png\n",
            "  -> Finished processing page_0320.png\n",
            "  -> Finished processing page_0321.png\n",
            "  -> Finished processing page_0322.png\n",
            "  -> Finished processing page_0323.png\n",
            "  -> Finished processing page_0324.png\n",
            "  -> Finished processing page_0325.png\n",
            "  -> Finished processing page_0326.png\n",
            "  -> Finished processing page_0327.png\n",
            "  -> Finished processing page_0328.png\n",
            "  -> Finished processing page_0329.png\n",
            "  -> Finished processing page_0330.png\n",
            "  -> Finished processing page_0331.png\n",
            "  -> Finished processing page_0332.png\n",
            "  -> Finished processing page_0333.png\n",
            "  -> Finished processing page_0334.png\n",
            "  -> Finished processing page_0335.png\n",
            "  -> Finished processing page_0336.png\n",
            "  -> Finished processing page_0337.png\n",
            "  -> Finished processing page_0338.png\n",
            "  -> Finished processing page_0339.png\n",
            "  -> Finished processing page_0340.png\n",
            "  -> Finished processing page_0341.png\n",
            "  -> Finished processing page_0342.png\n",
            "  -> Finished processing page_0343.png\n",
            "  -> Finished processing page_0344.png\n",
            "  -> Finished processing page_0345.png\n",
            "  -> Finished processing page_0346.png\n",
            "  -> Finished processing page_0347.png\n",
            "  -> Finished processing page_0348.png\n",
            "  -> Finished processing page_0349.png\n",
            "  -> Finished processing page_0350.png\n",
            "  -> Finished processing page_0351.png\n",
            "  -> Finished processing page_0352.png\n",
            "  -> Finished processing page_0353.png\n",
            "  -> Finished processing page_0354.png\n",
            "  -> Finished processing page_0355.png\n",
            "  -> Finished processing page_0356.png\n",
            "  -> Finished processing page_0357.png\n",
            "  -> Finished processing page_0358.png\n",
            "  -> Finished processing page_0359.png\n",
            "  -> Finished processing page_0360.png\n",
            "  -> Finished processing page_0361.png\n",
            "  -> Finished processing page_0362.png\n",
            "  -> Finished processing page_0363.png\n",
            "  -> Finished processing page_0364.png\n",
            "  -> Finished processing page_0365.png\n",
            "  -> Finished processing page_0366.png\n",
            "  -> Finished processing page_0367.png\n",
            "  -> Finished processing page_0368.png\n",
            "  -> Finished processing page_0369.png\n",
            "  -> Finished processing page_0370.png\n",
            "  -> Finished processing page_0371.png\n",
            "  -> Finished processing page_0372.png\n",
            "  -> Finished processing page_0373.png\n",
            "  -> Finished processing page_0374.png\n",
            "  -> Finished processing page_0375.png\n",
            "  -> Finished processing page_0376.png\n",
            "  -> Finished processing page_0377.png\n",
            "  -> Finished processing page_0378.png\n",
            "  -> Finished processing page_0379.png\n",
            "  -> Finished processing page_0380.png\n",
            "  -> Finished processing page_0381.png\n",
            "  -> Finished processing page_0382.png\n",
            "  -> Finished processing page_0383.png\n",
            "  -> Finished processing page_0384.png\n",
            "  -> Finished processing page_0385.png\n",
            "  -> Finished processing page_0386.png\n",
            "  -> Finished processing page_0387.png\n",
            "  -> Finished processing page_0388.png\n",
            "  -> Finished processing page_0389.png\n",
            "  -> Finished processing page_0390.png\n",
            "  -> Finished processing page_0391.png\n",
            "  -> Finished processing page_0392.png\n",
            "  -> Finished processing page_0393.png\n",
            "  -> Finished processing page_0394.png\n",
            "  -> Finished processing page_0395.png\n",
            "  -> Finished processing page_0396.png\n",
            "  -> Finished processing page_0397.png\n",
            "  -> Finished processing page_0398.png\n",
            "  -> Finished processing page_0399.png\n",
            "  -> Finished processing page_0400.png\n",
            "  -> Finished processing page_0401.png\n",
            "  -> Finished processing page_0402.png\n",
            "  -> Finished processing page_0403.png\n",
            "  -> Finished processing page_0404.png\n",
            "  -> Finished processing page_0405.png\n",
            "  -> Finished processing page_0406.png\n",
            "  -> Finished processing page_0407.png\n",
            "  -> Finished processing page_0408.png\n",
            "  -> Finished processing page_0409.png\n",
            "  -> Finished processing page_0410.png\n",
            "  -> Finished processing page_0411.png\n",
            "  -> Finished processing page_0412.png\n",
            "  -> Finished processing page_0413.png\n",
            "  -> Finished processing page_0414.png\n",
            "  -> Finished processing page_0415.png\n",
            "  -> Finished processing page_0416.png\n",
            "  -> Finished processing page_0417.png\n",
            "  -> Finished processing page_0418.png\n",
            "  -> Finished processing page_0419.png\n",
            "  -> Finished processing page_0420.png\n",
            "  -> Finished processing page_0421.png\n",
            "  -> Finished processing page_0422.png\n",
            "  -> Finished processing page_0423.png\n",
            "  -> Finished processing page_0424.png\n",
            "  -> Finished processing page_0425.png\n",
            "  -> Finished processing page_0426.png\n",
            "  -> Finished processing page_0427.png\n",
            "  -> Finished processing page_0428.png\n",
            "  -> Finished processing page_0429.png\n",
            "  -> Finished processing page_0430.png\n",
            "  -> Finished processing page_0431.png\n",
            "  -> Finished processing page_0432.png\n",
            "  -> Finished processing page_0433.png\n",
            "  -> Finished processing page_0434.png\n",
            "  -> Finished processing page_0435.png\n",
            "  -> Finished processing page_0436.png\n",
            "  -> Finished processing page_0437.png\n",
            "  -> Finished processing page_0438.png\n",
            "  -> Finished processing page_0439.png\n",
            "  -> Finished processing page_0440.png\n",
            "  -> Finished processing page_0441.png\n",
            "  -> Finished processing page_0442.png\n",
            "  -> Finished processing page_0443.png\n",
            "  -> Finished processing page_0444.png\n",
            "  -> Finished processing page_0445.png\n",
            "  -> Finished processing page_0446.png\n",
            "  -> Finished processing page_0447.png\n",
            "  -> Finished processing page_0448.png\n",
            "  -> Finished processing page_0449.png\n",
            "  -> Finished processing page_0450.png\n",
            "  -> Finished processing page_0451.png\n",
            "  -> Finished processing page_0452.png\n",
            "All extracted text has been saved to: Extracted_OCR_Text_Spanish_Full_Async.txt\n",
            "\n",
            "============================================================\n",
            "FIRST 200 WORDS OF EXTRACTED TEXT (Gemini):\n",
            "============================================================\n",
            "--- Start of OCR from page_0001.png --- No text detected --- End of OCR from page_0001.png --- --- Start of OCR from page_0002.png --- No text detected --- End of OCR from page_0002.png --- --- Start of OCR from page_0003.png --- No text detected --- End of OCR from page_0003.png --- --- Start of OCR from page_0004.png --- No text detected --- End of OCR from page_0004.png --- --- Start of OCR from page_0005.png --- SIXTVS PAPA V. Dilecto filio Ioanni Gonçalez de Mendoça preſbytero, ordinem Sancti Auguſtini Heremitarum expreſſe ſe profeſſo: y Magiſtro in Theologia. Dilecte fili Salutem y Apoſtolicam Benedictionem Exponi nobis nuper fecisti quòd cum tu quædam librum Hiſtoriarum, rerum memorandarum Indiarum de la China, y totius Mundi noui inſcriptum, de mandato felicis recordationis Gregorij Papæ XIII. prædeceſſoris noſtri, non paruis tuis labore y vigilijs idiomate hiſpano, ex quo poſtea in Italicum traductus est, compoſueris, ac illum sic compoſitum, traductum y à Dilecto filio Magiſtro noſtri Sacri Palatij Apoſtolici examinatum y approbatum, Typis mandari facere intendas quia tamen vereris, ne poſtquam in lucem prodierit, à pluribus, te inſcio y irreprehenſa imprimatur: y in preſſus in maximum tuum detrimentum, venalis habeatur. Nobis humiliter ſupplicari fecisti, quatenus tuæ indemnitati\n",
            "\n",
            "[... Text truncated for display purposes ...]\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# --- 1. Configuration Variables (Same as before) ---\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "# Path to your uploaded GCP JSON key file\n",
        "JSON_FILE_PATH = '/content/renaissance-ocr-4aabe5b8dc65.json'\n",
        "\n",
        "# Path to your uploaded PDF file\n",
        "LOCAL_PDF_PATH = '/content/bub_gb_6QiHhHwp8MMC.pdf'\n",
        "\n",
        "# GCP Project Details\n",
        "PROJECT_ID = 'renaissance-ocr'\n",
        "LOCATION = 'global'\n",
        "GEMINI_MODEL = 'gemini-2.5-flash'\n",
        "OUTPUT_IMAGE_FOLDER = 'extracted_images'\n",
        "OUTPUT_TEXT_FILE = 'Extracted_OCR_Text_Spanish_Full_Async.txt'\n",
        "\n",
        "# Specific prompt tailored for Early Modern Spanish (based on your rules)\n",
        "OCR_PROMPT = \"\"\"\n",
        "Eres un corrector experto de textos en español moderno temprano. TU TAREA es corregir ÚNICAMENTE los errores de OCR en el texto de entrada basándose en la imagen proporcionada. No reescribas ni alteres el uso auténtico del período.\n",
        "\n",
        "REGLAS ESPECÍFICAS PARA ESPAÑOL MODERNO TEMPRANO:\n",
        "\n",
        "1.  **Preservar el texto original (uso auténtico):** Mantén la redacción, gramática, sintaxis, y la ortografía histórica original. Corrige SOLAMENTE errores evidentes de OCR.\n",
        "2.  **Normalización mínima:** Mantén el uso original de `u`/`v`, `i`/`j`. Reemplazar `&` con `y`. Asegurar que la `ñ` esté correcta.\n",
        "3.  **Desguionizado e Hiphenación:** Elimina todos los guiones de final de línea que unan una palabra partida.\n",
        "4.  **Formato:** Conserva todas las pausas de párrafo y la capitalización exactamente igual que en la entrada. Elimina mobiliario de página (e.g., \"A ij\", signaturas).\n",
        "5.  **Salida:** Produce ÚNICAMENTE el texto en español corregido. NO añadas comentarios, explicaciones, ni formato adicional.\n",
        "\"\"\"\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# --- 2. Install System Dependencies & Python Libraries (Safety Net) ---\n",
        "# -----------------------------------------------------------\n",
        "print(\"Ensuring dependencies are installed...\")\n",
        "!apt-get install -y poppler-utils > /dev/null\n",
        "!pip install google-cloud-aiplatform PyMuPDF Pillow requests pdf2image --upgrade > /dev/null\n",
        "print(\"Dependencies check complete.\")\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# --- 3. Authenticate and Initialize the Vertex AI Client ---\n",
        "# -----------------------------------------------------------\n",
        "try:\n",
        "    if not os.path.exists(JSON_FILE_PATH):\n",
        "        raise FileNotFoundError(f\"Credentials file not found at: {JSON_FILE_PATH}.\")\n",
        "    os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = JSON_FILE_PATH\n",
        "    vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
        "    model = GenerativeModel(GEMINI_MODEL)\n",
        "    print(f\"Gemini Model '{GEMINI_MODEL}' initialized successfully for project '{PROJECT_ID}'.\")\n",
        "except Exception as e:\n",
        "    print(f\"Authentication or client initialization failed: {e}\")\n",
        "    exit()\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# --- 4. Define Functions (With automatic page count detection and ASYNC processing) ---\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "def extract_pdf_pages_from_local_file(local_pdf_path, output_folder):\n",
        "    \"\"\"Detects total pages and extracts all pages as high-quality images.\"\"\"\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "        print(f\"Created folder: {output_folder}\")\n",
        "    if not os.path.exists(local_pdf_path):\n",
        "        print(f\"Error: Local PDF file not found at {local_pdf_path}\")\n",
        "        return []\n",
        "    try:\n",
        "        info = pdfinfo_from_path(local_pdf_path, userpw=None, poppler_path=None)\n",
        "        total_pages = info[\"Pages\"]\n",
        "        print(f\"PDF detected to have a total of {total_pages} pages.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Could not determine page count automatically: {e}. Defaulting to 1000 max pages.\")\n",
        "        total_pages = 1000\n",
        "    print(f\"Converting pages 1 to {total_pages} into high-quality images (300 DPI)...\")\n",
        "    image_paths = []\n",
        "    try:\n",
        "        images = convert_from_path(local_pdf_path, dpi=300, fmt='png', first_page=1, last_page=total_pages, use_cropbox=True)\n",
        "        for i, img in enumerate(images):\n",
        "            img_path = os.path.join(output_folder, f\"page_{i+1:04d}.png\")\n",
        "            img.save(img_path)\n",
        "            image_paths.append(img_path)\n",
        "        print(f\"Image extraction complete for {len(image_paths)} pages.\")\n",
        "        return sorted(image_paths)\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during PDF conversion: {e}\")\n",
        "        return []\n",
        "\n",
        "# ASYNC function to call the API\n",
        "async def process_image_with_gemini_async(image_path):\n",
        "    \"\"\"Processes a local image file using the Gemini multimodal model asynchronously.\"\"\"\n",
        "    # print(f\"  -> Sending {os.path.basename(image_path)}\") # Optional verbose logging\n",
        "    try:\n",
        "        vertex_ai_image = VertexImage.load_from_file(image_path)\n",
        "    except Exception as e:\n",
        "        return f\"Error loading image {image_path}: {e}\", image_path\n",
        "\n",
        "    contents = [OCR_PROMPT, vertex_ai_image]\n",
        "\n",
        "    try:\n",
        "        # Use generate_content_async for non-blocking API calls\n",
        "        response = await model.generate_content_async(contents)\n",
        "        full_text = response.text or \"\"\n",
        "        if full_text:\n",
        "            return full_text, image_path\n",
        "        else:\n",
        "            return \"No text detected\", image_path\n",
        "    except Exception as e:\n",
        "        return f\"API call failed for {image_path}: {e}\", image_path\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# --- 5. Main Execution Pipeline (Updated for Async Execution) ---\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "async def main_async_pipeline():\n",
        "    # Step A: Extract ALL images from the local PDF file\n",
        "    image_files_list = extract_pdf_pages_from_local_file(\n",
        "        LOCAL_PDF_PATH, OUTPUT_IMAGE_FOLDER\n",
        "    )\n",
        "\n",
        "    if not image_files_list:\n",
        "        print(\"Pipeline halted because no images were extracted.\")\n",
        "        return\n",
        "\n",
        "    # Step B: Process ALL images using Gemini OCR asynchronously\n",
        "    print(f\"\\nStarting ASYNC Gemini OCR process on {len(image_files_list)} images...\")\n",
        "\n",
        "    # Create a list of all asynchronous tasks\n",
        "    tasks = [process_image_with_gemini_async(image_path) for image_path in image_files_list]\n",
        "\n",
        "    # Run all tasks concurrently and wait for them to complete\n",
        "    results = await asyncio.gather(*tasks)\n",
        "\n",
        "    # Step C: Combine results and save to file\n",
        "    print(f\"\\n--- Gemini OCR Pipeline Finished ---\")\n",
        "\n",
        "    full_document_text = \"\"\n",
        "    with open(OUTPUT_TEXT_FILE, 'w', encoding='utf-8') as f_out:\n",
        "        header = f\"Gemini OCR Results for the full document ({len(image_files_list)} pages) [ASYNC PROCESSING]\\n\" + \"=\" * 60 + \"\\n\"\n",
        "        f_out.write(header)\n",
        "        full_document_text += header\n",
        "\n",
        "        # results is a list of (text, image_path). We process them in order they were submitted\n",
        "        for text, image_path in results:\n",
        "            section_text = f\"\\n\\n--- Start of OCR from {os.path.basename(image_path)} ---\\n\\n{text}\\n\\n--- End of OCR from {os.path.basename(image_path)} ---\\n\\n\"\n",
        "            f_out.write(section_text)\n",
        "            full_document_text += section_text\n",
        "            print(f\"  -> Finished processing {os.path.basename(image_path)}\")\n",
        "\n",
        "    print(f\"All extracted text has been saved to: {OUTPUT_TEXT_FILE}\")\n",
        "\n",
        "    # Step D: Print First 200 Words for verification\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"FIRST 200 WORDS OF EXTRACTED TEXT (Gemini):\")\n",
        "    print(\"=\" * 60)\n",
        "    words = ' '.join(full_document_text.splitlines()[3:]).split()\n",
        "    print(' '.join(words[:200]))\n",
        "    if len(words) > 200:\n",
        "        print(\"\\n[... Text truncated for display purposes ...]\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# --- Execute the Async Main Function ---\n",
        "# -----------------------------------------------------------\n",
        "if __name__ == '__main__':\n",
        "    # Running the async main function in the notebook environment\n",
        "    await main_async_pipeline()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUQvYcyIde3X"
      },
      "source": [
        "Let's divide the code into blocks as it's more pythonic."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "SP1bCJLhdWy7",
        "outputId": "64db5dcc-1f2a-451c-9003-622d7c3e727e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ensuring dependencies are installed...\n",
            "Dependencies check complete.\n",
            "Gemini Model 'gemini-2.5-flash' initialized successfully for project 'renaissance-ocr'.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/vertexai/generative_models/_generative_models.py:433: UserWarning: This feature is deprecated as of June 24, 2025 and will be removed on June 24, 2026. For details, see https://cloud.google.com/vertex-ai/generative-ai/docs/deprecations/genai-vertexai-sdk.\n",
            "  warning_logs.show_deprecation_warning()\n"
          ]
        }
      ],
      "source": [
        "# Block 1: Configuration, Installs, and Authentication\n",
        "\n",
        "import os\n",
        "import io\n",
        "import json\n",
        "import vertexai\n",
        "import asyncio\n",
        "from pdf2image import convert_from_path, pdfinfo_from_path\n",
        "from PIL import Image\n",
        "from vertexai.generative_models import GenerativeModel, Part, Image as VertexImage\n",
        "from vertexai.preview.generative_models import Image as PreviewImage # Fallback\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# --- 1. Configuration Variables: UPDATE THESE ---\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "# Path to your uploaded GCP JSON key file\n",
        "JSON_FILE_PATH = '/content/renaissance-ocr-4aabe5b8dc65.json'\n",
        "\n",
        "# Path to your uploaded PDF file\n",
        "LOCAL_PDF_PATH = '/content/bub_gb_6QiHhHwp8MMC.pdf'\n",
        "\n",
        "# GCP Project Details\n",
        "PROJECT_ID = 'renaissance-ocr'\n",
        "LOCATION = 'global'\n",
        "GEMINI_MODEL = 'gemini-2.5-flash' # Can change to 'gemini-2.5-pro' if needed\n",
        "OUTPUT_IMAGE_FOLDER = 'extracted_images'\n",
        "OUTPUT_TEXT_FILE = 'Extracted_OCR_Text_Spanish_Full_Async.txt'\n",
        "\n",
        "# Specific prompt tailored for Early Modern Spanish\n",
        "OCR_PROMPT = \"\"\"\n",
        "Eres un corrector experto de textos en español moderno temprano. TU TAREA es corregir ÚNICAMENTE los errores de OCR en el texto de entrada basándose en la imagen proporcionada. No reescribas ni alteres el uso auténtico del período.\n",
        "\n",
        "REGLAS ESPECÍFICAS PARA ESPAÑOL MODERNO TEMPRANO:\n",
        "1.  **Preservar el texto original (uso auténtico):** Mantén la redacción, gramática, sintaxis, y la ortografía histórica original. Corrige SOLAMENTE errores evidentes de OCR.\n",
        "2.  **Normalización mínima:** Mantén el uso original de `u`/`v`, `i`/`j`. Reemplazar `&` con `y`. Asegurar que la `ñ` esté correcta.  ſ = s, ß = ss.\n",
        "3.  **Desguionizado e Hiphenación:** Elimina todos los guiones de final de línea que unan una palabra partida.\n",
        "4.  **Formato:** Conserva todas las pausas de párrafo y la capitalización exactamente igual que en la entrada. Elimina mobiliario de página (e.g., \"A ij\", signaturas).\n",
        "5.  **Salida:** Produce ÚNICAMENTE el texto en español corregido. NO añadas comentarios, explicaciones, ni formato adicional.\n",
        "6. **Emimina números de página de OCR** eliminar cualquier mención de números de página de OCR\n",
        "\"\"\"\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# --- 2. Install System Dependencies & Python Libraries ---\n",
        "# -----------------------------------------------------------\n",
        "print(\"Ensuring dependencies are installed...\")\n",
        "!apt-get install -y poppler-utils > /dev/null\n",
        "!pip install google-cloud-aiplatform PyMuPDF Pillow requests pdf2image --upgrade > /dev/null\n",
        "print(\"Dependencies check complete.\")\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# --- 3. Authenticate and Initialize the Vertex AI Client ---\n",
        "# -----------------------------------------------------------\n",
        "try:\n",
        "    if not os.path.exists(JSON_FILE_PATH):\n",
        "        raise FileNotFoundError(f\"Credentials file not found at: {JSON_FILE_PATH}.\")\n",
        "    os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = JSON_FILE_PATH\n",
        "    vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
        "    # Initialize the model globally\n",
        "    model = GenerativeModel(GEMINI_MODEL)\n",
        "    print(f\"Gemini Model '{GEMINI_MODEL}' initialized successfully for project '{PROJECT_ID}'.\")\n",
        "except Exception as e:\n",
        "    print(f\"Authentication or client initialization failed: {e}\")\n",
        "    exit()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iqqVS9KfdXP2"
      },
      "outputs": [],
      "source": [
        "# Block 2: Define Functions and Extract Images (This might take a few minutes)\n",
        "\n",
        "def extract_pdf_pages_from_local_file(local_pdf_path, output_folder):\n",
        "    \"\"\"Detects total pages and extracts all pages as high-quality images.\"\"\"\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "        print(f\"Created folder: {output_folder}\")\n",
        "    if not os.path.exists(local_pdf_path):\n",
        "        print(f\"Error: Local PDF file not found at {local_pdf_path}\")\n",
        "        return []\n",
        "    try:\n",
        "        info = pdfinfo_from_path(local_pdf_path, userpw=None, poppler_path=None)\n",
        "        total_pages = info[\"Pages\"]\n",
        "        print(f\"PDF detected to have a total of {total_pages} pages.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Could not determine page count automatically: {e}. Defaulting to 452 max pages.\")\n",
        "        total_pages = 452 # Fallback to known page count\n",
        "\n",
        "    print(f\"Converting pages 1 to {total_pages} into high-quality images (300 DPI)...\")\n",
        "    image_paths = []\n",
        "    try:\n",
        "        images = convert_from_path(local_pdf_path, dpi=300, fmt='png', first_page=1, last_page=total_pages, use_cropbox=True)\n",
        "        for i, img in enumerate(images):\n",
        "            img_path = os.path.join(output_folder, f\"page_{i+1:04d}.png\")\n",
        "            img.save(img_path)\n",
        "            image_paths.append(img_path)\n",
        "        print(f\"Image extraction complete for {len(image_paths)} pages.\")\n",
        "        return sorted(image_paths)\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during PDF conversion: {e}\")\n",
        "        return []\n",
        "\n",
        "# ASYNC function to call the API (needs 'model' from Block 1)\n",
        "async def process_image_with_gemini_async(image_path):\n",
        "    \"\"\"Processes a local image file using the Gemini multimodal model asynchronously.\"\"\"\n",
        "    try:\n",
        "        vertex_ai_image = VertexImage.load_from_file(image_path)\n",
        "    except Exception as e:\n",
        "        return f\"Error loading image {image_path}: {e}\", image_path\n",
        "\n",
        "    contents = [OCR_PROMPT, vertex_ai_image]\n",
        "\n",
        "    try:\n",
        "        response = await model.generate_content_async(contents)\n",
        "        full_text = response.text or \"\"\n",
        "        if full_text:\n",
        "            return full_text, image_path\n",
        "        else:\n",
        "            return \"No text detected\", image_path\n",
        "    except Exception as e:\n",
        "        return f\"API call failed for {image_path}: {e}\", image_path\n",
        "\n",
        "# Execute image extraction immediately\n",
        "image_files_list = extract_pdf_pages_from_local_file(\n",
        "    LOCAL_PDF_PATH, OUTPUT_IMAGE_FOLDER\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OxDRVo2FdXVv"
      },
      "outputs": [],
      "source": [
        "# Block 3: Run Asynchronous OCR and Save Results\n",
        "\n",
        "async def main_async_pipeline():\n",
        "    if not image_files_list:\n",
        "        print(\"Pipeline halted because no images were extracted in Block 2.\")\n",
        "        return\n",
        "\n",
        "    # Process ALL images using Gemini OCR asynchronously\n",
        "    print(f\"\\nStarting ASYNC Gemini OCR process using {GEMINI_MODEL} on {len(image_files_list)} images...\")\n",
        "\n",
        "    # Create a list of all asynchronous tasks\n",
        "    tasks = [process_image_with_gemini_async(image_path) for image_path in image_files_list]\n",
        "\n",
        "    # Run all tasks concurrently and wait for them to complete\n",
        "    results = await asyncio.gather(*tasks)\n",
        "\n",
        "    # Combine results and save to file\n",
        "    print(f\"\\n--- Gemini OCR Pipeline Finished ---\")\n",
        "\n",
        "    full_document_text = \"\"\n",
        "    with open(OUTPUT_TEXT_FILE, 'w', encoding='utf-8') as f_out:\n",
        "        header = f\"Gemini OCR Results for the full document ({len(image_files_list)} pages) [ASYNC PROCESSING]\\n\" + \"=\" * 60 + \"\\n\"\n",
        "        f_out.write(header)\n",
        "        full_document_text += header\n",
        "\n",
        "        for text, image_path in results:\n",
        "            section_text = f\"\\n\\n--- Start of OCR from {os.path.basename(image_path)} ---\\n\\n{text}\\n\\n--- End of OCR from {os.path.basename(image_path)} ---\\n\\n\"\n",
        "            f_out.write(section_text)\n",
        "            full_document_text += section_text\n",
        "            # print(f\"  -> Finished processing {os.path.basename(image_path)}\") # Optional: verbose\n",
        "\n",
        "    print(f\"All extracted text has been saved to: {OUTPUT_TEXT_FILE}\")\n",
        "\n",
        "    # Print First 200 Words for verification\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"FIRST 200 WORDS OF EXTRACTED TEXT (Gemini):\")\n",
        "    print(\"=\" * 60)\n",
        "    words = ' '.join(full_document_text.splitlines()[3:]).split()\n",
        "    print(' '.join(words[:200]))\n",
        "    if len(words) > 200:\n",
        "        print(\"\\n[... Text truncated for display purposes ...]\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "# Execute the async main function in the notebook environment\n",
        "await main_async_pipeline()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNHi1bwhvFw9IarqDYIRDIT",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}